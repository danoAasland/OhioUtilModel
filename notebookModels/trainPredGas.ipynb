{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "trainPredGas.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danoAasland/OhioUtilModel/blob/master/notebookModels/trainPredGas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2hoFW5R7sSn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#python 2/3 compatibility\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "#packages\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.externals import joblib\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnL8I3oY7sSt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#add code to input data\n",
        "#for now, uploads data file from local drive\n",
        "dataset1 =  pd.read_csv('cinTargetClean.csv')\n",
        "dataset2 =  pd.read_csv('cleTargetClean.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg-tv4El7sSw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#combine cleveland and cinncinati target datasets into one\n",
        "dataset = pd.concat([dataset1, dataset2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_7sS2t47sSy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#drop client name column\n",
        "dataset.drop('FullName', axis = 1, inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zh3Ry5uU7sS1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#deleting the init. datasets now that they're one large dataset\n",
        "del dataset1\n",
        "del dataset2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOtSsaCM7sS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#set home value at/above 100k\n",
        "dataset = dataset[dataset['Value'] >= 100000.00].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EousEzLh7sS6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#set energy value above 6000 KwH Annual\n",
        "dataset = dataset[dataset['E annual'] >= 6000.00].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViFueXAj7sS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#set energy value less than 6000 KwH Annual\n",
        "dataset = dataset[dataset['G annual'] <= 4000.00].copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzIG1N387sS-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check to ensure dataset concat. correctly\n",
        "#uncomment to run\n",
        "#dataset.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kc2JPcy57sTJ",
        "colab_type": "code",
        "outputId": "3a09a5a2-53fb-43e9-c194-f2537b8920c3",
        "colab": {}
      },
      "source": [
        "train_DF = dataset.describe()\n",
        "train_DF = train_DF.transpose()\n",
        "#train_DF"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>SF</th>\n",
              "      <td>119549.0</td>\n",
              "      <td>2122.321943</td>\n",
              "      <td>850.684704</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1525.0</td>\n",
              "      <td>1945.0</td>\n",
              "      <td>2514.0</td>\n",
              "      <td>14788.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Floors</th>\n",
              "      <td>119549.0</td>\n",
              "      <td>1.628777</td>\n",
              "      <td>0.463201</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Year Built</th>\n",
              "      <td>119549.0</td>\n",
              "      <td>1962.298739</td>\n",
              "      <td>26.133081</td>\n",
              "      <td>1800.0</td>\n",
              "      <td>1950.0</td>\n",
              "      <td>1962.0</td>\n",
              "      <td>1983.0</td>\n",
              "      <td>2014.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Value</th>\n",
              "      <td>119549.0</td>\n",
              "      <td>219452.265841</td>\n",
              "      <td>162045.070298</td>\n",
              "      <td>100000.0</td>\n",
              "      <td>125300.0</td>\n",
              "      <td>165300.0</td>\n",
              "      <td>253500.0</td>\n",
              "      <td>3663000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>E annual</th>\n",
              "      <td>119549.0</td>\n",
              "      <td>12419.001723</td>\n",
              "      <td>6050.031002</td>\n",
              "      <td>6000.0</td>\n",
              "      <td>8392.0</td>\n",
              "      <td>10925.0</td>\n",
              "      <td>14579.0</td>\n",
              "      <td>185920.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>G annual</th>\n",
              "      <td>119549.0</td>\n",
              "      <td>1104.743879</td>\n",
              "      <td>502.432011</td>\n",
              "      <td>200.0</td>\n",
              "      <td>775.0</td>\n",
              "      <td>997.0</td>\n",
              "      <td>1302.0</td>\n",
              "      <td>3999.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               count           mean            std       min       25%  \\\n",
              "SF          119549.0    2122.321943     850.684704       0.0    1525.0   \n",
              "Floors      119549.0       1.628777       0.463201       0.0       1.0   \n",
              "Year Built  119549.0    1962.298739      26.133081    1800.0    1950.0   \n",
              "Value       119549.0  219452.265841  162045.070298  100000.0  125300.0   \n",
              "E annual    119549.0   12419.001723    6050.031002    6000.0    8392.0   \n",
              "G annual    119549.0    1104.743879     502.432011     200.0     775.0   \n",
              "\n",
              "                 50%       75%        max  \n",
              "SF            1945.0    2514.0    14788.0  \n",
              "Floors           2.0       2.0        4.0  \n",
              "Year Built    1962.0    1983.0     2014.0  \n",
              "Value       165300.0  253500.0  3663000.0  \n",
              "E annual     10925.0   14579.0   185920.0  \n",
              "G annual       997.0    1302.0     3999.0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqc11UA17sTL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#sample dataset (10% of full data) to test parameter tuning with\n",
        "#uncomment to run\n",
        "#dataset = dataset.sample(frac=0.1, random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbMctO5j7sTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#split data into train/test sets 80%/20%\n",
        "train_dataset = dataset.sample(frac=0.8,random_state=0)\n",
        "test_dataset = dataset.drop(train_dataset.index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASfzQ9Ns7sTP",
        "colab_type": "code",
        "outputId": "80ebfab0-1367-463f-9477-021ecd49b121",
        "colab": {}
      },
      "source": [
        "#creates training data stats \n",
        "train_stats = train_dataset.describe()\n",
        "train_stats.pop(\"G annual\")\n",
        "train_stats = train_stats.transpose()\n",
        "\n",
        "#save train stats for norm. function\n",
        "scaler_filename = \"trainPredGasScaler.save\"\n",
        "joblib.dump(train_stats, scaler_filename)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['trainPredGasScaler.save']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKeQL0EV7sTS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#train_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjEiACGr7sTU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creates train and test datasets target variable: Annual Natural Gas Usage\n",
        "#and removes target variable from feature variable dataset\n",
        "train_labels = train_dataset.pop('G annual')\n",
        "test_labels = test_dataset.pop('G annual')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhirGxvt7sTW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to normalize train and test datasets to dist. range from train data\n",
        "def norm(x):\n",
        "    return (x - train_stats['mean']) / train_stats['std']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jgpkpcw7sTY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#normalized train and test datasets\n",
        "normed_train_data = norm(train_dataset)\n",
        "normed_test_data = norm(test_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlEZ6zJS7sTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Deep Learning model, 8 layers deep, 2 fully connected layers\n",
        "#can adjust optimizer by commenting/uncommeting 'optimizer' variable\n",
        "#loss func. set to highly penalize model for large errors\n",
        "\n",
        "def build_model():\n",
        "  model = keras.Sequential([\n",
        "    layers.Dense(256, activation='relu', input_shape=[len(train_dataset.keys())]),\n",
        "    #layers.Dropout(0.25),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.15),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.15),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dropout(0.15),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dropout(0.15),\n",
        "    layers.Dense(16, activation='relu'),\n",
        "    layers.Dropout(0.15),\n",
        "    #layers.Dense(8, activation='relu'),\n",
        "    layers.Dense(1)\n",
        "  ])\n",
        "\n",
        "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "  #optimizer = tf.keras.optimizers.Adam(lr=0.001)\n",
        "\n",
        "  model.compile(loss='mean_squared_logarithmic_error',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mae', 'mse'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKlGuCis7sTd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calls ML model and assigns it to the variable 'model'\n",
        "model = build_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18rU-f7z7sTf",
        "colab_type": "code",
        "outputId": "54854158-ac11-4ba5-ef22-b58bf34c11c9",
        "colab": {}
      },
      "source": [
        "# The patience parameter is the amount of epochs to check for improvement\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='loss', patience=50, restore_best_weights=True)\n",
        "\n",
        "model.fit(normed_train_data, train_labels, epochs=1000, \n",
        "          validation_split = 0.2, verbose=2, \n",
        "          callbacks=[early_stop])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 76511 samples, validate on 19128 samples\n",
            "Epoch 1/1000\n",
            "76511/76511 - 7s - loss: 0.4010 - mae: 348.5424 - mse: 231476.6562 - val_loss: 0.1090 - val_mae: 275.4754 - val_mse: 151671.9688\n",
            "Epoch 2/1000\n",
            "76511/76511 - 6s - loss: 0.1445 - mae: 319.4567 - mse: 189560.4688 - val_loss: 0.1112 - val_mae: 278.0058 - val_mse: 153963.0469\n",
            "Epoch 3/1000\n",
            "76511/76511 - 6s - loss: 0.1430 - mae: 317.0651 - mse: 186664.0469 - val_loss: 0.1049 - val_mae: 269.7525 - val_mse: 144944.9375\n",
            "Epoch 4/1000\n",
            "76511/76511 - 6s - loss: 0.1417 - mae: 315.6755 - mse: 185499.6875 - val_loss: 0.1084 - val_mae: 276.3453 - val_mse: 156307.0781\n",
            "Epoch 5/1000\n",
            "76511/76511 - 6s - loss: 0.1409 - mae: 314.1501 - mse: 184858.7344 - val_loss: 0.1041 - val_mae: 268.6554 - val_mse: 143662.5312\n",
            "Epoch 6/1000\n",
            "76511/76511 - 6s - loss: 0.1391 - mae: 312.4812 - mse: 182504.2188 - val_loss: 0.1071 - val_mae: 272.5202 - val_mse: 143028.3281\n",
            "Epoch 7/1000\n",
            "76511/76511 - 6s - loss: 0.1381 - mae: 311.2811 - mse: 180637.7500 - val_loss: 0.1060 - val_mae: 272.9185 - val_mse: 152294.4844\n",
            "Epoch 8/1000\n",
            "76511/76511 - 6s - loss: 0.1369 - mae: 309.5503 - mse: 178538.7031 - val_loss: 0.1116 - val_mae: 276.9226 - val_mse: 143278.0938\n",
            "Epoch 9/1000\n",
            "76511/76511 - 6s - loss: 0.1372 - mae: 309.7646 - mse: 179184.4219 - val_loss: 0.1034 - val_mae: 268.0845 - val_mse: 144678.9531\n",
            "Epoch 10/1000\n",
            "76511/76511 - 6s - loss: 0.1366 - mae: 308.5318 - mse: 178082.4688 - val_loss: 0.1066 - val_mae: 270.7944 - val_mse: 141934.3438\n",
            "Epoch 11/1000\n",
            "76511/76511 - 7s - loss: 0.1360 - mae: 308.6402 - mse: 177690.7812 - val_loss: 0.1044 - val_mae: 267.6151 - val_mse: 138888.6719\n",
            "Epoch 12/1000\n",
            "76511/76511 - 6s - loss: 0.1352 - mae: 307.3156 - mse: 176441.3438 - val_loss: 0.1035 - val_mae: 266.3170 - val_mse: 139524.0469\n",
            "Epoch 13/1000\n",
            "76511/76511 - 6s - loss: 0.1350 - mae: 307.0095 - mse: 177203.2500 - val_loss: 0.1034 - val_mae: 266.3300 - val_mse: 139999.9688\n",
            "Epoch 14/1000\n",
            "76511/76511 - 6s - loss: 0.1340 - mae: 305.7720 - mse: 175748.4844 - val_loss: 0.1040 - val_mae: 269.3830 - val_mse: 147779.5000\n",
            "Epoch 15/1000\n",
            "76511/76511 - 6s - loss: 0.1327 - mae: 304.5834 - mse: 173986.8906 - val_loss: 0.1026 - val_mae: 265.4966 - val_mse: 138156.2656\n",
            "Epoch 16/1000\n",
            "76511/76511 - 6s - loss: 0.1331 - mae: 304.2496 - mse: 173306.7500 - val_loss: 0.1024 - val_mae: 265.4283 - val_mse: 140328.9219\n",
            "Epoch 17/1000\n",
            "76511/76511 - 6s - loss: 0.1319 - mae: 303.6979 - mse: 173092.1094 - val_loss: 0.1018 - val_mae: 264.8771 - val_mse: 140461.4062\n",
            "Epoch 18/1000\n",
            "76511/76511 - 7s - loss: 0.1316 - mae: 302.9615 - mse: 172813.6406 - val_loss: 0.1052 - val_mae: 267.7195 - val_mse: 137819.0156\n",
            "Epoch 19/1000\n",
            "76511/76511 - 7s - loss: 0.1314 - mae: 302.5154 - mse: 171889.2188 - val_loss: 0.1045 - val_mae: 271.1816 - val_mse: 151746.3438\n",
            "Epoch 20/1000\n",
            "76511/76511 - 8s - loss: 0.1300 - mae: 301.7454 - mse: 170873.3750 - val_loss: 0.1040 - val_mae: 266.9240 - val_mse: 139452.8750\n",
            "Epoch 21/1000\n",
            "76511/76511 - 7s - loss: 0.1303 - mae: 300.5032 - mse: 170663.9531 - val_loss: 0.1019 - val_mae: 265.7408 - val_mse: 140988.2031\n",
            "Epoch 22/1000\n",
            "76511/76511 - 7s - loss: 0.1291 - mae: 299.9760 - mse: 170126.2656 - val_loss: 0.1040 - val_mae: 267.9277 - val_mse: 142069.5938\n",
            "Epoch 23/1000\n",
            "76511/76511 - 7s - loss: 0.1285 - mae: 299.9730 - mse: 170036.2031 - val_loss: 0.1033 - val_mae: 265.7533 - val_mse: 138229.6719\n",
            "Epoch 24/1000\n",
            "76511/76511 - 7s - loss: 0.1282 - mae: 298.7458 - mse: 168745.8281 - val_loss: 0.1013 - val_mae: 264.9783 - val_mse: 141621.9844\n",
            "Epoch 25/1000\n",
            "76511/76511 - 7s - loss: 0.1283 - mae: 298.2930 - mse: 169012.3281 - val_loss: 0.1020 - val_mae: 265.2094 - val_mse: 141683.6719\n",
            "Epoch 26/1000\n",
            "76511/76511 - 7s - loss: 0.1278 - mae: 298.4824 - mse: 169298.8281 - val_loss: 0.1020 - val_mae: 265.6427 - val_mse: 144336.5781\n",
            "Epoch 27/1000\n",
            "76511/76511 - 7s - loss: 0.1275 - mae: 298.3672 - mse: 168522.7344 - val_loss: 0.1023 - val_mae: 265.9411 - val_mse: 142894.2656\n",
            "Epoch 28/1000\n",
            "76511/76511 - 7s - loss: 0.1268 - mae: 297.6996 - mse: 168104.2188 - val_loss: 0.1028 - val_mae: 267.8105 - val_mse: 146468.6875\n",
            "Epoch 29/1000\n",
            "76511/76511 - 7s - loss: 0.1268 - mae: 297.2016 - mse: 167064.8750 - val_loss: 0.1031 - val_mae: 265.2447 - val_mse: 137246.2500\n",
            "Epoch 30/1000\n",
            "76511/76511 - 7s - loss: 0.1264 - mae: 296.2758 - mse: 166947.1562 - val_loss: 0.1018 - val_mae: 266.0634 - val_mse: 144996.4375\n",
            "Epoch 31/1000\n",
            "76511/76511 - 7s - loss: 0.1263 - mae: 296.6802 - mse: 167166.9531 - val_loss: 0.1056 - val_mae: 267.6640 - val_mse: 137272.0625\n",
            "Epoch 32/1000\n",
            "76511/76511 - 7s - loss: 0.1260 - mae: 295.9824 - mse: 166547.7969 - val_loss: 0.1022 - val_mae: 267.1206 - val_mse: 146043.8438\n",
            "Epoch 33/1000\n",
            "76511/76511 - 7s - loss: 0.1257 - mae: 294.9207 - mse: 166009.7344 - val_loss: 0.1016 - val_mae: 264.2467 - val_mse: 139049.2344\n",
            "Epoch 34/1000\n",
            "76511/76511 - 7s - loss: 0.1250 - mae: 295.3782 - mse: 166534.5469 - val_loss: 0.1013 - val_mae: 263.5124 - val_mse: 137905.6562\n",
            "Epoch 35/1000\n",
            "76511/76511 - 7s - loss: 0.1245 - mae: 294.5502 - mse: 165502.5469 - val_loss: 0.1044 - val_mae: 270.7473 - val_mse: 151295.5312\n",
            "Epoch 36/1000\n",
            "76511/76511 - 7s - loss: 0.1242 - mae: 294.3714 - mse: 165054.1562 - val_loss: 0.1030 - val_mae: 268.3208 - val_mse: 147634.4219\n",
            "Epoch 37/1000\n",
            "76511/76511 - 7s - loss: 0.1243 - mae: 294.3169 - mse: 165127.9688 - val_loss: 0.1016 - val_mae: 265.5335 - val_mse: 144233.2031\n",
            "Epoch 38/1000\n",
            "76511/76511 - 7s - loss: 0.1242 - mae: 293.8426 - mse: 164299.9062 - val_loss: 0.1037 - val_mae: 266.2623 - val_mse: 139018.9688\n",
            "Epoch 39/1000\n",
            "76511/76511 - 7s - loss: 0.1239 - mae: 293.3173 - mse: 164586.5156 - val_loss: 0.1011 - val_mae: 263.5170 - val_mse: 138752.9219\n",
            "Epoch 40/1000\n",
            "76511/76511 - 7s - loss: 0.1234 - mae: 292.2857 - mse: 163503.1250 - val_loss: 0.1033 - val_mae: 265.7594 - val_mse: 139089.8438\n",
            "Epoch 41/1000\n",
            "76511/76511 - 7s - loss: 0.1238 - mae: 293.3774 - mse: 164781.8906 - val_loss: 0.1019 - val_mae: 264.1547 - val_mse: 137404.8594\n",
            "Epoch 42/1000\n",
            "76511/76511 - 7s - loss: 0.1230 - mae: 292.6066 - mse: 163196.1406 - val_loss: 0.1042 - val_mae: 267.1252 - val_mse: 139457.1719\n",
            "Epoch 43/1000\n",
            "76511/76511 - 7s - loss: 0.1233 - mae: 292.3320 - mse: 163420.9375 - val_loss: 0.1047 - val_mae: 267.2992 - val_mse: 137276.4844\n",
            "Epoch 44/1000\n",
            "76511/76511 - 7s - loss: 0.1224 - mae: 291.5648 - mse: 162503.2969 - val_loss: 0.1020 - val_mae: 266.6947 - val_mse: 144911.7656\n",
            "Epoch 45/1000\n",
            "76511/76511 - 7s - loss: 0.1227 - mae: 292.5093 - mse: 163947.2344 - val_loss: 0.1017 - val_mae: 264.8468 - val_mse: 141068.0781\n",
            "Epoch 46/1000\n",
            "76511/76511 - 7s - loss: 0.1227 - mae: 291.6317 - mse: 163467.4844 - val_loss: 0.1021 - val_mae: 266.6295 - val_mse: 145069.1094\n",
            "Epoch 47/1000\n",
            "76511/76511 - 7s - loss: 0.1223 - mae: 291.5157 - mse: 162699.3281 - val_loss: 0.1035 - val_mae: 265.7770 - val_mse: 137517.1719\n",
            "Epoch 48/1000\n",
            "76511/76511 - 7s - loss: 0.1228 - mae: 291.7148 - mse: 163228.5469 - val_loss: 0.1025 - val_mae: 268.0211 - val_mse: 146957.9062\n",
            "Epoch 49/1000\n",
            "76511/76511 - 7s - loss: 0.1217 - mae: 291.2401 - mse: 162374.3906 - val_loss: 0.1040 - val_mae: 266.4958 - val_mse: 137960.8125\n",
            "Epoch 50/1000\n",
            "76511/76511 - 7s - loss: 0.1212 - mae: 290.7029 - mse: 162062.7656 - val_loss: 0.1025 - val_mae: 264.9803 - val_mse: 138636.4844\n",
            "Epoch 51/1000\n",
            "76511/76511 - 7s - loss: 0.1220 - mae: 290.8915 - mse: 161867.5625 - val_loss: 0.1041 - val_mae: 266.5438 - val_mse: 137094.7969\n",
            "Epoch 52/1000\n",
            "76511/76511 - 7s - loss: 0.1217 - mae: 290.9468 - mse: 162653.6094 - val_loss: 0.1022 - val_mae: 265.5667 - val_mse: 143327.3594\n",
            "Epoch 53/1000\n",
            "76511/76511 - 7s - loss: 0.1217 - mae: 290.7249 - mse: 162808.5312 - val_loss: 0.1034 - val_mae: 265.5085 - val_mse: 137085.1562\n",
            "Epoch 54/1000\n",
            "76511/76511 - 7s - loss: 0.1211 - mae: 290.0291 - mse: 160544.7812 - val_loss: 0.1027 - val_mae: 264.8230 - val_mse: 139472.7656\n",
            "Epoch 55/1000\n",
            "76511/76511 - 7s - loss: 0.1209 - mae: 289.7346 - mse: 161520.5938 - val_loss: 0.1031 - val_mae: 266.0534 - val_mse: 141969.4375\n",
            "Epoch 56/1000\n",
            "76511/76511 - 8s - loss: 0.1212 - mae: 289.9377 - mse: 161952.9062 - val_loss: 0.1011 - val_mae: 264.0795 - val_mse: 141273.2500\n",
            "Epoch 57/1000\n",
            "76511/76511 - 8s - loss: 0.1205 - mae: 289.7159 - mse: 161648.5156 - val_loss: 0.1020 - val_mae: 263.6809 - val_mse: 136600.0000\n",
            "Epoch 58/1000\n",
            "76511/76511 - 8s - loss: 0.1200 - mae: 288.6682 - mse: 160411.4219 - val_loss: 0.1023 - val_mae: 264.9698 - val_mse: 139514.0469\n",
            "Epoch 59/1000\n",
            "76511/76511 - 7s - loss: 0.1200 - mae: 288.6183 - mse: 160338.0469 - val_loss: 0.1020 - val_mae: 263.7467 - val_mse: 136865.9062\n",
            "Epoch 60/1000\n",
            "76511/76511 - 7s - loss: 0.1204 - mae: 289.0627 - mse: 161448.6875 - val_loss: 0.1020 - val_mae: 264.4787 - val_mse: 138600.3281\n",
            "Epoch 61/1000\n",
            "76511/76511 - 7s - loss: 0.1202 - mae: 288.9810 - mse: 160982.4062 - val_loss: 0.1056 - val_mae: 270.2436 - val_mse: 144255.5625\n",
            "Epoch 62/1000\n",
            "76511/76511 - 7s - loss: 0.1193 - mae: 287.9320 - mse: 159417.0312 - val_loss: 0.1019 - val_mae: 265.4995 - val_mse: 141726.1250\n",
            "Epoch 63/1000\n",
            "76511/76511 - 7s - loss: 0.1200 - mae: 288.7758 - mse: 160404.9062 - val_loss: 0.1047 - val_mae: 268.3111 - val_mse: 140746.4844\n",
            "Epoch 64/1000\n",
            "76511/76511 - 7s - loss: 0.1193 - mae: 287.5862 - mse: 159003.5156 - val_loss: 0.1044 - val_mae: 271.3362 - val_mse: 152989.4219\n",
            "Epoch 65/1000\n",
            "76511/76511 - 7s - loss: 0.1187 - mae: 287.4248 - mse: 159061.5469 - val_loss: 0.1022 - val_mae: 264.7845 - val_mse: 139898.6719\n",
            "Epoch 66/1000\n",
            "76511/76511 - 7s - loss: 0.1197 - mae: 288.6144 - mse: 160116.6250 - val_loss: 0.1029 - val_mae: 264.9624 - val_mse: 137845.7188\n",
            "Epoch 67/1000\n",
            "76511/76511 - 7s - loss: 0.1193 - mae: 287.9481 - mse: 159473.5625 - val_loss: 0.1020 - val_mae: 265.9429 - val_mse: 144314.2344\n",
            "Epoch 68/1000\n",
            "76511/76511 - 7s - loss: 0.1193 - mae: 288.0363 - mse: 159176.3594 - val_loss: 0.1038 - val_mae: 265.8305 - val_mse: 138489.4844\n",
            "Epoch 69/1000\n",
            "76511/76511 - 7s - loss: 0.1185 - mae: 287.2782 - mse: 159204.9375 - val_loss: 0.1016 - val_mae: 263.8672 - val_mse: 138955.5156\n",
            "Epoch 70/1000\n",
            "76511/76511 - 7s - loss: 0.1184 - mae: 286.9425 - mse: 158165.6875 - val_loss: 0.1018 - val_mae: 263.8379 - val_mse: 138110.1875\n",
            "Epoch 71/1000\n",
            "76511/76511 - 7s - loss: 0.1181 - mae: 286.0705 - mse: 158496.2031 - val_loss: 0.1012 - val_mae: 263.8299 - val_mse: 139691.2031\n",
            "Epoch 72/1000\n",
            "76511/76511 - 7s - loss: 0.1182 - mae: 286.3732 - mse: 158267.3438 - val_loss: 0.1030 - val_mae: 268.1039 - val_mse: 147587.3594\n",
            "Epoch 73/1000\n",
            "76511/76511 - 7s - loss: 0.1177 - mae: 285.9944 - mse: 158197.8281 - val_loss: 0.1025 - val_mae: 265.5851 - val_mse: 140813.2500\n",
            "Epoch 74/1000\n",
            "76511/76511 - 7s - loss: 0.1186 - mae: 287.0056 - mse: 159238.2812 - val_loss: 0.1029 - val_mae: 264.6230 - val_mse: 137554.2812\n",
            "Epoch 75/1000\n",
            "76511/76511 - 7s - loss: 0.1172 - mae: 285.3977 - mse: 156673.6250 - val_loss: 0.1018 - val_mae: 263.3846 - val_mse: 138233.7500\n",
            "Epoch 76/1000\n",
            "76511/76511 - 8s - loss: 0.1181 - mae: 286.0921 - mse: 158548.2031 - val_loss: 0.1025 - val_mae: 265.1852 - val_mse: 141832.0625\n",
            "Epoch 77/1000\n",
            "76511/76511 - 8s - loss: 0.1177 - mae: 285.5695 - mse: 157794.8594 - val_loss: 0.1016 - val_mae: 263.7767 - val_mse: 138058.4844\n",
            "Epoch 78/1000\n",
            "76511/76511 - 8s - loss: 0.1177 - mae: 286.4733 - mse: 157626.6875 - val_loss: 0.1033 - val_mae: 269.9677 - val_mse: 150590.4219\n",
            "Epoch 79/1000\n",
            "76511/76511 - 8s - loss: 0.1178 - mae: 285.4837 - mse: 157546.7969 - val_loss: 0.1051 - val_mae: 269.0747 - val_mse: 141299.7969\n",
            "Epoch 80/1000\n",
            "76511/76511 - 8s - loss: 0.1177 - mae: 285.5005 - mse: 157262.6719 - val_loss: 0.1023 - val_mae: 267.0876 - val_mse: 145860.0312\n",
            "Epoch 81/1000\n",
            "76511/76511 - 7s - loss: 0.1180 - mae: 286.1569 - mse: 158020.0156 - val_loss: 0.1029 - val_mae: 264.8634 - val_mse: 138362.5156\n",
            "Epoch 82/1000\n",
            "76511/76511 - 8s - loss: 0.1174 - mae: 285.7812 - mse: 158006.5938 - val_loss: 0.1021 - val_mae: 264.2698 - val_mse: 137595.5625\n",
            "Epoch 83/1000\n",
            "76511/76511 - 7s - loss: 0.1178 - mae: 285.7200 - mse: 158194.8594 - val_loss: 0.1014 - val_mae: 263.2803 - val_mse: 137564.1562\n",
            "Epoch 84/1000\n",
            "76511/76511 - 9s - loss: 0.1169 - mae: 284.7054 - mse: 156732.9531 - val_loss: 0.1037 - val_mae: 266.5943 - val_mse: 139149.7812\n",
            "Epoch 85/1000\n",
            "76511/76511 - 7s - loss: 0.1166 - mae: 285.0573 - mse: 157117.2188 - val_loss: 0.1022 - val_mae: 264.8404 - val_mse: 139120.8438\n",
            "Epoch 86/1000\n",
            "76511/76511 - 7s - loss: 0.1179 - mae: 285.6732 - mse: 157517.7656 - val_loss: 0.1017 - val_mae: 265.0445 - val_mse: 141951.3906\n",
            "Epoch 87/1000\n",
            "76511/76511 - 7s - loss: 0.1170 - mae: 284.4410 - mse: 156395.1562 - val_loss: 0.1034 - val_mae: 265.7664 - val_mse: 138786.7812\n",
            "Epoch 88/1000\n",
            "76511/76511 - 7s - loss: 0.1167 - mae: 284.5319 - mse: 156477.5625 - val_loss: 0.1027 - val_mae: 264.2215 - val_mse: 137174.6562\n",
            "Epoch 89/1000\n",
            "76511/76511 - 7s - loss: 0.1170 - mae: 284.3449 - mse: 156640.9844 - val_loss: 0.1026 - val_mae: 267.8055 - val_mse: 147609.0625\n",
            "Epoch 90/1000\n",
            "76511/76511 - 7s - loss: 0.1173 - mae: 285.1248 - mse: 156779.7031 - val_loss: 0.1016 - val_mae: 263.8820 - val_mse: 139758.3438\n",
            "Epoch 91/1000\n",
            "76511/76511 - 7s - loss: 0.1173 - mae: 285.5360 - mse: 157470.1562 - val_loss: 0.1017 - val_mae: 263.2549 - val_mse: 137779.5312\n",
            "Epoch 92/1000\n",
            "76511/76511 - 7s - loss: 0.1170 - mae: 284.6885 - mse: 156797.4062 - val_loss: 0.1019 - val_mae: 264.4681 - val_mse: 138574.1406\n",
            "Epoch 93/1000\n",
            "76511/76511 - 9s - loss: 0.1168 - mae: 284.7252 - mse: 157036.2969 - val_loss: 0.1019 - val_mae: 264.4495 - val_mse: 140009.4531\n",
            "Epoch 94/1000\n",
            "76511/76511 - 8s - loss: 0.1167 - mae: 284.7903 - mse: 156516.5156 - val_loss: 0.1025 - val_mae: 264.0054 - val_mse: 137993.6562\n",
            "Epoch 95/1000\n",
            "76511/76511 - 8s - loss: 0.1169 - mae: 284.4632 - mse: 156741.0000 - val_loss: 0.1020 - val_mae: 264.3232 - val_mse: 138904.1094\n",
            "Epoch 96/1000\n",
            "76511/76511 - 8s - loss: 0.1171 - mae: 285.0761 - mse: 157565.5156 - val_loss: 0.1034 - val_mae: 265.5688 - val_mse: 137537.8906\n",
            "Epoch 97/1000\n",
            "76511/76511 - 9s - loss: 0.1168 - mae: 285.2307 - mse: 156827.2031 - val_loss: 0.1016 - val_mae: 263.2935 - val_mse: 137652.2188\n",
            "Epoch 98/1000\n",
            "76511/76511 - 8s - loss: 0.1165 - mae: 284.1010 - mse: 155606.2812 - val_loss: 0.1032 - val_mae: 268.3849 - val_mse: 147977.0000\n",
            "Epoch 99/1000\n",
            "76511/76511 - 8s - loss: 0.1161 - mae: 283.7945 - mse: 155433.9219 - val_loss: 0.1026 - val_mae: 265.4849 - val_mse: 140575.3906\n",
            "Epoch 100/1000\n",
            "76511/76511 - 10s - loss: 0.1166 - mae: 283.8809 - mse: 156232.8750 - val_loss: 0.1030 - val_mae: 265.3605 - val_mse: 137920.7031\n",
            "Epoch 101/1000\n",
            "76511/76511 - 8s - loss: 0.1166 - mae: 284.5061 - mse: 156931.0625 - val_loss: 0.1038 - val_mae: 265.9978 - val_mse: 137982.4375\n",
            "Epoch 102/1000\n",
            "76511/76511 - 7s - loss: 0.1162 - mae: 283.7639 - mse: 155690.7969 - val_loss: 0.1037 - val_mae: 266.4324 - val_mse: 139157.0312\n",
            "Epoch 103/1000\n",
            "76511/76511 - 8s - loss: 0.1161 - mae: 283.7003 - mse: 155424.2031 - val_loss: 0.1021 - val_mae: 264.3832 - val_mse: 138511.0156\n",
            "Epoch 104/1000\n",
            "76511/76511 - 8s - loss: 0.1161 - mae: 283.6207 - mse: 156057.7344 - val_loss: 0.1022 - val_mae: 263.9129 - val_mse: 137849.1406\n",
            "Epoch 105/1000\n",
            "76511/76511 - 7s - loss: 0.1162 - mae: 283.9073 - mse: 156142.9219 - val_loss: 0.1020 - val_mae: 264.0688 - val_mse: 140250.8281\n",
            "Epoch 106/1000\n",
            "76511/76511 - 7s - loss: 0.1162 - mae: 283.6348 - mse: 155994.1094 - val_loss: 0.1022 - val_mae: 266.7470 - val_mse: 144693.0156\n",
            "Epoch 107/1000\n",
            "76511/76511 - 8s - loss: 0.1164 - mae: 283.9207 - mse: 155899.8750 - val_loss: 0.1020 - val_mae: 264.5146 - val_mse: 140983.8438\n",
            "Epoch 108/1000\n",
            "76511/76511 - 8s - loss: 0.1165 - mae: 283.8528 - mse: 155963.3750 - val_loss: 0.1033 - val_mae: 266.2078 - val_mse: 141042.4062\n",
            "Epoch 109/1000\n",
            "76511/76511 - 8s - loss: 0.1159 - mae: 283.2700 - mse: 154911.1250 - val_loss: 0.1024 - val_mae: 264.6414 - val_mse: 139260.5781\n",
            "Epoch 110/1000\n",
            "76511/76511 - 7s - loss: 0.1161 - mae: 283.9739 - mse: 156020.3906 - val_loss: 0.1057 - val_mae: 269.4612 - val_mse: 142073.2031\n",
            "Epoch 111/1000\n",
            "76511/76511 - 7s - loss: 0.1160 - mae: 283.4744 - mse: 156444.6875 - val_loss: 0.1017 - val_mae: 263.4456 - val_mse: 138318.8438\n",
            "Epoch 112/1000\n",
            "76511/76511 - 7s - loss: 0.1161 - mae: 283.6184 - mse: 156070.6875 - val_loss: 0.1022 - val_mae: 264.8557 - val_mse: 139093.7188\n",
            "Epoch 113/1000\n",
            "76511/76511 - 8s - loss: 0.1157 - mae: 283.1212 - mse: 155368.3594 - val_loss: 0.1023 - val_mae: 265.1235 - val_mse: 140416.7656\n",
            "Epoch 114/1000\n",
            "76511/76511 - 7s - loss: 0.1160 - mae: 283.3869 - mse: 156142.1250 - val_loss: 0.1026 - val_mae: 264.5349 - val_mse: 138342.5156\n",
            "Epoch 115/1000\n",
            "76511/76511 - 8s - loss: 0.1159 - mae: 283.5709 - mse: 155835.4062 - val_loss: 0.1018 - val_mae: 265.0395 - val_mse: 141578.3594\n",
            "Epoch 116/1000\n",
            "76511/76511 - 9s - loss: 0.1160 - mae: 283.3350 - mse: 155646.3906 - val_loss: 0.1014 - val_mae: 264.1395 - val_mse: 140041.4531\n",
            "Epoch 117/1000\n",
            "76511/76511 - 7s - loss: 0.1152 - mae: 282.6158 - mse: 154419.1719 - val_loss: 0.1017 - val_mae: 265.2300 - val_mse: 142323.5781\n",
            "Epoch 118/1000\n",
            "76511/76511 - 8s - loss: 0.1160 - mae: 283.7231 - mse: 155485.8438 - val_loss: 0.1025 - val_mae: 264.0867 - val_mse: 137165.3594\n",
            "Epoch 119/1000\n",
            "76511/76511 - 9s - loss: 0.1156 - mae: 283.2080 - mse: 155364.6875 - val_loss: 0.1015 - val_mae: 264.3683 - val_mse: 140967.4531\n",
            "Epoch 120/1000\n",
            "76511/76511 - 8s - loss: 0.1159 - mae: 283.3443 - mse: 156327.6719 - val_loss: 0.1015 - val_mae: 265.5265 - val_mse: 143692.8125\n",
            "Epoch 121/1000\n",
            "76511/76511 - 7s - loss: 0.1154 - mae: 283.0440 - mse: 155032.9688 - val_loss: 0.1018 - val_mae: 264.1359 - val_mse: 139627.5156\n",
            "Epoch 122/1000\n",
            "76511/76511 - 8s - loss: 0.1159 - mae: 283.4353 - mse: 156262.5000 - val_loss: 0.1020 - val_mae: 264.9368 - val_mse: 141929.8594\n",
            "Epoch 123/1000\n",
            "76511/76511 - 8s - loss: 0.1150 - mae: 282.6479 - mse: 154894.1406 - val_loss: 0.1022 - val_mae: 264.8677 - val_mse: 141181.4375\n",
            "Epoch 124/1000\n",
            "76511/76511 - 8s - loss: 0.1153 - mae: 282.1637 - mse: 154822.0938 - val_loss: 0.1025 - val_mae: 266.7086 - val_mse: 145429.3125\n",
            "Epoch 125/1000\n",
            "76511/76511 - 7s - loss: 0.1146 - mae: 282.0143 - mse: 154127.4062 - val_loss: 0.1014 - val_mae: 264.4536 - val_mse: 140453.7812\n",
            "Epoch 126/1000\n",
            "76511/76511 - 8s - loss: 0.1148 - mae: 282.0850 - mse: 154525.7500 - val_loss: 0.1015 - val_mae: 264.3841 - val_mse: 141037.1875\n",
            "Epoch 127/1000\n",
            "76511/76511 - 7s - loss: 0.1143 - mae: 281.5837 - mse: 153787.4844 - val_loss: 0.1020 - val_mae: 265.1032 - val_mse: 142250.8750\n",
            "Epoch 128/1000\n",
            "76511/76511 - 7s - loss: 0.1141 - mae: 281.4049 - mse: 153952.4688 - val_loss: 0.1017 - val_mae: 264.7304 - val_mse: 141771.1562\n",
            "Epoch 129/1000\n",
            "76511/76511 - 8s - loss: 0.1146 - mae: 282.3332 - mse: 154872.4844 - val_loss: 0.1012 - val_mae: 263.9746 - val_mse: 139704.6875\n",
            "Epoch 130/1000\n",
            "76511/76511 - 7s - loss: 0.1141 - mae: 281.1667 - mse: 154261.3594 - val_loss: 0.1025 - val_mae: 264.8077 - val_mse: 138993.0312\n",
            "Epoch 131/1000\n",
            "76511/76511 - 7s - loss: 0.1146 - mae: 282.2921 - mse: 154818.9844 - val_loss: 0.1018 - val_mae: 264.1432 - val_mse: 138704.3906\n",
            "Epoch 132/1000\n",
            "76511/76511 - 7s - loss: 0.1143 - mae: 281.4417 - mse: 154423.7344 - val_loss: 0.1019 - val_mae: 263.9803 - val_mse: 139236.6094\n",
            "Epoch 133/1000\n",
            "76511/76511 - 7s - loss: 0.1142 - mae: 281.9859 - mse: 155533.4219 - val_loss: 0.1024 - val_mae: 265.0940 - val_mse: 138552.0469\n",
            "Epoch 134/1000\n",
            "76511/76511 - 7s - loss: 0.1139 - mae: 281.3241 - mse: 153473.3750 - val_loss: 0.1019 - val_mae: 263.9012 - val_mse: 138085.5000\n",
            "Epoch 135/1000\n",
            "76511/76511 - 7s - loss: 0.1134 - mae: 281.1622 - mse: 153268.3438 - val_loss: 0.1014 - val_mae: 264.0992 - val_mse: 139188.2500\n",
            "Epoch 136/1000\n",
            "76511/76511 - 8s - loss: 0.1145 - mae: 281.9117 - mse: 155599.7344 - val_loss: 0.1028 - val_mae: 264.2051 - val_mse: 136509.4219\n",
            "Epoch 137/1000\n",
            "76511/76511 - 8s - loss: 0.1140 - mae: 281.7132 - mse: 154347.1875 - val_loss: 0.1017 - val_mae: 264.0629 - val_mse: 139142.5781\n",
            "Epoch 138/1000\n",
            "76511/76511 - 8s - loss: 0.1138 - mae: 281.3361 - mse: 154312.3906 - val_loss: 0.1021 - val_mae: 264.9326 - val_mse: 140517.0469\n",
            "Epoch 139/1000\n",
            "76511/76511 - 7s - loss: 0.1143 - mae: 281.9183 - mse: 155295.7500 - val_loss: 0.1019 - val_mae: 264.2108 - val_mse: 139227.8594\n",
            "Epoch 140/1000\n",
            "76511/76511 - 8s - loss: 0.1136 - mae: 281.1825 - mse: 153540.5469 - val_loss: 0.1028 - val_mae: 267.4501 - val_mse: 145534.7188\n",
            "Epoch 141/1000\n",
            "76511/76511 - 9s - loss: 0.1130 - mae: 280.0255 - mse: 152231.3906 - val_loss: 0.1019 - val_mae: 263.7718 - val_mse: 136705.4531\n",
            "Epoch 142/1000\n",
            "76511/76511 - 10s - loss: 0.1138 - mae: 281.0915 - mse: 153518.9844 - val_loss: 0.1035 - val_mae: 265.6949 - val_mse: 137935.2500\n",
            "Epoch 143/1000\n",
            "76511/76511 - 8s - loss: 0.1132 - mae: 280.2289 - mse: 153044.2031 - val_loss: 0.1028 - val_mae: 266.4507 - val_mse: 144016.1250\n",
            "Epoch 144/1000\n",
            "76511/76511 - 7s - loss: 0.1133 - mae: 280.0819 - mse: 152633.6250 - val_loss: 0.1031 - val_mae: 265.4732 - val_mse: 140497.1406\n",
            "Epoch 145/1000\n",
            "76511/76511 - 7s - loss: 0.1135 - mae: 280.1836 - mse: 153461.5781 - val_loss: 0.1042 - val_mae: 266.7392 - val_mse: 137426.2969\n",
            "Epoch 146/1000\n",
            "76511/76511 - 9s - loss: 0.1133 - mae: 280.2464 - mse: 153203.1094 - val_loss: 0.1036 - val_mae: 265.7537 - val_mse: 138958.0469\n",
            "Epoch 147/1000\n",
            "76511/76511 - 7s - loss: 0.1131 - mae: 280.2821 - mse: 152734.0312 - val_loss: 0.1033 - val_mae: 265.2774 - val_mse: 138883.7500\n",
            "Epoch 148/1000\n",
            "76511/76511 - 8s - loss: 0.1130 - mae: 279.8483 - mse: 153433.4531 - val_loss: 0.1020 - val_mae: 264.1164 - val_mse: 138255.0156\n",
            "Epoch 149/1000\n",
            "76511/76511 - 8s - loss: 0.1132 - mae: 280.1580 - mse: 152808.5469 - val_loss: 0.1023 - val_mae: 265.3264 - val_mse: 141660.3281\n",
            "Epoch 150/1000\n",
            "76511/76511 - 8s - loss: 0.1136 - mae: 280.8375 - mse: 153988.8125 - val_loss: 0.1031 - val_mae: 267.6808 - val_mse: 145683.3281\n",
            "Epoch 151/1000\n",
            "76511/76511 - 8s - loss: 0.1136 - mae: 280.8396 - mse: 153313.5000 - val_loss: 0.1020 - val_mae: 266.4176 - val_mse: 145232.5938\n",
            "Epoch 152/1000\n",
            "76511/76511 - 8s - loss: 0.1132 - mae: 280.4359 - mse: 152749.0312 - val_loss: 0.1028 - val_mae: 265.2389 - val_mse: 141381.8438\n",
            "Epoch 153/1000\n",
            "76511/76511 - 8s - loss: 0.1132 - mae: 280.5683 - mse: 153278.7656 - val_loss: 0.1028 - val_mae: 264.5076 - val_mse: 137363.5781\n",
            "Epoch 154/1000\n",
            "76511/76511 - 9s - loss: 0.1133 - mae: 280.7421 - mse: 153899.4531 - val_loss: 0.1025 - val_mae: 264.4054 - val_mse: 138140.6406\n",
            "Epoch 155/1000\n",
            "76511/76511 - 9s - loss: 0.1130 - mae: 280.0309 - mse: 152756.4062 - val_loss: 0.1021 - val_mae: 263.9522 - val_mse: 137768.8125\n",
            "Epoch 156/1000\n",
            "76511/76511 - 8s - loss: 0.1132 - mae: 280.7577 - mse: 153419.2656 - val_loss: 0.1032 - val_mae: 268.9278 - val_mse: 148644.9219\n",
            "Epoch 157/1000\n",
            "76511/76511 - 7s - loss: 0.1131 - mae: 280.1938 - mse: 153051.0469 - val_loss: 0.1028 - val_mae: 265.2220 - val_mse: 139523.7344\n",
            "Epoch 158/1000\n",
            "76511/76511 - 8s - loss: 0.1129 - mae: 280.0219 - mse: 152354.2188 - val_loss: 0.1038 - val_mae: 267.1163 - val_mse: 140670.9531\n",
            "Epoch 159/1000\n",
            "76511/76511 - 7s - loss: 0.1131 - mae: 280.0213 - mse: 153044.7812 - val_loss: 0.1018 - val_mae: 264.3318 - val_mse: 139942.7344\n",
            "Epoch 160/1000\n",
            "76511/76511 - 7s - loss: 0.1130 - mae: 280.1559 - mse: 153201.3125 - val_loss: 0.1015 - val_mae: 263.9560 - val_mse: 139518.2500\n",
            "Epoch 161/1000\n",
            "76511/76511 - 8s - loss: 0.1136 - mae: 280.6923 - mse: 153905.1875 - val_loss: 0.1024 - val_mae: 264.4766 - val_mse: 137751.5625\n",
            "Epoch 162/1000\n",
            "76511/76511 - 10s - loss: 0.1127 - mae: 280.1824 - mse: 152881.2344 - val_loss: 0.1024 - val_mae: 264.5202 - val_mse: 139743.7500\n",
            "Epoch 163/1000\n",
            "76511/76511 - 8s - loss: 0.1126 - mae: 279.4097 - mse: 152243.2812 - val_loss: 0.1020 - val_mae: 265.5603 - val_mse: 142863.9375\n",
            "Epoch 164/1000\n",
            "76511/76511 - 8s - loss: 0.1126 - mae: 279.9894 - mse: 151876.8750 - val_loss: 0.1018 - val_mae: 264.5976 - val_mse: 139500.3594\n",
            "Epoch 165/1000\n",
            "76511/76511 - 8s - loss: 0.1125 - mae: 279.0439 - mse: 151325.4219 - val_loss: 0.1020 - val_mae: 264.3680 - val_mse: 139344.5938\n",
            "Epoch 166/1000\n",
            "76511/76511 - 10s - loss: 0.1125 - mae: 279.6154 - mse: 152284.1094 - val_loss: 0.1028 - val_mae: 265.3835 - val_mse: 140496.1875\n",
            "Epoch 167/1000\n",
            "76511/76511 - 9s - loss: 0.1126 - mae: 280.0358 - mse: 153254.9219 - val_loss: 0.1021 - val_mae: 264.9960 - val_mse: 142013.9062\n",
            "Epoch 168/1000\n",
            "76511/76511 - 11s - loss: 0.1132 - mae: 280.1681 - mse: 152790.7969 - val_loss: 0.1026 - val_mae: 265.7310 - val_mse: 141415.2656\n",
            "Epoch 169/1000\n",
            "76511/76511 - 8s - loss: 0.1130 - mae: 280.1113 - mse: 153066.8594 - val_loss: 0.1022 - val_mae: 264.2265 - val_mse: 139357.6562\n",
            "Epoch 170/1000\n",
            "76511/76511 - 8s - loss: 0.1131 - mae: 280.2527 - mse: 153747.8906 - val_loss: 0.1014 - val_mae: 264.4153 - val_mse: 140895.6406\n",
            "Epoch 171/1000\n",
            "76511/76511 - 10s - loss: 0.1124 - mae: 279.1968 - mse: 152255.5156 - val_loss: 0.1032 - val_mae: 266.3110 - val_mse: 139667.5938\n",
            "Epoch 172/1000\n",
            "76511/76511 - 7s - loss: 0.1129 - mae: 279.9162 - mse: 152542.2344 - val_loss: 0.1013 - val_mae: 263.5474 - val_mse: 138142.3594\n",
            "Epoch 173/1000\n",
            "76511/76511 - 8s - loss: 0.1128 - mae: 280.0582 - mse: 152826.5469 - val_loss: 0.1023 - val_mae: 266.9912 - val_mse: 145436.7188\n",
            "Epoch 174/1000\n",
            "76511/76511 - 8s - loss: 0.1130 - mae: 279.9258 - mse: 153332.3906 - val_loss: 0.1017 - val_mae: 265.1183 - val_mse: 141190.0000\n",
            "Epoch 175/1000\n",
            "76511/76511 - 7s - loss: 0.1122 - mae: 279.0965 - mse: 152598.9531 - val_loss: 0.1024 - val_mae: 264.3575 - val_mse: 137738.5156\n",
            "Epoch 176/1000\n",
            "76511/76511 - 8s - loss: 0.1125 - mae: 279.4270 - mse: 152666.8750 - val_loss: 0.1027 - val_mae: 265.2261 - val_mse: 140184.9531\n",
            "Epoch 177/1000\n",
            "76511/76511 - 8s - loss: 0.1129 - mae: 280.0357 - mse: 152844.2031 - val_loss: 0.1023 - val_mae: 266.9311 - val_mse: 145113.2500\n",
            "Epoch 178/1000\n",
            "76511/76511 - 8s - loss: 0.1127 - mae: 279.2414 - mse: 152330.0781 - val_loss: 0.1025 - val_mae: 265.0968 - val_mse: 141121.1719\n",
            "Epoch 179/1000\n",
            "76511/76511 - 9s - loss: 0.1126 - mae: 279.8806 - mse: 152419.6562 - val_loss: 0.1045 - val_mae: 268.0107 - val_mse: 142694.7344\n",
            "Epoch 180/1000\n",
            "76511/76511 - 9s - loss: 0.1122 - mae: 279.0860 - mse: 151801.0781 - val_loss: 0.1025 - val_mae: 264.4062 - val_mse: 138258.8750\n",
            "Epoch 181/1000\n",
            "76511/76511 - 9s - loss: 0.1119 - mae: 279.0872 - mse: 151543.0000 - val_loss: 0.1065 - val_mae: 271.0598 - val_mse: 144525.7656\n",
            "Epoch 182/1000\n",
            "76511/76511 - 9s - loss: 0.1120 - mae: 278.4288 - mse: 151067.7344 - val_loss: 0.1024 - val_mae: 266.5414 - val_mse: 144672.7188\n",
            "Epoch 183/1000\n",
            "76511/76511 - 9s - loss: 0.1128 - mae: 279.7545 - mse: 153128.8438 - val_loss: 0.1021 - val_mae: 265.2171 - val_mse: 141093.2500\n",
            "Epoch 184/1000\n",
            "76511/76511 - 8s - loss: 0.1124 - mae: 279.3910 - mse: 151675.9062 - val_loss: 0.1023 - val_mae: 266.3255 - val_mse: 145279.4062\n",
            "Epoch 185/1000\n",
            "76511/76511 - 8s - loss: 0.1125 - mae: 279.8342 - mse: 152739.7656 - val_loss: 0.1016 - val_mae: 264.2115 - val_mse: 140264.2969\n",
            "Epoch 186/1000\n",
            "76511/76511 - 8s - loss: 0.1126 - mae: 279.7284 - mse: 152948.5781 - val_loss: 0.1021 - val_mae: 265.6942 - val_mse: 143156.5156\n",
            "Epoch 187/1000\n",
            "76511/76511 - 8s - loss: 0.1120 - mae: 278.4779 - mse: 151457.5312 - val_loss: 0.1017 - val_mae: 264.2300 - val_mse: 140618.0469\n",
            "Epoch 188/1000\n",
            "76511/76511 - 8s - loss: 0.1126 - mae: 279.8057 - mse: 153023.1406 - val_loss: 0.1024 - val_mae: 265.5263 - val_mse: 141974.8125\n",
            "Epoch 189/1000\n",
            "76511/76511 - 8s - loss: 0.1121 - mae: 279.2907 - mse: 152198.3906 - val_loss: 0.1029 - val_mae: 266.1616 - val_mse: 142505.0000\n",
            "Epoch 190/1000\n",
            "76511/76511 - 8s - loss: 0.1124 - mae: 279.0097 - mse: 151600.1719 - val_loss: 0.1019 - val_mae: 265.8478 - val_mse: 143167.0312\n",
            "Epoch 191/1000\n",
            "76511/76511 - 8s - loss: 0.1124 - mae: 279.2834 - mse: 152079.8281 - val_loss: 0.1041 - val_mae: 269.7390 - val_mse: 149573.3906\n",
            "Epoch 192/1000\n",
            "76511/76511 - 8s - loss: 0.1124 - mae: 279.2790 - mse: 152333.2031 - val_loss: 0.1025 - val_mae: 264.4374 - val_mse: 140440.9844\n",
            "Epoch 193/1000\n",
            "76511/76511 - 8s - loss: 0.1120 - mae: 278.9569 - mse: 151378.2031 - val_loss: 0.1020 - val_mae: 264.7972 - val_mse: 140258.4062\n",
            "Epoch 194/1000\n",
            "76511/76511 - 8s - loss: 0.1122 - mae: 279.2637 - mse: 151876.9219 - val_loss: 0.1037 - val_mae: 265.9248 - val_mse: 139295.3906\n",
            "Epoch 195/1000\n",
            "76511/76511 - 9s - loss: 0.1120 - mae: 278.4152 - mse: 151359.6719 - val_loss: 0.1029 - val_mae: 267.2332 - val_mse: 145224.1250\n",
            "Epoch 196/1000\n",
            "76511/76511 - 8s - loss: 0.1120 - mae: 279.3491 - mse: 152256.9219 - val_loss: 0.1013 - val_mae: 263.5749 - val_mse: 138116.0938\n",
            "Epoch 197/1000\n",
            "76511/76511 - 8s - loss: 0.1115 - mae: 278.6008 - mse: 151557.1562 - val_loss: 0.1024 - val_mae: 266.3469 - val_mse: 143791.0625\n",
            "Epoch 198/1000\n",
            "76511/76511 - 8s - loss: 0.1120 - mae: 279.0820 - mse: 152057.8750 - val_loss: 0.1022 - val_mae: 264.4543 - val_mse: 139372.8281\n",
            "Epoch 199/1000\n",
            "76511/76511 - 8s - loss: 0.1121 - mae: 279.3572 - mse: 152192.4688 - val_loss: 0.1016 - val_mae: 264.5095 - val_mse: 140106.7812\n",
            "Epoch 200/1000\n",
            "76511/76511 - 8s - loss: 0.1125 - mae: 279.9106 - mse: 152711.6250 - val_loss: 0.1033 - val_mae: 268.2841 - val_mse: 147301.3125\n",
            "Epoch 201/1000\n",
            "76511/76511 - 10s - loss: 0.1117 - mae: 278.4448 - mse: 151069.1094 - val_loss: 0.1025 - val_mae: 267.1207 - val_mse: 146297.3438\n",
            "Epoch 202/1000\n",
            "76511/76511 - 8s - loss: 0.1120 - mae: 278.9787 - mse: 152614.7812 - val_loss: 0.1042 - val_mae: 267.7176 - val_mse: 140632.0781\n",
            "Epoch 203/1000\n",
            "76511/76511 - 8s - loss: 0.1110 - mae: 277.0387 - mse: 150243.0312 - val_loss: 0.1027 - val_mae: 267.7562 - val_mse: 146988.4688\n",
            "Epoch 204/1000\n",
            "76511/76511 - 8s - loss: 0.1116 - mae: 277.9197 - mse: 150816.3281 - val_loss: 0.1023 - val_mae: 265.6312 - val_mse: 142305.8125\n",
            "Epoch 205/1000\n",
            "76511/76511 - 8s - loss: 0.1116 - mae: 277.8433 - mse: 150533.5312 - val_loss: 0.1024 - val_mae: 267.3674 - val_mse: 146831.0000\n",
            "Epoch 206/1000\n",
            "76511/76511 - 8s - loss: 0.1116 - mae: 278.6941 - mse: 151655.4531 - val_loss: 0.1017 - val_mae: 263.8202 - val_mse: 139117.7344\n",
            "Epoch 207/1000\n",
            "76511/76511 - 8s - loss: 0.1120 - mae: 278.4684 - mse: 151004.6250 - val_loss: 0.1015 - val_mae: 264.6280 - val_mse: 141325.2031\n",
            "Epoch 208/1000\n",
            "76511/76511 - 8s - loss: 0.1123 - mae: 279.1633 - mse: 152603.9531 - val_loss: 0.1019 - val_mae: 265.1091 - val_mse: 142612.8125\n",
            "Epoch 209/1000\n",
            "76511/76511 - 8s - loss: 0.1122 - mae: 278.8757 - mse: 152318.0312 - val_loss: 0.1047 - val_mae: 269.0063 - val_mse: 143846.5000\n",
            "Epoch 210/1000\n",
            "76511/76511 - 8s - loss: 0.1114 - mae: 278.1992 - mse: 151040.0625 - val_loss: 0.1018 - val_mae: 263.7616 - val_mse: 138876.6250\n",
            "Epoch 211/1000\n",
            "76511/76511 - 8s - loss: 0.1115 - mae: 277.9007 - mse: 151531.0781 - val_loss: 0.1017 - val_mae: 264.7083 - val_mse: 140512.1094\n",
            "Epoch 212/1000\n",
            "76511/76511 - 8s - loss: 0.1116 - mae: 278.2665 - mse: 151444.4219 - val_loss: 0.1026 - val_mae: 264.5654 - val_mse: 140578.7500\n",
            "Epoch 213/1000\n",
            "76511/76511 - 8s - loss: 0.1120 - mae: 278.9086 - mse: 151919.0469 - val_loss: 0.1028 - val_mae: 267.6559 - val_mse: 146033.7656\n",
            "Epoch 214/1000\n",
            "76511/76511 - 8s - loss: 0.1122 - mae: 279.0687 - mse: 151891.4219 - val_loss: 0.1025 - val_mae: 266.5454 - val_mse: 144657.8594\n",
            "Epoch 215/1000\n",
            "76511/76511 - 8s - loss: 0.1113 - mae: 278.1060 - mse: 151499.4375 - val_loss: 0.1026 - val_mae: 264.6960 - val_mse: 138241.6094\n",
            "Epoch 216/1000\n",
            "76511/76511 - 8s - loss: 0.1120 - mae: 278.7296 - mse: 151590.1562 - val_loss: 0.1022 - val_mae: 264.5240 - val_mse: 141047.0312\n",
            "Epoch 217/1000\n",
            "76511/76511 - 8s - loss: 0.1118 - mae: 278.3916 - mse: 151532.3125 - val_loss: 0.1022 - val_mae: 264.8847 - val_mse: 140416.5156\n",
            "Epoch 218/1000\n",
            "76511/76511 - 9s - loss: 0.1112 - mae: 278.2961 - mse: 150627.9531 - val_loss: 0.1022 - val_mae: 264.9649 - val_mse: 141747.9688\n",
            "Epoch 219/1000\n",
            "76511/76511 - 9s - loss: 0.1111 - mae: 277.3444 - mse: 150378.7344 - val_loss: 0.1017 - val_mae: 265.1334 - val_mse: 142583.1875\n",
            "Epoch 220/1000\n",
            "76511/76511 - 8s - loss: 0.1116 - mae: 277.8874 - mse: 150725.0156 - val_loss: 0.1024 - val_mae: 266.2172 - val_mse: 144271.7812\n",
            "Epoch 221/1000\n",
            "76511/76511 - 8s - loss: 0.1112 - mae: 277.7415 - mse: 150598.6562 - val_loss: 0.1016 - val_mae: 264.1248 - val_mse: 138892.9844\n",
            "Epoch 222/1000\n",
            "76511/76511 - 8s - loss: 0.1116 - mae: 278.2866 - mse: 150851.8125 - val_loss: 0.1030 - val_mae: 265.1072 - val_mse: 140269.0000\n",
            "Epoch 223/1000\n",
            "76511/76511 - 9s - loss: 0.1111 - mae: 277.6082 - mse: 151056.8594 - val_loss: 0.1016 - val_mae: 265.1058 - val_mse: 141591.2656\n",
            "Epoch 224/1000\n",
            "76511/76511 - 9s - loss: 0.1114 - mae: 278.1361 - mse: 150910.6406 - val_loss: 0.1022 - val_mae: 264.0503 - val_mse: 137647.0156\n",
            "Epoch 225/1000\n",
            "76511/76511 - 8s - loss: 0.1115 - mae: 277.7208 - mse: 151257.1094 - val_loss: 0.1032 - val_mae: 264.8510 - val_mse: 137428.2031\n",
            "Epoch 226/1000\n",
            "76511/76511 - 9s - loss: 0.1118 - mae: 278.2562 - mse: 151108.2500 - val_loss: 0.1026 - val_mae: 265.3319 - val_mse: 140676.0000\n",
            "Epoch 227/1000\n",
            "76511/76511 - 9s - loss: 0.1116 - mae: 278.5246 - mse: 151413.8906 - val_loss: 0.1026 - val_mae: 264.6011 - val_mse: 137862.6875\n",
            "Epoch 228/1000\n",
            "76511/76511 - 8s - loss: 0.1114 - mae: 278.1909 - mse: 151805.7656 - val_loss: 0.1026 - val_mae: 265.1733 - val_mse: 138765.1094\n",
            "Epoch 229/1000\n",
            "76511/76511 - 8s - loss: 0.1109 - mae: 277.3179 - mse: 150357.0781 - val_loss: 0.1016 - val_mae: 263.6692 - val_mse: 137273.8594\n",
            "Epoch 230/1000\n",
            "76511/76511 - 8s - loss: 0.1110 - mae: 277.7808 - mse: 150941.5781 - val_loss: 0.1028 - val_mae: 268.0153 - val_mse: 147016.6250\n",
            "Epoch 231/1000\n",
            "76511/76511 - 9s - loss: 0.1114 - mae: 278.1954 - mse: 151365.1875 - val_loss: 0.1018 - val_mae: 264.0236 - val_mse: 137722.2031\n",
            "Epoch 232/1000\n",
            "76511/76511 - 8s - loss: 0.1116 - mae: 278.3751 - mse: 151481.3438 - val_loss: 0.1037 - val_mae: 266.7419 - val_mse: 141876.5938\n",
            "Epoch 233/1000\n",
            "76511/76511 - 8s - loss: 0.1110 - mae: 277.7563 - mse: 150601.4531 - val_loss: 0.1023 - val_mae: 267.4771 - val_mse: 147239.7031\n",
            "Epoch 234/1000\n",
            "76511/76511 - 8s - loss: 0.1109 - mae: 277.5686 - mse: 151345.9688 - val_loss: 0.1019 - val_mae: 264.7685 - val_mse: 140308.7812\n",
            "Epoch 235/1000\n",
            "76511/76511 - 8s - loss: 0.1109 - mae: 277.5235 - mse: 150525.5312 - val_loss: 0.1024 - val_mae: 264.5603 - val_mse: 138018.7344\n",
            "Epoch 236/1000\n",
            "76511/76511 - 8s - loss: 0.1112 - mae: 277.9525 - mse: 151442.2344 - val_loss: 0.1022 - val_mae: 264.7415 - val_mse: 140241.7031\n",
            "Epoch 237/1000\n",
            "76511/76511 - 9s - loss: 0.1110 - mae: 278.0434 - mse: 150864.7656 - val_loss: 0.1019 - val_mae: 264.2858 - val_mse: 138344.6875\n",
            "Epoch 238/1000\n",
            "76511/76511 - 9s - loss: 0.1114 - mae: 277.8885 - mse: 151423.6875 - val_loss: 0.1028 - val_mae: 265.1422 - val_mse: 139626.8906\n",
            "Epoch 239/1000\n",
            "76511/76511 - 8s - loss: 0.1117 - mae: 277.9870 - mse: 151411.4531 - val_loss: 0.1038 - val_mae: 266.2732 - val_mse: 139908.4688\n",
            "Epoch 240/1000\n",
            "76511/76511 - 9s - loss: 0.1109 - mae: 277.4898 - mse: 151103.0156 - val_loss: 0.1025 - val_mae: 264.9240 - val_mse: 139675.3125\n",
            "Epoch 241/1000\n",
            "76511/76511 - 9s - loss: 0.1114 - mae: 278.6866 - mse: 151326.7969 - val_loss: 0.1024 - val_mae: 264.3850 - val_mse: 138812.9531\n",
            "Epoch 242/1000\n",
            "76511/76511 - 9s - loss: 0.1112 - mae: 278.0911 - mse: 151838.3281 - val_loss: 0.1025 - val_mae: 265.6343 - val_mse: 142351.8125\n",
            "Epoch 243/1000\n",
            "76511/76511 - 8s - loss: 0.1115 - mae: 278.0517 - mse: 151235.9531 - val_loss: 0.1030 - val_mae: 268.2579 - val_mse: 147759.9531\n",
            "Epoch 244/1000\n",
            "76511/76511 - 8s - loss: 0.1107 - mae: 276.9738 - mse: 150368.2188 - val_loss: 0.1019 - val_mae: 264.4488 - val_mse: 140260.1719\n",
            "Epoch 245/1000\n",
            "76511/76511 - 9s - loss: 0.1108 - mae: 277.1984 - mse: 150692.3125 - val_loss: 0.1021 - val_mae: 265.8974 - val_mse: 143219.0625\n",
            "Epoch 246/1000\n",
            "76511/76511 - 9s - loss: 0.1112 - mae: 277.4772 - mse: 150913.3594 - val_loss: 0.1047 - val_mae: 268.6746 - val_mse: 141899.0938\n",
            "Epoch 247/1000\n",
            "76511/76511 - 9s - loss: 0.1107 - mae: 277.3281 - mse: 150632.7344 - val_loss: 0.1020 - val_mae: 265.2198 - val_mse: 141576.5312\n",
            "Epoch 248/1000\n",
            "76511/76511 - 9s - loss: 0.1110 - mae: 277.9485 - mse: 150863.6875 - val_loss: 0.1021 - val_mae: 264.2276 - val_mse: 138306.5312\n",
            "Epoch 249/1000\n",
            "76511/76511 - 8s - loss: 0.1111 - mae: 277.7011 - mse: 151210.3750 - val_loss: 0.1017 - val_mae: 264.8286 - val_mse: 141228.1094\n",
            "Epoch 250/1000\n",
            "76511/76511 - 8s - loss: 0.1107 - mae: 277.1396 - mse: 150728.6406 - val_loss: 0.1020 - val_mae: 265.1524 - val_mse: 140954.1094\n",
            "Epoch 251/1000\n",
            "76511/76511 - 8s - loss: 0.1106 - mae: 277.1232 - mse: 150278.4062 - val_loss: 0.1023 - val_mae: 264.8298 - val_mse: 139863.2812\n",
            "Epoch 252/1000\n",
            "76511/76511 - 9s - loss: 0.1111 - mae: 277.9072 - mse: 151664.4844 - val_loss: 0.1030 - val_mae: 265.7620 - val_mse: 139233.9062\n",
            "Epoch 253/1000\n",
            "76511/76511 - 9s - loss: 0.1113 - mae: 278.1265 - mse: 151043.4688 - val_loss: 0.1028 - val_mae: 267.6809 - val_mse: 146647.7812\n",
            "Epoch 254/1000\n",
            "76511/76511 - 9s - loss: 0.1115 - mae: 277.9486 - mse: 151599.2344 - val_loss: 0.1023 - val_mae: 265.4229 - val_mse: 140723.4219\n",
            "Epoch 255/1000\n",
            "76511/76511 - 9s - loss: 0.1109 - mae: 277.3881 - mse: 151494.2656 - val_loss: 0.1036 - val_mae: 268.2681 - val_mse: 146497.6094\n",
            "Epoch 256/1000\n",
            "76511/76511 - 9s - loss: 0.1105 - mae: 277.3550 - mse: 151561.0938 - val_loss: 0.1021 - val_mae: 265.8419 - val_mse: 142838.9375\n",
            "Epoch 257/1000\n",
            "76511/76511 - 9s - loss: 0.1109 - mae: 277.3861 - mse: 151357.1406 - val_loss: 0.1035 - val_mae: 267.0128 - val_mse: 142587.4688\n",
            "Epoch 258/1000\n",
            "76511/76511 - 9s - loss: 0.1108 - mae: 277.1476 - mse: 150825.8750 - val_loss: 0.1017 - val_mae: 264.2766 - val_mse: 139859.4844\n",
            "Epoch 259/1000\n",
            "76511/76511 - 9s - loss: 0.1104 - mae: 276.7817 - mse: 150230.6250 - val_loss: 0.1019 - val_mae: 265.2848 - val_mse: 142558.9531\n",
            "Epoch 260/1000\n",
            "76511/76511 - 9s - loss: 0.1108 - mae: 277.4667 - mse: 151307.6406 - val_loss: 0.1013 - val_mae: 264.2711 - val_mse: 141215.7500\n",
            "Epoch 261/1000\n",
            "76511/76511 - 9s - loss: 0.1109 - mae: 277.2988 - mse: 150865.2344 - val_loss: 0.1023 - val_mae: 264.1706 - val_mse: 139164.3125\n",
            "Epoch 262/1000\n",
            "76511/76511 - 9s - loss: 0.1102 - mae: 276.6253 - mse: 150378.4531 - val_loss: 0.1043 - val_mae: 267.3740 - val_mse: 140456.2969\n",
            "Epoch 263/1000\n",
            "76511/76511 - 9s - loss: 0.1106 - mae: 277.1706 - mse: 151035.0938 - val_loss: 0.1018 - val_mae: 265.2392 - val_mse: 141388.0469\n",
            "Epoch 264/1000\n",
            "76511/76511 - 9s - loss: 0.1109 - mae: 277.5603 - mse: 150615.4531 - val_loss: 0.1017 - val_mae: 263.7326 - val_mse: 138551.6562\n",
            "Epoch 265/1000\n",
            "76511/76511 - 9s - loss: 0.1101 - mae: 276.3304 - mse: 149235.7969 - val_loss: 0.1023 - val_mae: 265.2156 - val_mse: 140662.8125\n",
            "Epoch 266/1000\n",
            "76511/76511 - 9s - loss: 0.1108 - mae: 277.2064 - mse: 150308.3281 - val_loss: 0.1026 - val_mae: 264.7696 - val_mse: 139176.0625\n",
            "Epoch 267/1000\n",
            "76511/76511 - 9s - loss: 0.1107 - mae: 277.8610 - mse: 151487.0469 - val_loss: 0.1021 - val_mae: 264.6240 - val_mse: 140143.0625\n",
            "Epoch 268/1000\n",
            "76511/76511 - 9s - loss: 0.1103 - mae: 276.1560 - mse: 149907.7969 - val_loss: 0.1023 - val_mae: 264.2720 - val_mse: 138984.3438\n",
            "Epoch 269/1000\n",
            "76511/76511 - 9s - loss: 0.1107 - mae: 277.2273 - mse: 150742.1094 - val_loss: 0.1026 - val_mae: 267.7375 - val_mse: 147603.5938\n",
            "Epoch 270/1000\n",
            "76511/76511 - 9s - loss: 0.1108 - mae: 277.5999 - mse: 151238.2344 - val_loss: 0.1018 - val_mae: 264.4429 - val_mse: 140183.2812\n",
            "Epoch 271/1000\n",
            "76511/76511 - 9s - loss: 0.1101 - mae: 276.7115 - mse: 149330.0000 - val_loss: 0.1022 - val_mae: 264.8672 - val_mse: 139240.5156\n",
            "Epoch 272/1000\n",
            "76511/76511 - 9s - loss: 0.1103 - mae: 277.3890 - mse: 150666.3594 - val_loss: 0.1023 - val_mae: 266.0399 - val_mse: 143248.8750\n",
            "Epoch 273/1000\n",
            "76511/76511 - 9s - loss: 0.1103 - mae: 277.0764 - mse: 150815.6719 - val_loss: 0.1030 - val_mae: 265.4977 - val_mse: 139183.1875\n",
            "Epoch 274/1000\n",
            "76511/76511 - 9s - loss: 0.1108 - mae: 277.4137 - mse: 151428.0469 - val_loss: 0.1030 - val_mae: 265.5329 - val_mse: 140887.5000\n",
            "Epoch 275/1000\n",
            "76511/76511 - 9s - loss: 0.1106 - mae: 276.8376 - mse: 150290.9844 - val_loss: 0.1020 - val_mae: 264.6880 - val_mse: 140853.5938\n",
            "Epoch 276/1000\n",
            "76511/76511 - 9s - loss: 0.1099 - mae: 275.8777 - mse: 149798.1250 - val_loss: 0.1041 - val_mae: 266.9024 - val_mse: 141027.2031\n",
            "Epoch 277/1000\n",
            "76511/76511 - 9s - loss: 0.1107 - mae: 277.4298 - mse: 150804.8750 - val_loss: 0.1021 - val_mae: 265.4072 - val_mse: 142524.4688\n",
            "Epoch 278/1000\n",
            "76511/76511 - 9s - loss: 0.1106 - mae: 277.2979 - mse: 151107.0000 - val_loss: 0.1033 - val_mae: 265.8922 - val_mse: 138853.3594\n",
            "Epoch 279/1000\n",
            "76511/76511 - 9s - loss: 0.1108 - mae: 277.5064 - mse: 151051.2500 - val_loss: 0.1022 - val_mae: 264.9828 - val_mse: 140750.9531\n",
            "Epoch 280/1000\n",
            "76511/76511 - 9s - loss: 0.1106 - mae: 277.1843 - mse: 150909.8438 - val_loss: 0.1019 - val_mae: 265.8188 - val_mse: 143481.9844\n",
            "Epoch 281/1000\n",
            "76511/76511 - 9s - loss: 0.1103 - mae: 276.7026 - mse: 150187.3281 - val_loss: 0.1025 - val_mae: 264.8212 - val_mse: 139452.8750\n",
            "Epoch 282/1000\n",
            "76511/76511 - 9s - loss: 0.1107 - mae: 276.7166 - mse: 150224.3125 - val_loss: 0.1020 - val_mae: 264.3524 - val_mse: 139374.6719\n",
            "Epoch 283/1000\n",
            "76511/76511 - 9s - loss: 0.1109 - mae: 277.3668 - mse: 150381.1406 - val_loss: 0.1037 - val_mae: 266.1875 - val_mse: 139860.1250\n",
            "Epoch 284/1000\n",
            "76511/76511 - 8s - loss: 0.1101 - mae: 276.5471 - mse: 150416.2656 - val_loss: 0.1025 - val_mae: 267.0108 - val_mse: 145408.1875\n",
            "Epoch 285/1000\n",
            "76511/76511 - 6s - loss: 0.1101 - mae: 276.4110 - mse: 149733.9062 - val_loss: 0.1024 - val_mae: 265.0634 - val_mse: 142133.8594\n",
            "Epoch 286/1000\n",
            "76511/76511 - 6s - loss: 0.1104 - mae: 276.9093 - mse: 150474.3594 - val_loss: 0.1027 - val_mae: 265.1202 - val_mse: 141185.5938\n",
            "Epoch 287/1000\n",
            "76511/76511 - 6s - loss: 0.1106 - mae: 277.0465 - mse: 151166.1406 - val_loss: 0.1014 - val_mae: 264.2155 - val_mse: 141010.8438\n",
            "Epoch 288/1000\n",
            "76511/76511 - 6s - loss: 0.1102 - mae: 276.3806 - mse: 149921.6562 - val_loss: 0.1017 - val_mae: 264.6645 - val_mse: 140868.7031\n",
            "Epoch 289/1000\n",
            "76511/76511 - 6s - loss: 0.1098 - mae: 276.4426 - mse: 149654.1562 - val_loss: 0.1027 - val_mae: 265.8544 - val_mse: 142662.5781\n",
            "Epoch 290/1000\n",
            "76511/76511 - 6s - loss: 0.1099 - mae: 275.7833 - mse: 148907.2812 - val_loss: 0.1024 - val_mae: 265.1410 - val_mse: 141742.8750\n",
            "Epoch 291/1000\n",
            "76511/76511 - 6s - loss: 0.1104 - mae: 277.2537 - mse: 150803.9375 - val_loss: 0.1025 - val_mae: 265.3644 - val_mse: 141652.7500\n",
            "Epoch 292/1000\n",
            "76511/76511 - 6s - loss: 0.1102 - mae: 276.5356 - mse: 150250.2188 - val_loss: 0.1028 - val_mae: 267.3629 - val_mse: 146248.8750\n",
            "Epoch 293/1000\n",
            "76511/76511 - 6s - loss: 0.1098 - mae: 276.4368 - mse: 150051.2969 - val_loss: 0.1020 - val_mae: 266.0645 - val_mse: 144687.8750\n",
            "Epoch 294/1000\n",
            "76511/76511 - 6s - loss: 0.1101 - mae: 276.2491 - mse: 149523.9688 - val_loss: 0.1021 - val_mae: 265.5927 - val_mse: 143185.8594\n",
            "Epoch 295/1000\n",
            "76511/76511 - 6s - loss: 0.1106 - mae: 277.2093 - mse: 150484.6562 - val_loss: 0.1027 - val_mae: 267.3519 - val_mse: 146193.8438\n",
            "Epoch 296/1000\n",
            "76511/76511 - 6s - loss: 0.1098 - mae: 275.7967 - mse: 148691.3594 - val_loss: 0.1020 - val_mae: 264.7140 - val_mse: 140534.2500\n",
            "Epoch 297/1000\n",
            "76511/76511 - 6s - loss: 0.1096 - mae: 276.2524 - mse: 149470.1719 - val_loss: 0.1029 - val_mae: 264.9887 - val_mse: 138267.1719\n",
            "Epoch 298/1000\n",
            "76511/76511 - 6s - loss: 0.1097 - mae: 276.0841 - mse: 149454.3750 - val_loss: 0.1027 - val_mae: 267.2180 - val_mse: 145539.2656\n",
            "Epoch 299/1000\n",
            "76511/76511 - 6s - loss: 0.1094 - mae: 275.9620 - mse: 149201.1250 - val_loss: 0.1035 - val_mae: 268.4245 - val_mse: 147661.6719\n",
            "Epoch 300/1000\n",
            "76511/76511 - 6s - loss: 0.1099 - mae: 276.0834 - mse: 149727.0000 - val_loss: 0.1025 - val_mae: 267.2592 - val_mse: 145436.9062\n",
            "Epoch 301/1000\n",
            "76511/76511 - 6s - loss: 0.1105 - mae: 276.8090 - mse: 150481.2344 - val_loss: 0.1028 - val_mae: 267.6173 - val_mse: 147778.3125\n",
            "Epoch 302/1000\n",
            "76511/76511 - 6s - loss: 0.1098 - mae: 275.7417 - mse: 149397.8750 - val_loss: 0.1048 - val_mae: 272.1047 - val_mse: 154936.0156\n",
            "Epoch 303/1000\n",
            "76511/76511 - 6s - loss: 0.1096 - mae: 276.1804 - mse: 149896.9531 - val_loss: 0.1028 - val_mae: 267.0321 - val_mse: 144299.9062\n",
            "Epoch 304/1000\n",
            "76511/76511 - 6s - loss: 0.1100 - mae: 276.1621 - mse: 149047.1094 - val_loss: 0.1021 - val_mae: 264.8128 - val_mse: 141081.2500\n",
            "Epoch 305/1000\n",
            "76511/76511 - 6s - loss: 0.1096 - mae: 275.9077 - mse: 149401.7812 - val_loss: 0.1028 - val_mae: 265.8549 - val_mse: 142592.0156\n",
            "Epoch 306/1000\n",
            "76511/76511 - 6s - loss: 0.1096 - mae: 275.0960 - mse: 148268.4531 - val_loss: 0.1025 - val_mae: 264.0529 - val_mse: 138396.0312\n",
            "Epoch 307/1000\n",
            "76511/76511 - 6s - loss: 0.1102 - mae: 276.7686 - mse: 150131.3750 - val_loss: 0.1020 - val_mae: 264.1068 - val_mse: 139835.4062\n",
            "Epoch 308/1000\n",
            "76511/76511 - 6s - loss: 0.1094 - mae: 275.1721 - mse: 149033.2500 - val_loss: 0.1023 - val_mae: 265.9597 - val_mse: 142866.3438\n",
            "Epoch 309/1000\n",
            "76511/76511 - 6s - loss: 0.1097 - mae: 275.9617 - mse: 149471.8125 - val_loss: 0.1030 - val_mae: 265.4976 - val_mse: 139949.6250\n",
            "Epoch 310/1000\n",
            "76511/76511 - 6s - loss: 0.1096 - mae: 275.3470 - mse: 149049.5312 - val_loss: 0.1025 - val_mae: 264.4875 - val_mse: 138211.1875\n",
            "Epoch 311/1000\n",
            "76511/76511 - 6s - loss: 0.1095 - mae: 275.6513 - mse: 148830.7344 - val_loss: 0.1020 - val_mae: 264.8621 - val_mse: 140259.2656\n",
            "Epoch 312/1000\n",
            "76511/76511 - 6s - loss: 0.1098 - mae: 276.2955 - mse: 149797.9688 - val_loss: 0.1025 - val_mae: 264.7281 - val_mse: 139307.5156\n",
            "Epoch 313/1000\n",
            "76511/76511 - 6s - loss: 0.1095 - mae: 275.5692 - mse: 149323.5469 - val_loss: 0.1018 - val_mae: 264.0901 - val_mse: 138998.8906\n",
            "Epoch 314/1000\n",
            "76511/76511 - 6s - loss: 0.1098 - mae: 276.1595 - mse: 149787.8750 - val_loss: 0.1042 - val_mae: 270.6109 - val_mse: 151596.3594\n",
            "Epoch 315/1000\n",
            "76511/76511 - 6s - loss: 0.1097 - mae: 276.2533 - mse: 149264.2188 - val_loss: 0.1028 - val_mae: 266.0939 - val_mse: 143362.2500\n",
            "Epoch 316/1000\n",
            "76511/76511 - 6s - loss: 0.1094 - mae: 275.6396 - mse: 149165.2500 - val_loss: 0.1021 - val_mae: 264.9076 - val_mse: 141405.3750\n",
            "Epoch 317/1000\n",
            "76511/76511 - 6s - loss: 0.1102 - mae: 276.4877 - mse: 150336.2812 - val_loss: 0.1025 - val_mae: 266.8867 - val_mse: 146008.6406\n",
            "Epoch 318/1000\n",
            "76511/76511 - 6s - loss: 0.1092 - mae: 275.4465 - mse: 148921.7500 - val_loss: 0.1022 - val_mae: 264.3999 - val_mse: 138439.9062\n",
            "Epoch 319/1000\n",
            "76511/76511 - 6s - loss: 0.1091 - mae: 275.2266 - mse: 148673.9062 - val_loss: 0.1023 - val_mae: 265.1039 - val_mse: 141470.0469\n",
            "Epoch 320/1000\n",
            "76511/76511 - 6s - loss: 0.1092 - mae: 275.2955 - mse: 148790.1719 - val_loss: 0.1019 - val_mae: 264.2845 - val_mse: 139778.5312\n",
            "Epoch 321/1000\n",
            "76511/76511 - 6s - loss: 0.1092 - mae: 274.9774 - mse: 148841.6719 - val_loss: 0.1034 - val_mae: 269.4893 - val_mse: 150325.3906\n",
            "Epoch 322/1000\n",
            "76511/76511 - 6s - loss: 0.1100 - mae: 276.5023 - mse: 149300.8125 - val_loss: 0.1026 - val_mae: 264.6470 - val_mse: 140070.2031\n",
            "Epoch 323/1000\n",
            "76511/76511 - 6s - loss: 0.1095 - mae: 275.8539 - mse: 149290.0781 - val_loss: 0.1030 - val_mae: 267.6021 - val_mse: 146974.2969\n",
            "Epoch 324/1000\n",
            "76511/76511 - 6s - loss: 0.1090 - mae: 275.4190 - mse: 148394.0625 - val_loss: 0.1052 - val_mae: 273.7224 - val_mse: 157971.6875\n",
            "Epoch 325/1000\n",
            "76511/76511 - 6s - loss: 0.1095 - mae: 275.6351 - mse: 149043.2031 - val_loss: 0.1023 - val_mae: 265.2047 - val_mse: 141354.3281\n",
            "Epoch 326/1000\n",
            "76511/76511 - 6s - loss: 0.1092 - mae: 275.0586 - mse: 148922.6250 - val_loss: 0.1017 - val_mae: 265.2100 - val_mse: 142043.7188\n",
            "Epoch 327/1000\n",
            "76511/76511 - 6s - loss: 0.1093 - mae: 275.5219 - mse: 148650.0625 - val_loss: 0.1028 - val_mae: 266.8598 - val_mse: 144646.2031\n",
            "Epoch 328/1000\n",
            "76511/76511 - 6s - loss: 0.1089 - mae: 274.9132 - mse: 149203.0469 - val_loss: 0.1027 - val_mae: 264.9766 - val_mse: 140801.2812\n",
            "Epoch 329/1000\n",
            "76511/76511 - 6s - loss: 0.1096 - mae: 275.0600 - mse: 148915.2812 - val_loss: 0.1026 - val_mae: 267.2307 - val_mse: 145765.1719\n",
            "Epoch 330/1000\n",
            "76511/76511 - 6s - loss: 0.1097 - mae: 275.9836 - mse: 149537.0156 - val_loss: 0.1034 - val_mae: 270.2673 - val_mse: 151326.3438\n",
            "Epoch 331/1000\n",
            "76511/76511 - 6s - loss: 0.1097 - mae: 275.9156 - mse: 149596.9375 - val_loss: 0.1020 - val_mae: 265.0634 - val_mse: 141405.0625\n",
            "Epoch 332/1000\n",
            "76511/76511 - 6s - loss: 0.1092 - mae: 275.8620 - mse: 149371.1094 - val_loss: 0.1041 - val_mae: 270.1991 - val_mse: 151870.6406\n",
            "Epoch 333/1000\n",
            "76511/76511 - 6s - loss: 0.1095 - mae: 275.7311 - mse: 149056.1875 - val_loss: 0.1023 - val_mae: 266.3965 - val_mse: 144986.5469\n",
            "Epoch 334/1000\n",
            "76511/76511 - 6s - loss: 0.1095 - mae: 275.4413 - mse: 149057.6719 - val_loss: 0.1019 - val_mae: 265.0661 - val_mse: 141162.7031\n",
            "Epoch 335/1000\n",
            "76511/76511 - 6s - loss: 0.1091 - mae: 275.1983 - mse: 148539.2969 - val_loss: 0.1037 - val_mae: 270.1796 - val_mse: 151483.7656\n",
            "Epoch 336/1000\n",
            "76511/76511 - 6s - loss: 0.1091 - mae: 275.2625 - mse: 148966.6875 - val_loss: 0.1037 - val_mae: 270.3751 - val_mse: 151955.3750\n",
            "Epoch 337/1000\n",
            "76511/76511 - 6s - loss: 0.1091 - mae: 275.2702 - mse: 148839.7188 - val_loss: 0.1012 - val_mae: 264.5687 - val_mse: 141061.2969\n",
            "Epoch 338/1000\n",
            "76511/76511 - 6s - loss: 0.1089 - mae: 274.9792 - mse: 149018.1094 - val_loss: 0.1019 - val_mae: 265.2356 - val_mse: 141450.9062\n",
            "Epoch 339/1000\n",
            "76511/76511 - 6s - loss: 0.1093 - mae: 275.4944 - mse: 149169.6562 - val_loss: 0.1019 - val_mae: 265.1862 - val_mse: 141635.9688\n",
            "Epoch 340/1000\n",
            "76511/76511 - 6s - loss: 0.1089 - mae: 275.0521 - mse: 148438.7812 - val_loss: 0.1021 - val_mae: 264.5369 - val_mse: 139879.6875\n",
            "Epoch 341/1000\n",
            "76511/76511 - 6s - loss: 0.1088 - mae: 274.9684 - mse: 148667.3438 - val_loss: 0.1026 - val_mae: 266.1964 - val_mse: 143499.3906\n",
            "Epoch 342/1000\n",
            "76511/76511 - 6s - loss: 0.1092 - mae: 275.7995 - mse: 149436.4062 - val_loss: 0.1028 - val_mae: 267.4399 - val_mse: 146880.7031\n",
            "Epoch 343/1000\n",
            "76511/76511 - 6s - loss: 0.1090 - mae: 275.3794 - mse: 148854.3594 - val_loss: 0.1026 - val_mae: 267.1893 - val_mse: 146623.5000\n",
            "Epoch 344/1000\n",
            "76511/76511 - 6s - loss: 0.1091 - mae: 275.1533 - mse: 148482.9688 - val_loss: 0.1018 - val_mae: 264.8345 - val_mse: 141805.0312\n",
            "Epoch 345/1000\n",
            "76511/76511 - 6s - loss: 0.1085 - mae: 274.7807 - mse: 148360.5000 - val_loss: 0.1029 - val_mae: 267.3608 - val_mse: 145245.0625\n",
            "Epoch 346/1000\n",
            "76511/76511 - 6s - loss: 0.1093 - mae: 275.4774 - mse: 148564.1562 - val_loss: 0.1022 - val_mae: 265.0078 - val_mse: 140791.5312\n",
            "Epoch 347/1000\n",
            "76511/76511 - 6s - loss: 0.1087 - mae: 274.1827 - mse: 147681.6562 - val_loss: 0.1033 - val_mae: 268.5796 - val_mse: 148344.5781\n",
            "Epoch 348/1000\n",
            "76511/76511 - 6s - loss: 0.1094 - mae: 275.4338 - mse: 149009.9062 - val_loss: 0.1026 - val_mae: 267.1240 - val_mse: 145486.7500\n",
            "Epoch 349/1000\n",
            "76511/76511 - 6s - loss: 0.1088 - mae: 275.0258 - mse: 148723.9688 - val_loss: 0.1026 - val_mae: 264.4731 - val_mse: 138355.4531\n",
            "Epoch 350/1000\n",
            "76511/76511 - 6s - loss: 0.1084 - mae: 274.5049 - mse: 148490.1094 - val_loss: 0.1019 - val_mae: 264.7431 - val_mse: 140598.7344\n",
            "Epoch 351/1000\n",
            "76511/76511 - 6s - loss: 0.1088 - mae: 274.7622 - mse: 148900.0000 - val_loss: 0.1020 - val_mae: 264.7969 - val_mse: 141204.1094\n",
            "Epoch 352/1000\n",
            "76511/76511 - 6s - loss: 0.1093 - mae: 275.6169 - mse: 148992.2812 - val_loss: 0.1026 - val_mae: 265.8971 - val_mse: 143083.0312\n",
            "Epoch 353/1000\n",
            "76511/76511 - 6s - loss: 0.1087 - mae: 274.8398 - mse: 147692.1562 - val_loss: 0.1035 - val_mae: 267.8102 - val_mse: 145641.8125\n",
            "Epoch 354/1000\n",
            "76511/76511 - 6s - loss: 0.1085 - mae: 274.3713 - mse: 147925.7969 - val_loss: 0.1017 - val_mae: 265.1834 - val_mse: 142856.9062\n",
            "Epoch 355/1000\n",
            "76511/76511 - 6s - loss: 0.1091 - mae: 275.2970 - mse: 149329.7344 - val_loss: 0.1022 - val_mae: 264.7871 - val_mse: 140866.1875\n",
            "Epoch 356/1000\n",
            "76511/76511 - 6s - loss: 0.1096 - mae: 276.4963 - mse: 150492.0156 - val_loss: 0.1023 - val_mae: 265.2352 - val_mse: 140413.2500\n",
            "Epoch 357/1000\n",
            "76511/76511 - 6s - loss: 0.1089 - mae: 274.8487 - mse: 148200.0156 - val_loss: 0.1028 - val_mae: 264.9128 - val_mse: 138338.3750\n",
            "Epoch 358/1000\n",
            "76511/76511 - 6s - loss: 0.1089 - mae: 274.7634 - mse: 148506.9219 - val_loss: 0.1023 - val_mae: 265.0358 - val_mse: 140287.8125\n",
            "Epoch 359/1000\n",
            "76511/76511 - 6s - loss: 0.1090 - mae: 275.1747 - mse: 149259.3438 - val_loss: 0.1025 - val_mae: 264.9413 - val_mse: 141049.6875\n",
            "Epoch 360/1000\n",
            "76511/76511 - 6s - loss: 0.1088 - mae: 275.1386 - mse: 147810.4531 - val_loss: 0.1027 - val_mae: 265.5209 - val_mse: 141578.4531\n",
            "Epoch 361/1000\n",
            "76511/76511 - 6s - loss: 0.1092 - mae: 275.5523 - mse: 149305.9688 - val_loss: 0.1016 - val_mae: 265.1478 - val_mse: 142367.5000\n",
            "Epoch 362/1000\n",
            "76511/76511 - 6s - loss: 0.1091 - mae: 275.1312 - mse: 148632.9688 - val_loss: 0.1020 - val_mae: 264.7458 - val_mse: 140297.1875\n",
            "Epoch 363/1000\n",
            "76511/76511 - 6s - loss: 0.1088 - mae: 275.0370 - mse: 148358.9844 - val_loss: 0.1026 - val_mae: 265.2365 - val_mse: 140739.2031\n",
            "Epoch 364/1000\n",
            "76511/76511 - 6s - loss: 0.1086 - mae: 274.2971 - mse: 148878.1719 - val_loss: 0.1041 - val_mae: 271.7128 - val_mse: 154106.2969\n",
            "Epoch 365/1000\n",
            "76511/76511 - 6s - loss: 0.1090 - mae: 275.3517 - mse: 149104.3438 - val_loss: 0.1022 - val_mae: 264.5433 - val_mse: 138473.4531\n",
            "Epoch 366/1000\n",
            "76511/76511 - 6s - loss: 0.1084 - mae: 273.9565 - mse: 148289.9062 - val_loss: 0.1019 - val_mae: 265.2875 - val_mse: 141711.1875\n",
            "Epoch 367/1000\n",
            "76511/76511 - 6s - loss: 0.1090 - mae: 275.2443 - mse: 148792.7812 - val_loss: 0.1030 - val_mae: 267.2058 - val_mse: 144697.7031\n",
            "Epoch 368/1000\n",
            "76511/76511 - 6s - loss: 0.1088 - mae: 274.7539 - mse: 148583.0781 - val_loss: 0.1016 - val_mae: 264.5345 - val_mse: 140773.2500\n",
            "Epoch 369/1000\n",
            "76511/76511 - 6s - loss: 0.1085 - mae: 274.5897 - mse: 148050.2969 - val_loss: 0.1021 - val_mae: 266.0572 - val_mse: 143048.1406\n",
            "Epoch 370/1000\n",
            "76511/76511 - 6s - loss: 0.1090 - mae: 275.0954 - mse: 148743.5938 - val_loss: 0.1026 - val_mae: 265.0760 - val_mse: 140028.7812\n",
            "Epoch 371/1000\n",
            "76511/76511 - 6s - loss: 0.1086 - mae: 274.5717 - mse: 148642.6406 - val_loss: 0.1020 - val_mae: 265.4566 - val_mse: 141095.3906\n",
            "Epoch 372/1000\n",
            "76511/76511 - 6s - loss: 0.1086 - mae: 274.6832 - mse: 148161.2188 - val_loss: 0.1021 - val_mae: 265.9660 - val_mse: 143776.4844\n",
            "Epoch 373/1000\n",
            "76511/76511 - 6s - loss: 0.1080 - mae: 274.2222 - mse: 147669.6250 - val_loss: 0.1022 - val_mae: 266.2188 - val_mse: 143658.2344\n",
            "Epoch 374/1000\n",
            "76511/76511 - 6s - loss: 0.1089 - mae: 275.2325 - mse: 148747.8906 - val_loss: 0.1018 - val_mae: 264.3890 - val_mse: 140509.7812\n",
            "Epoch 375/1000\n",
            "76511/76511 - 6s - loss: 0.1084 - mae: 274.0062 - mse: 147845.3906 - val_loss: 0.1049 - val_mae: 273.0857 - val_mse: 156514.0938\n",
            "Epoch 376/1000\n",
            "76511/76511 - 6s - loss: 0.1084 - mae: 274.2720 - mse: 147661.3594 - val_loss: 0.1020 - val_mae: 264.8828 - val_mse: 141195.7188\n",
            "Epoch 377/1000\n",
            "76511/76511 - 6s - loss: 0.1079 - mae: 273.5943 - mse: 147767.0625 - val_loss: 0.1032 - val_mae: 268.0343 - val_mse: 147247.7344\n",
            "Epoch 378/1000\n",
            "76511/76511 - 6s - loss: 0.1089 - mae: 274.5033 - mse: 148690.0781 - val_loss: 0.1021 - val_mae: 264.4992 - val_mse: 140430.2656\n",
            "Epoch 379/1000\n",
            "76511/76511 - 6s - loss: 0.1085 - mae: 274.6435 - mse: 147875.5625 - val_loss: 0.1018 - val_mae: 265.3760 - val_mse: 143089.9844\n",
            "Epoch 380/1000\n",
            "76511/76511 - 6s - loss: 0.1085 - mae: 274.7463 - mse: 148170.4219 - val_loss: 0.1020 - val_mae: 265.9891 - val_mse: 143275.0469\n",
            "Epoch 381/1000\n",
            "76511/76511 - 6s - loss: 0.1087 - mae: 275.1371 - mse: 149343.6562 - val_loss: 0.1048 - val_mae: 272.1544 - val_mse: 154742.0625\n",
            "Epoch 382/1000\n",
            "76511/76511 - 6s - loss: 0.1082 - mae: 274.5738 - mse: 148564.9531 - val_loss: 0.1017 - val_mae: 265.2091 - val_mse: 141667.9688\n",
            "Epoch 383/1000\n",
            "76511/76511 - 6s - loss: 0.1088 - mae: 275.1830 - mse: 149411.7656 - val_loss: 0.1025 - val_mae: 267.4616 - val_mse: 145901.1406\n",
            "Epoch 384/1000\n",
            "76511/76511 - 6s - loss: 0.1086 - mae: 274.7735 - mse: 149267.3594 - val_loss: 0.1027 - val_mae: 265.5234 - val_mse: 139622.8906\n",
            "Epoch 385/1000\n",
            "76511/76511 - 6s - loss: 0.1086 - mae: 274.3914 - mse: 148985.3438 - val_loss: 0.1028 - val_mae: 268.1673 - val_mse: 147663.6250\n",
            "Epoch 386/1000\n",
            "76511/76511 - 6s - loss: 0.1084 - mae: 274.4386 - mse: 148497.8750 - val_loss: 0.1020 - val_mae: 266.6169 - val_mse: 144489.6406\n",
            "Epoch 387/1000\n",
            "76511/76511 - 6s - loss: 0.1080 - mae: 273.7464 - mse: 146803.0469 - val_loss: 0.1033 - val_mae: 269.5235 - val_mse: 151376.7969\n",
            "Epoch 388/1000\n",
            "76511/76511 - 6s - loss: 0.1083 - mae: 274.1750 - mse: 147958.7500 - val_loss: 0.1034 - val_mae: 268.2280 - val_mse: 146770.0781\n",
            "Epoch 389/1000\n",
            "76511/76511 - 15s - loss: 0.1084 - mae: 274.2992 - mse: 148291.9531 - val_loss: 0.1019 - val_mae: 265.6214 - val_mse: 142193.4219\n",
            "Epoch 390/1000\n",
            "76511/76511 - 22s - loss: 0.1086 - mae: 274.8152 - mse: 148529.3281 - val_loss: 0.1047 - val_mae: 272.9343 - val_mse: 156735.0469\n",
            "Epoch 391/1000\n",
            "76511/76511 - 22s - loss: 0.1082 - mae: 274.3486 - mse: 148344.1406 - val_loss: 0.1021 - val_mae: 264.5825 - val_mse: 139334.7969\n",
            "Epoch 392/1000\n",
            "76511/76511 - 23s - loss: 0.1085 - mae: 274.7609 - mse: 148339.8125 - val_loss: 0.1030 - val_mae: 266.5331 - val_mse: 141534.1562\n",
            "Epoch 393/1000\n",
            "76511/76511 - 22s - loss: 0.1082 - mae: 274.0446 - mse: 147734.2500 - val_loss: 0.1032 - val_mae: 269.2854 - val_mse: 149952.2969\n",
            "Epoch 394/1000\n",
            "76511/76511 - 23s - loss: 0.1083 - mae: 274.6405 - mse: 148485.1406 - val_loss: 0.1029 - val_mae: 267.4188 - val_mse: 144803.3906\n",
            "Epoch 395/1000\n",
            "76511/76511 - 23s - loss: 0.1081 - mae: 273.8882 - mse: 147670.9219 - val_loss: 0.1027 - val_mae: 267.5471 - val_mse: 145929.9219\n",
            "Epoch 396/1000\n",
            "76511/76511 - 24s - loss: 0.1083 - mae: 274.9764 - mse: 148335.4219 - val_loss: 0.1023 - val_mae: 265.2138 - val_mse: 140199.0938\n",
            "Epoch 397/1000\n",
            "76511/76511 - 25s - loss: 0.1084 - mae: 273.7147 - mse: 147452.2344 - val_loss: 0.1033 - val_mae: 269.3367 - val_mse: 149738.8438\n",
            "Epoch 398/1000\n",
            "76511/76511 - 25s - loss: 0.1082 - mae: 274.2829 - mse: 148358.7188 - val_loss: 0.1024 - val_mae: 264.5880 - val_mse: 139197.4219\n",
            "Epoch 399/1000\n",
            "76511/76511 - 23s - loss: 0.1082 - mae: 274.2069 - mse: 147386.7188 - val_loss: 0.1021 - val_mae: 266.0609 - val_mse: 144179.9688\n",
            "Epoch 400/1000\n",
            "76511/76511 - 22s - loss: 0.1087 - mae: 274.4498 - mse: 148383.0625 - val_loss: 0.1017 - val_mae: 264.6557 - val_mse: 141348.7656\n",
            "Epoch 401/1000\n",
            "76511/76511 - 23s - loss: 0.1084 - mae: 274.5148 - mse: 148533.6250 - val_loss: 0.1026 - val_mae: 265.9023 - val_mse: 142956.4375\n",
            "Epoch 402/1000\n",
            "76511/76511 - 22s - loss: 0.1083 - mae: 274.7214 - mse: 147766.1094 - val_loss: 0.1022 - val_mae: 265.9880 - val_mse: 142853.1406\n",
            "Epoch 403/1000\n",
            "76511/76511 - 23s - loss: 0.1078 - mae: 273.7336 - mse: 147147.6562 - val_loss: 0.1024 - val_mae: 267.0856 - val_mse: 145491.5625\n",
            "Epoch 404/1000\n",
            "76511/76511 - 23s - loss: 0.1083 - mae: 273.8769 - mse: 147566.6094 - val_loss: 0.1025 - val_mae: 266.7130 - val_mse: 144369.1094\n",
            "Epoch 405/1000\n",
            "76511/76511 - 9s - loss: 0.1085 - mae: 273.8850 - mse: 147294.4844 - val_loss: 0.1038 - val_mae: 270.1275 - val_mse: 149941.0312\n",
            "Epoch 406/1000\n",
            "76511/76511 - 7s - loss: 0.1082 - mae: 273.6759 - mse: 147703.1719 - val_loss: 0.1045 - val_mae: 271.8386 - val_mse: 153424.2812\n",
            "Epoch 407/1000\n",
            "76511/76511 - 6s - loss: 0.1081 - mae: 273.6992 - mse: 147777.5000 - val_loss: 0.1033 - val_mae: 265.8796 - val_mse: 139080.5938\n",
            "Epoch 408/1000\n",
            "76511/76511 - 6s - loss: 0.1081 - mae: 273.9492 - mse: 147219.5312 - val_loss: 0.1045 - val_mae: 272.3968 - val_mse: 155543.6562\n",
            "Epoch 409/1000\n",
            "76511/76511 - 6s - loss: 0.1076 - mae: 273.5237 - mse: 147199.6406 - val_loss: 0.1038 - val_mae: 270.0504 - val_mse: 151068.5000\n",
            "Epoch 410/1000\n",
            "76511/76511 - 6s - loss: 0.1082 - mae: 274.0536 - mse: 148103.2031 - val_loss: 0.1018 - val_mae: 265.2781 - val_mse: 142400.8125\n",
            "Epoch 411/1000\n",
            "76511/76511 - 6s - loss: 0.1081 - mae: 274.0395 - mse: 147626.8750 - val_loss: 0.1025 - val_mae: 265.1415 - val_mse: 140739.3281\n",
            "Epoch 412/1000\n",
            "76511/76511 - 6s - loss: 0.1076 - mae: 273.4663 - mse: 146988.8594 - val_loss: 0.1024 - val_mae: 264.9869 - val_mse: 140269.7969\n",
            "Epoch 413/1000\n",
            "76511/76511 - 6s - loss: 0.1081 - mae: 274.1094 - mse: 147536.2812 - val_loss: 0.1050 - val_mae: 272.4593 - val_mse: 155609.3594\n",
            "Epoch 414/1000\n",
            "76511/76511 - 6s - loss: 0.1081 - mae: 273.3498 - mse: 148058.0312 - val_loss: 0.1023 - val_mae: 264.7913 - val_mse: 139739.5156\n",
            "Epoch 415/1000\n",
            "76511/76511 - 6s - loss: 0.1081 - mae: 274.0757 - mse: 147988.2344 - val_loss: 0.1035 - val_mae: 269.7380 - val_mse: 150082.4531\n",
            "Epoch 416/1000\n",
            "76511/76511 - 6s - loss: 0.1080 - mae: 273.6023 - mse: 147860.5156 - val_loss: 0.1021 - val_mae: 264.9400 - val_mse: 141155.1250\n",
            "Epoch 417/1000\n",
            "76511/76511 - 6s - loss: 0.1086 - mae: 275.2835 - mse: 148682.3438 - val_loss: 0.1022 - val_mae: 265.8839 - val_mse: 143511.4375\n",
            "Epoch 418/1000\n",
            "76511/76511 - 6s - loss: 0.1076 - mae: 273.1039 - mse: 146643.4844 - val_loss: 0.1064 - val_mae: 276.0864 - val_mse: 161433.9844\n",
            "Epoch 419/1000\n",
            "76511/76511 - 6s - loss: 0.1074 - mae: 273.2876 - mse: 147118.2656 - val_loss: 0.1026 - val_mae: 265.8145 - val_mse: 142135.6094\n",
            "Epoch 420/1000\n",
            "76511/76511 - 6s - loss: 0.1081 - mae: 273.9697 - mse: 148081.5312 - val_loss: 0.1025 - val_mae: 266.0365 - val_mse: 143898.6094\n",
            "Epoch 421/1000\n",
            "76511/76511 - 6s - loss: 0.1081 - mae: 273.9244 - mse: 147725.0781 - val_loss: 0.1032 - val_mae: 267.8948 - val_mse: 146634.2344\n",
            "Epoch 422/1000\n",
            "76511/76511 - 6s - loss: 0.1078 - mae: 272.9385 - mse: 147754.2656 - val_loss: 0.1028 - val_mae: 267.9913 - val_mse: 148172.2656\n",
            "Epoch 423/1000\n",
            "76511/76511 - 6s - loss: 0.1082 - mae: 273.6034 - mse: 148201.2969 - val_loss: 0.1021 - val_mae: 264.0051 - val_mse: 138854.0625\n",
            "Epoch 424/1000\n",
            "76511/76511 - 6s - loss: 0.1079 - mae: 273.5270 - mse: 147120.1250 - val_loss: 0.1024 - val_mae: 266.2002 - val_mse: 143788.7656\n",
            "Epoch 425/1000\n",
            "76511/76511 - 6s - loss: 0.1079 - mae: 274.0754 - mse: 147583.0000 - val_loss: 0.1029 - val_mae: 268.2252 - val_mse: 148204.0625\n",
            "Epoch 426/1000\n",
            "76511/76511 - 6s - loss: 0.1080 - mae: 274.1596 - mse: 148132.9688 - val_loss: 0.1025 - val_mae: 267.9093 - val_mse: 147385.2656\n",
            "Epoch 427/1000\n",
            "76511/76511 - 6s - loss: 0.1082 - mae: 274.1182 - mse: 148197.3438 - val_loss: 0.1026 - val_mae: 266.8025 - val_mse: 145178.0469\n",
            "Epoch 428/1000\n",
            "76511/76511 - 6s - loss: 0.1079 - mae: 273.6600 - mse: 147301.6719 - val_loss: 0.1022 - val_mae: 266.6633 - val_mse: 145115.9531\n",
            "Epoch 429/1000\n",
            "76511/76511 - 6s - loss: 0.1074 - mae: 273.4702 - mse: 147564.0781 - val_loss: 0.1018 - val_mae: 264.5287 - val_mse: 140230.0312\n",
            "Epoch 430/1000\n",
            "76511/76511 - 6s - loss: 0.1075 - mae: 272.6937 - mse: 147161.1406 - val_loss: 0.1025 - val_mae: 266.6643 - val_mse: 144753.5469\n",
            "Epoch 431/1000\n",
            "76511/76511 - 6s - loss: 0.1077 - mae: 274.1249 - mse: 148073.3438 - val_loss: 0.1023 - val_mae: 264.4913 - val_mse: 138952.2656\n",
            "Epoch 432/1000\n",
            "76511/76511 - 6s - loss: 0.1076 - mae: 273.3183 - mse: 146743.4688 - val_loss: 0.1026 - val_mae: 266.9764 - val_mse: 145644.8281\n",
            "Epoch 433/1000\n",
            "76511/76511 - 6s - loss: 0.1077 - mae: 273.4896 - mse: 147197.8906 - val_loss: 0.1027 - val_mae: 267.2213 - val_mse: 146611.0781\n",
            "Epoch 434/1000\n",
            "76511/76511 - 6s - loss: 0.1081 - mae: 273.6854 - mse: 148036.7031 - val_loss: 0.1019 - val_mae: 265.2736 - val_mse: 141745.2969\n",
            "Epoch 435/1000\n",
            "76511/76511 - 6s - loss: 0.1077 - mae: 273.9374 - mse: 147436.5312 - val_loss: 0.1033 - val_mae: 265.7787 - val_mse: 140217.0938\n",
            "Epoch 436/1000\n",
            "76511/76511 - 6s - loss: 0.1080 - mae: 273.9536 - mse: 147628.2344 - val_loss: 0.1019 - val_mae: 265.6552 - val_mse: 142863.7344\n",
            "Epoch 437/1000\n",
            "76511/76511 - 6s - loss: 0.1077 - mae: 273.4574 - mse: 147471.5156 - val_loss: 0.1021 - val_mae: 265.9981 - val_mse: 143110.9531\n",
            "Epoch 438/1000\n",
            "76511/76511 - 6s - loss: 0.1076 - mae: 273.8016 - mse: 147429.0000 - val_loss: 0.1029 - val_mae: 267.3083 - val_mse: 146097.5312\n",
            "Epoch 439/1000\n",
            "76511/76511 - 6s - loss: 0.1078 - mae: 273.5935 - mse: 148010.4062 - val_loss: 0.1027 - val_mae: 266.2695 - val_mse: 143471.8438\n",
            "Epoch 440/1000\n",
            "76511/76511 - 6s - loss: 0.1077 - mae: 273.3211 - mse: 147390.2188 - val_loss: 0.1028 - val_mae: 265.9014 - val_mse: 139953.9531\n",
            "Epoch 441/1000\n",
            "76511/76511 - 6s - loss: 0.1076 - mae: 273.3154 - mse: 146914.0000 - val_loss: 0.1023 - val_mae: 265.0214 - val_mse: 139663.0156\n",
            "Epoch 442/1000\n",
            "76511/76511 - 6s - loss: 0.1076 - mae: 273.3158 - mse: 147758.5781 - val_loss: 0.1019 - val_mae: 265.4002 - val_mse: 141280.1875\n",
            "Epoch 443/1000\n",
            "76511/76511 - 6s - loss: 0.1077 - mae: 273.5315 - mse: 147381.6406 - val_loss: 0.1018 - val_mae: 264.5853 - val_mse: 140411.5625\n",
            "Epoch 444/1000\n",
            "76511/76511 - 6s - loss: 0.1079 - mae: 273.6519 - mse: 148854.2969 - val_loss: 0.1017 - val_mae: 264.5896 - val_mse: 140428.0938\n",
            "Epoch 445/1000\n",
            "76511/76511 - 6s - loss: 0.1070 - mae: 272.7438 - mse: 146319.2812 - val_loss: 0.1030 - val_mae: 267.1053 - val_mse: 145772.9219\n",
            "Epoch 446/1000\n",
            "76511/76511 - 6s - loss: 0.1081 - mae: 273.9123 - mse: 147548.5938 - val_loss: 0.1023 - val_mae: 266.8465 - val_mse: 145841.2656\n",
            "Epoch 447/1000\n",
            "76511/76511 - 6s - loss: 0.1078 - mae: 273.6187 - mse: 147837.1406 - val_loss: 0.1021 - val_mae: 265.3531 - val_mse: 141473.6406\n",
            "Epoch 448/1000\n",
            "76511/76511 - 6s - loss: 0.1079 - mae: 273.8404 - mse: 147585.9531 - val_loss: 0.1028 - val_mae: 265.6107 - val_mse: 141444.9062\n",
            "Epoch 449/1000\n",
            "76511/76511 - 6s - loss: 0.1069 - mae: 272.3906 - mse: 146222.1562 - val_loss: 0.1033 - val_mae: 269.3127 - val_mse: 149500.5156\n",
            "Epoch 450/1000\n",
            "76511/76511 - 6s - loss: 0.1073 - mae: 272.8417 - mse: 147016.7031 - val_loss: 0.1056 - val_mae: 274.0019 - val_mse: 157245.3438\n",
            "Epoch 451/1000\n",
            "76511/76511 - 6s - loss: 0.1074 - mae: 273.1152 - mse: 147019.5781 - val_loss: 0.1024 - val_mae: 264.6398 - val_mse: 139975.5156\n",
            "Epoch 452/1000\n",
            "76511/76511 - 6s - loss: 0.1072 - mae: 272.7502 - mse: 147456.9844 - val_loss: 0.1023 - val_mae: 264.7807 - val_mse: 139383.6875\n",
            "Epoch 453/1000\n",
            "76511/76511 - 6s - loss: 0.1073 - mae: 272.6338 - mse: 146437.6406 - val_loss: 0.1043 - val_mae: 271.0318 - val_mse: 152482.8438\n",
            "Epoch 454/1000\n",
            "76511/76511 - 6s - loss: 0.1072 - mae: 272.4803 - mse: 146751.0469 - val_loss: 0.1019 - val_mae: 265.5793 - val_mse: 142726.4375\n",
            "Epoch 455/1000\n",
            "76511/76511 - 6s - loss: 0.1071 - mae: 272.6831 - mse: 146087.6719 - val_loss: 0.1032 - val_mae: 266.1870 - val_mse: 139610.0781\n",
            "Epoch 456/1000\n",
            "76511/76511 - 6s - loss: 0.1073 - mae: 273.0191 - mse: 146892.5781 - val_loss: 0.1027 - val_mae: 265.2476 - val_mse: 139167.2031\n",
            "Epoch 457/1000\n",
            "76511/76511 - 6s - loss: 0.1073 - mae: 272.7287 - mse: 146320.7969 - val_loss: 0.1019 - val_mae: 264.5053 - val_mse: 140003.2031\n",
            "Epoch 458/1000\n",
            "76511/76511 - 6s - loss: 0.1074 - mae: 272.7865 - mse: 147169.8906 - val_loss: 0.1019 - val_mae: 266.0682 - val_mse: 143825.6719\n",
            "Epoch 459/1000\n",
            "76511/76511 - 6s - loss: 0.1069 - mae: 272.5240 - mse: 146775.9531 - val_loss: 0.1025 - val_mae: 265.2716 - val_mse: 141355.4062\n",
            "Epoch 460/1000\n",
            "76511/76511 - 6s - loss: 0.1074 - mae: 273.3980 - mse: 147050.9219 - val_loss: 0.1025 - val_mae: 266.0010 - val_mse: 142994.7344\n",
            "Epoch 461/1000\n",
            "76511/76511 - 6s - loss: 0.1073 - mae: 272.8297 - mse: 147293.9062 - val_loss: 0.1027 - val_mae: 265.5690 - val_mse: 140295.1250\n",
            "Epoch 462/1000\n",
            "76511/76511 - 6s - loss: 0.1074 - mae: 272.9635 - mse: 147512.4219 - val_loss: 0.1018 - val_mae: 265.3882 - val_mse: 142340.1406\n",
            "Epoch 463/1000\n",
            "76511/76511 - 6s - loss: 0.1071 - mae: 272.9933 - mse: 146773.8750 - val_loss: 0.1054 - val_mae: 273.8188 - val_mse: 156919.8906\n",
            "Epoch 464/1000\n",
            "76511/76511 - 6s - loss: 0.1076 - mae: 273.5293 - mse: 147093.0312 - val_loss: 0.1030 - val_mae: 268.3169 - val_mse: 148005.4688\n",
            "Epoch 465/1000\n",
            "76511/76511 - 6s - loss: 0.1075 - mae: 273.1698 - mse: 147351.8125 - val_loss: 0.1037 - val_mae: 266.4011 - val_mse: 139575.0000\n",
            "Epoch 466/1000\n",
            "76511/76511 - 6s - loss: 0.1069 - mae: 272.4314 - mse: 146176.2188 - val_loss: 0.1020 - val_mae: 264.4006 - val_mse: 140255.2812\n",
            "Epoch 467/1000\n",
            "76511/76511 - 6s - loss: 0.1072 - mae: 273.3684 - mse: 147169.0781 - val_loss: 0.1019 - val_mae: 265.0193 - val_mse: 141409.9844\n",
            "Epoch 468/1000\n",
            "76511/76511 - 6s - loss: 0.1071 - mae: 272.7417 - mse: 146306.3125 - val_loss: 0.1022 - val_mae: 264.5817 - val_mse: 140958.0625\n",
            "Epoch 469/1000\n",
            "76511/76511 - 6s - loss: 0.1076 - mae: 273.3401 - mse: 147573.2969 - val_loss: 0.1034 - val_mae: 269.1269 - val_mse: 148910.1562\n",
            "Epoch 470/1000\n",
            "76511/76511 - 6s - loss: 0.1070 - mae: 272.6572 - mse: 146258.5938 - val_loss: 0.1037 - val_mae: 269.9516 - val_mse: 150434.7344\n",
            "Epoch 471/1000\n",
            "76511/76511 - 6s - loss: 0.1072 - mae: 272.8703 - mse: 146486.1562 - val_loss: 0.1022 - val_mae: 265.6088 - val_mse: 141603.6250\n",
            "Epoch 472/1000\n",
            "76511/76511 - 6s - loss: 0.1072 - mae: 272.8425 - mse: 146629.6562 - val_loss: 0.1019 - val_mae: 264.7757 - val_mse: 139635.6094\n",
            "Epoch 473/1000\n",
            "76511/76511 - 6s - loss: 0.1075 - mae: 273.0284 - mse: 147219.2656 - val_loss: 0.1020 - val_mae: 265.4405 - val_mse: 142144.7031\n",
            "Epoch 474/1000\n",
            "76511/76511 - 6s - loss: 0.1069 - mae: 272.8799 - mse: 147171.9219 - val_loss: 0.1024 - val_mae: 266.0163 - val_mse: 142658.2812\n",
            "Epoch 475/1000\n",
            "76511/76511 - 6s - loss: 0.1069 - mae: 271.9582 - mse: 146076.8750 - val_loss: 0.1041 - val_mae: 270.7860 - val_mse: 151616.4219\n",
            "Epoch 476/1000\n",
            "76511/76511 - 6s - loss: 0.1066 - mae: 272.1369 - mse: 147111.0000 - val_loss: 0.1027 - val_mae: 267.1468 - val_mse: 145419.0312\n",
            "Epoch 477/1000\n",
            "76511/76511 - 6s - loss: 0.1069 - mae: 272.9295 - mse: 146982.2500 - val_loss: 0.1022 - val_mae: 265.7322 - val_mse: 142825.9375\n",
            "Epoch 478/1000\n",
            "76511/76511 - 6s - loss: 0.1069 - mae: 272.4528 - mse: 146432.7344 - val_loss: 0.1047 - val_mae: 272.5473 - val_mse: 154850.8594\n",
            "Epoch 479/1000\n",
            "76511/76511 - 19s - loss: 0.1068 - mae: 272.5214 - mse: 146635.5312 - val_loss: 0.1024 - val_mae: 264.8607 - val_mse: 139676.7500\n",
            "Epoch 480/1000\n",
            "76511/76511 - 21s - loss: 0.1070 - mae: 272.4290 - mse: 147032.8594 - val_loss: 0.1026 - val_mae: 265.7170 - val_mse: 141548.3438\n",
            "Epoch 481/1000\n",
            "76511/76511 - 6s - loss: 0.1071 - mae: 272.7483 - mse: 146961.8906 - val_loss: 0.1050 - val_mae: 269.3466 - val_mse: 144925.5312\n",
            "Epoch 482/1000\n",
            "76511/76511 - 5s - loss: 0.1069 - mae: 272.2164 - mse: 146493.0625 - val_loss: 0.1031 - val_mae: 268.9057 - val_mse: 148682.0625\n",
            "Epoch 483/1000\n",
            "76511/76511 - 5s - loss: 0.1072 - mae: 272.6927 - mse: 146725.4219 - val_loss: 0.1046 - val_mae: 271.8989 - val_mse: 153784.7969\n",
            "Epoch 484/1000\n",
            "76511/76511 - 5s - loss: 0.1067 - mae: 272.5011 - mse: 146609.8125 - val_loss: 0.1025 - val_mae: 265.8376 - val_mse: 142839.2812\n",
            "Epoch 485/1000\n",
            "76511/76511 - 5s - loss: 0.1069 - mae: 272.4327 - mse: 146692.9844 - val_loss: 0.1026 - val_mae: 264.8853 - val_mse: 139982.9062\n",
            "Epoch 486/1000\n",
            "76511/76511 - 5s - loss: 0.1071 - mae: 272.9238 - mse: 146589.0312 - val_loss: 0.1035 - val_mae: 270.2690 - val_mse: 151982.6406\n",
            "Epoch 487/1000\n",
            "76511/76511 - 5s - loss: 0.1069 - mae: 272.1672 - mse: 146130.4844 - val_loss: 0.1020 - val_mae: 265.8999 - val_mse: 144138.1875\n",
            "Epoch 488/1000\n",
            "76511/76511 - 5s - loss: 0.1070 - mae: 272.2620 - mse: 146398.2969 - val_loss: 0.1021 - val_mae: 265.0224 - val_mse: 140882.3906\n",
            "Epoch 489/1000\n",
            "76511/76511 - 5s - loss: 0.1067 - mae: 272.5229 - mse: 146705.7031 - val_loss: 0.1025 - val_mae: 266.7162 - val_mse: 144162.9062\n",
            "Epoch 490/1000\n",
            "76511/76511 - 5s - loss: 0.1072 - mae: 272.9485 - mse: 147413.8594 - val_loss: 0.1043 - val_mae: 270.6666 - val_mse: 151512.9531\n",
            "Epoch 491/1000\n",
            "76511/76511 - 5s - loss: 0.1070 - mae: 272.2175 - mse: 146637.8281 - val_loss: 0.1018 - val_mae: 264.8463 - val_mse: 141053.0000\n",
            "Epoch 492/1000\n",
            "76511/76511 - 5s - loss: 0.1071 - mae: 272.5414 - mse: 147453.6094 - val_loss: 0.1040 - val_mae: 270.0646 - val_mse: 150849.0000\n",
            "Epoch 493/1000\n",
            "76511/76511 - 5s - loss: 0.1068 - mae: 272.2100 - mse: 146528.2656 - val_loss: 0.1036 - val_mae: 269.5333 - val_mse: 150664.2344\n",
            "Epoch 494/1000\n",
            "76511/76511 - 5s - loss: 0.1066 - mae: 272.1816 - mse: 145808.8750 - val_loss: 0.1045 - val_mae: 272.0948 - val_mse: 154753.5938\n",
            "Epoch 495/1000\n",
            "76511/76511 - 5s - loss: 0.1071 - mae: 272.4793 - mse: 147322.0312 - val_loss: 0.1020 - val_mae: 265.0992 - val_mse: 141277.9531\n",
            "Epoch 496/1000\n",
            "76511/76511 - 5s - loss: 0.1068 - mae: 272.6674 - mse: 146623.7188 - val_loss: 0.1033 - val_mae: 268.4524 - val_mse: 147396.4375\n",
            "Epoch 497/1000\n",
            "76511/76511 - 5s - loss: 0.1064 - mae: 272.1565 - mse: 146134.2812 - val_loss: 0.1035 - val_mae: 268.2711 - val_mse: 146910.6250\n",
            "Epoch 498/1000\n",
            "76511/76511 - 5s - loss: 0.1068 - mae: 272.4134 - mse: 146840.4219 - val_loss: 0.1021 - val_mae: 264.6404 - val_mse: 140091.0625\n",
            "Epoch 499/1000\n",
            "76511/76511 - 5s - loss: 0.1064 - mae: 271.9417 - mse: 145918.8438 - val_loss: 0.1020 - val_mae: 265.2842 - val_mse: 141788.1875\n",
            "Epoch 500/1000\n",
            "76511/76511 - 5s - loss: 0.1069 - mae: 272.9010 - mse: 146510.0469 - val_loss: 0.1019 - val_mae: 264.5018 - val_mse: 140184.8281\n",
            "Epoch 501/1000\n",
            "76511/76511 - 5s - loss: 0.1067 - mae: 271.8568 - mse: 146611.6094 - val_loss: 0.1029 - val_mae: 267.7238 - val_mse: 146458.0781\n",
            "Epoch 502/1000\n",
            "76511/76511 - 5s - loss: 0.1073 - mae: 273.1543 - mse: 147346.9688 - val_loss: 0.1034 - val_mae: 265.5569 - val_mse: 139066.2656\n",
            "Epoch 503/1000\n",
            "76511/76511 - 5s - loss: 0.1071 - mae: 272.8164 - mse: 146151.6875 - val_loss: 0.1036 - val_mae: 269.9122 - val_mse: 150667.7031\n",
            "Epoch 504/1000\n",
            "76511/76511 - 5s - loss: 0.1065 - mae: 271.9763 - mse: 146305.3906 - val_loss: 0.1018 - val_mae: 264.3737 - val_mse: 140607.7656\n",
            "Epoch 505/1000\n",
            "76511/76511 - 5s - loss: 0.1067 - mae: 272.5174 - mse: 146996.2969 - val_loss: 0.1040 - val_mae: 269.7548 - val_mse: 150364.6719\n",
            "Epoch 506/1000\n",
            "76511/76511 - 5s - loss: 0.1067 - mae: 272.5721 - mse: 146790.8125 - val_loss: 0.1024 - val_mae: 264.6615 - val_mse: 139737.1250\n",
            "Epoch 507/1000\n",
            "76511/76511 - 5s - loss: 0.1067 - mae: 272.4671 - mse: 146174.7188 - val_loss: 0.1045 - val_mae: 270.8524 - val_mse: 152197.4375\n",
            "Epoch 508/1000\n",
            "76511/76511 - 5s - loss: 0.1066 - mae: 272.2381 - mse: 146268.9062 - val_loss: 0.1022 - val_mae: 264.8883 - val_mse: 140463.7812\n",
            "Epoch 509/1000\n",
            "76511/76511 - 5s - loss: 0.1065 - mae: 271.8043 - mse: 145828.1562 - val_loss: 0.1040 - val_mae: 270.2993 - val_mse: 150514.7969\n",
            "Epoch 510/1000\n",
            "76511/76511 - 5s - loss: 0.1066 - mae: 272.3444 - mse: 146635.1875 - val_loss: 0.1035 - val_mae: 269.0352 - val_mse: 148576.7969\n",
            "Epoch 511/1000\n",
            "76511/76511 - 5s - loss: 0.1067 - mae: 272.1076 - mse: 145494.9531 - val_loss: 0.1020 - val_mae: 265.5102 - val_mse: 141844.0469\n",
            "Epoch 512/1000\n",
            "76511/76511 - 5s - loss: 0.1066 - mae: 271.8158 - mse: 146227.9219 - val_loss: 0.1027 - val_mae: 267.0885 - val_mse: 144517.9844\n",
            "Epoch 513/1000\n",
            "76511/76511 - 5s - loss: 0.1066 - mae: 272.3382 - mse: 146320.2188 - val_loss: 0.1019 - val_mae: 265.4900 - val_mse: 141427.9844\n",
            "Epoch 514/1000\n",
            "76511/76511 - 5s - loss: 0.1068 - mae: 272.6007 - mse: 146584.7969 - val_loss: 0.1028 - val_mae: 265.9919 - val_mse: 140398.4062\n",
            "Epoch 515/1000\n",
            "76511/76511 - 5s - loss: 0.1066 - mae: 271.8421 - mse: 146008.7188 - val_loss: 0.1020 - val_mae: 265.4686 - val_mse: 141821.0625\n",
            "Epoch 516/1000\n",
            "76511/76511 - 5s - loss: 0.1068 - mae: 271.6538 - mse: 145751.8906 - val_loss: 0.1021 - val_mae: 264.8824 - val_mse: 139504.0781\n",
            "Epoch 517/1000\n",
            "76511/76511 - 5s - loss: 0.1061 - mae: 271.4164 - mse: 145401.6562 - val_loss: 0.1028 - val_mae: 265.2512 - val_mse: 139769.1406\n",
            "Epoch 518/1000\n",
            "76511/76511 - 5s - loss: 0.1061 - mae: 271.6755 - mse: 145703.0312 - val_loss: 0.1035 - val_mae: 269.7199 - val_mse: 150963.2969\n",
            "Epoch 519/1000\n",
            "76511/76511 - 5s - loss: 0.1059 - mae: 271.1680 - mse: 145486.9531 - val_loss: 0.1030 - val_mae: 267.7083 - val_mse: 146327.2656\n",
            "Epoch 520/1000\n",
            "76511/76511 - 5s - loss: 0.1066 - mae: 271.9014 - mse: 145781.3281 - val_loss: 0.1023 - val_mae: 266.3838 - val_mse: 143580.1406\n",
            "Epoch 521/1000\n",
            "76511/76511 - 5s - loss: 0.1062 - mae: 271.5359 - mse: 145815.4688 - val_loss: 0.1024 - val_mae: 266.2228 - val_mse: 143790.0312\n",
            "Epoch 522/1000\n",
            "76511/76511 - 5s - loss: 0.1063 - mae: 272.1233 - mse: 146055.1719 - val_loss: 0.1027 - val_mae: 265.7366 - val_mse: 143010.9062\n",
            "Epoch 523/1000\n",
            "76511/76511 - 5s - loss: 0.1067 - mae: 272.2267 - mse: 145782.5000 - val_loss: 0.1023 - val_mae: 266.1140 - val_mse: 142721.7188\n",
            "Epoch 524/1000\n",
            "76511/76511 - 5s - loss: 0.1062 - mae: 271.5257 - mse: 145407.7500 - val_loss: 0.1022 - val_mae: 265.1210 - val_mse: 140102.2344\n",
            "Epoch 525/1000\n",
            "76511/76511 - 5s - loss: 0.1066 - mae: 272.3086 - mse: 146823.0312 - val_loss: 0.1024 - val_mae: 266.1898 - val_mse: 143150.5938\n",
            "Epoch 526/1000\n",
            "76511/76511 - 5s - loss: 0.1064 - mae: 271.9968 - mse: 145651.8438 - val_loss: 0.1032 - val_mae: 268.2454 - val_mse: 147217.6719\n",
            "Epoch 527/1000\n",
            "76511/76511 - 5s - loss: 0.1068 - mae: 272.2162 - mse: 146051.0469 - val_loss: 0.1019 - val_mae: 264.4866 - val_mse: 140265.7969\n",
            "Epoch 528/1000\n",
            "76511/76511 - 5s - loss: 0.1064 - mae: 272.3359 - mse: 146797.0625 - val_loss: 0.1031 - val_mae: 269.0038 - val_mse: 149257.3281\n",
            "Epoch 529/1000\n",
            "76511/76511 - 5s - loss: 0.1061 - mae: 271.5081 - mse: 145323.9531 - val_loss: 0.1025 - val_mae: 264.8872 - val_mse: 139815.2500\n",
            "Epoch 530/1000\n",
            "76511/76511 - 6s - loss: 0.1063 - mae: 271.7607 - mse: 146273.9844 - val_loss: 0.1028 - val_mae: 266.8351 - val_mse: 144831.7656\n",
            "Epoch 531/1000\n",
            "76511/76511 - 6s - loss: 0.1063 - mae: 271.9692 - mse: 146352.4531 - val_loss: 0.1024 - val_mae: 266.0536 - val_mse: 143333.6719\n",
            "Epoch 532/1000\n",
            "76511/76511 - 6s - loss: 0.1066 - mae: 271.5135 - mse: 145738.4219 - val_loss: 0.1073 - val_mae: 277.2539 - val_mse: 163329.2500\n",
            "Epoch 533/1000\n",
            "76511/76511 - 6s - loss: 0.1065 - mae: 272.1018 - mse: 146521.5312 - val_loss: 0.1033 - val_mae: 266.5426 - val_mse: 142497.1875\n",
            "Epoch 534/1000\n",
            "76511/76511 - 6s - loss: 0.1066 - mae: 271.8020 - mse: 146308.8438 - val_loss: 0.1075 - val_mae: 278.0828 - val_mse: 164618.6719\n",
            "Epoch 535/1000\n",
            "76511/76511 - 6s - loss: 0.1065 - mae: 271.8085 - mse: 146562.8438 - val_loss: 0.1047 - val_mae: 271.1617 - val_mse: 152265.2500\n",
            "Epoch 536/1000\n",
            "76511/76511 - 6s - loss: 0.1063 - mae: 272.0895 - mse: 146907.2500 - val_loss: 0.1022 - val_mae: 265.0886 - val_mse: 140569.5625\n",
            "Epoch 537/1000\n",
            "76511/76511 - 5s - loss: 0.1058 - mae: 271.2928 - mse: 145655.1562 - val_loss: 0.1027 - val_mae: 266.6670 - val_mse: 143498.0312\n",
            "Epoch 538/1000\n",
            "76511/76511 - 6s - loss: 0.1064 - mae: 271.8379 - mse: 146396.5000 - val_loss: 0.1023 - val_mae: 264.9319 - val_mse: 140131.6406\n",
            "Epoch 539/1000\n",
            "76511/76511 - 6s - loss: 0.1066 - mae: 271.6573 - mse: 146285.7500 - val_loss: 0.1025 - val_mae: 266.4848 - val_mse: 143878.3906\n",
            "Epoch 540/1000\n",
            "76511/76511 - 6s - loss: 0.1057 - mae: 271.0114 - mse: 144598.2188 - val_loss: 0.1025 - val_mae: 265.3861 - val_mse: 141454.2500\n",
            "Epoch 541/1000\n",
            "76511/76511 - 6s - loss: 0.1058 - mae: 271.0244 - mse: 145335.6719 - val_loss: 0.1030 - val_mae: 266.5925 - val_mse: 143998.4062\n",
            "Epoch 542/1000\n",
            "76511/76511 - 6s - loss: 0.1061 - mae: 271.7874 - mse: 146182.5625 - val_loss: 0.1031 - val_mae: 268.0463 - val_mse: 146671.5625\n",
            "Epoch 543/1000\n",
            "76511/76511 - 6s - loss: 0.1063 - mae: 271.5450 - mse: 145816.0625 - val_loss: 0.1021 - val_mae: 265.5764 - val_mse: 141936.5781\n",
            "Epoch 544/1000\n",
            "76511/76511 - 6s - loss: 0.1061 - mae: 271.5604 - mse: 145509.2656 - val_loss: 0.1026 - val_mae: 265.7569 - val_mse: 141630.3594\n",
            "Epoch 545/1000\n",
            "76511/76511 - 6s - loss: 0.1060 - mae: 271.4301 - mse: 146117.1250 - val_loss: 0.1024 - val_mae: 267.1053 - val_mse: 145372.4688\n",
            "Epoch 546/1000\n",
            "76511/76511 - 6s - loss: 0.1063 - mae: 272.0045 - mse: 146101.2188 - val_loss: 0.1025 - val_mae: 266.4457 - val_mse: 144110.7969\n",
            "Epoch 547/1000\n",
            "76511/76511 - 6s - loss: 0.1063 - mae: 271.4263 - mse: 145747.7188 - val_loss: 0.1031 - val_mae: 267.8921 - val_mse: 145239.5156\n",
            "Epoch 548/1000\n",
            "76511/76511 - 6s - loss: 0.1059 - mae: 271.3972 - mse: 145272.6875 - val_loss: 0.1022 - val_mae: 266.1455 - val_mse: 142841.9844\n",
            "Epoch 549/1000\n",
            "76511/76511 - 6s - loss: 0.1068 - mae: 272.1996 - mse: 147574.8281 - val_loss: 0.1060 - val_mae: 274.9434 - val_mse: 159420.4844\n",
            "Epoch 550/1000\n",
            "76511/76511 - 6s - loss: 0.1057 - mae: 271.2210 - mse: 145044.9688 - val_loss: 0.1025 - val_mae: 266.5236 - val_mse: 143972.2969\n",
            "Epoch 551/1000\n",
            "76511/76511 - 6s - loss: 0.1062 - mae: 271.5754 - mse: 145790.8750 - val_loss: 0.1022 - val_mae: 265.2801 - val_mse: 141706.9219\n",
            "Epoch 552/1000\n",
            "76511/76511 - 6s - loss: 0.1059 - mae: 271.5231 - mse: 145838.0781 - val_loss: 0.1030 - val_mae: 267.7198 - val_mse: 147021.8594\n",
            "Epoch 553/1000\n",
            "76511/76511 - 6s - loss: 0.1057 - mae: 271.0827 - mse: 145100.7969 - val_loss: 0.1044 - val_mae: 270.8181 - val_mse: 151393.1719\n",
            "Epoch 554/1000\n",
            "76511/76511 - 6s - loss: 0.1058 - mae: 271.3983 - mse: 145764.7656 - val_loss: 0.1020 - val_mae: 264.5935 - val_mse: 140699.1406\n",
            "Epoch 555/1000\n",
            "76511/76511 - 6s - loss: 0.1060 - mae: 271.3210 - mse: 145567.0156 - val_loss: 0.1018 - val_mae: 265.1731 - val_mse: 142482.9844\n",
            "Epoch 556/1000\n",
            "76511/76511 - 6s - loss: 0.1059 - mae: 271.2155 - mse: 145097.4375 - val_loss: 0.1024 - val_mae: 264.9850 - val_mse: 140493.6719\n",
            "Epoch 557/1000\n",
            "76511/76511 - 6s - loss: 0.1063 - mae: 271.9347 - mse: 146154.0000 - val_loss: 0.1022 - val_mae: 265.4446 - val_mse: 142207.6094\n",
            "Epoch 558/1000\n",
            "76511/76511 - 6s - loss: 0.1060 - mae: 271.2944 - mse: 145238.6875 - val_loss: 0.1021 - val_mae: 265.5930 - val_mse: 142139.3750\n",
            "Epoch 559/1000\n",
            "76511/76511 - 6s - loss: 0.1063 - mae: 271.8878 - mse: 145689.8438 - val_loss: 0.1026 - val_mae: 265.3530 - val_mse: 140160.5781\n",
            "Epoch 560/1000\n",
            "76511/76511 - 6s - loss: 0.1062 - mae: 271.3204 - mse: 145810.1875 - val_loss: 0.1050 - val_mae: 272.4168 - val_mse: 155187.4844\n",
            "Epoch 561/1000\n",
            "76511/76511 - 6s - loss: 0.1060 - mae: 271.3606 - mse: 145419.3594 - val_loss: 0.1027 - val_mae: 267.5190 - val_mse: 147088.3750\n",
            "Epoch 562/1000\n",
            "76511/76511 - 6s - loss: 0.1056 - mae: 270.8149 - mse: 144918.0000 - val_loss: 0.1029 - val_mae: 267.4401 - val_mse: 145662.1719\n",
            "Epoch 563/1000\n",
            "76511/76511 - 6s - loss: 0.1057 - mae: 271.3943 - mse: 145714.3438 - val_loss: 0.1025 - val_mae: 267.0248 - val_mse: 145033.6250\n",
            "Epoch 564/1000\n",
            "76511/76511 - 6s - loss: 0.1059 - mae: 271.5093 - mse: 146383.3281 - val_loss: 0.1029 - val_mae: 267.7131 - val_mse: 146909.0625\n",
            "Epoch 565/1000\n",
            "76511/76511 - 6s - loss: 0.1058 - mae: 271.1504 - mse: 145795.7969 - val_loss: 0.1027 - val_mae: 266.6379 - val_mse: 144044.6250\n",
            "Epoch 566/1000\n",
            "76511/76511 - 6s - loss: 0.1054 - mae: 271.0941 - mse: 145082.2344 - val_loss: 0.1029 - val_mae: 267.6064 - val_mse: 146993.2969\n",
            "Epoch 567/1000\n",
            "76511/76511 - 6s - loss: 0.1056 - mae: 270.9041 - mse: 145432.6719 - val_loss: 0.1026 - val_mae: 266.4405 - val_mse: 143583.5156\n",
            "Epoch 568/1000\n",
            "76511/76511 - 6s - loss: 0.1061 - mae: 271.4311 - mse: 145814.6250 - val_loss: 0.1049 - val_mae: 272.4716 - val_mse: 154999.7344\n",
            "Epoch 569/1000\n",
            "76511/76511 - 6s - loss: 0.1059 - mae: 271.0310 - mse: 145082.6094 - val_loss: 0.1025 - val_mae: 266.2226 - val_mse: 143066.1719\n",
            "Epoch 570/1000\n",
            "76511/76511 - 6s - loss: 0.1057 - mae: 270.4843 - mse: 145049.1250 - val_loss: 0.1024 - val_mae: 265.2342 - val_mse: 140526.3281\n",
            "Epoch 571/1000\n",
            "76511/76511 - 5s - loss: 0.1055 - mae: 270.5514 - mse: 144900.4062 - val_loss: 0.1026 - val_mae: 265.3656 - val_mse: 141700.2500\n",
            "Epoch 572/1000\n",
            "76511/76511 - 6s - loss: 0.1060 - mae: 271.4566 - mse: 145485.6875 - val_loss: 0.1025 - val_mae: 265.0800 - val_mse: 139742.9531\n",
            "Epoch 573/1000\n",
            "76511/76511 - 6s - loss: 0.1063 - mae: 271.9012 - mse: 146309.7344 - val_loss: 0.1032 - val_mae: 268.0526 - val_mse: 146966.6719\n",
            "Epoch 574/1000\n",
            "76511/76511 - 5s - loss: 0.1061 - mae: 271.7492 - mse: 146246.4688 - val_loss: 0.1023 - val_mae: 266.1340 - val_mse: 143867.4531\n",
            "Epoch 575/1000\n",
            "76511/76511 - 5s - loss: 0.1058 - mae: 271.5388 - mse: 146353.1875 - val_loss: 0.1046 - val_mae: 270.7855 - val_mse: 151451.9375\n",
            "Epoch 576/1000\n",
            "76511/76511 - 5s - loss: 0.1061 - mae: 271.2445 - mse: 145453.4844 - val_loss: 0.1029 - val_mae: 265.8408 - val_mse: 142989.1094\n",
            "Epoch 577/1000\n",
            "76511/76511 - 6s - loss: 0.1056 - mae: 270.8178 - mse: 145216.2969 - val_loss: 0.1027 - val_mae: 267.5087 - val_mse: 146372.2500\n",
            "Epoch 578/1000\n",
            "76511/76511 - 6s - loss: 0.1063 - mae: 271.6821 - mse: 146453.2969 - val_loss: 0.1026 - val_mae: 266.4694 - val_mse: 145159.6406\n",
            "Epoch 579/1000\n",
            "76511/76511 - 6s - loss: 0.1055 - mae: 270.3516 - mse: 144823.2500 - val_loss: 0.1023 - val_mae: 266.3201 - val_mse: 144216.2500\n",
            "Epoch 580/1000\n",
            "76511/76511 - 6s - loss: 0.1059 - mae: 271.3022 - mse: 146186.1719 - val_loss: 0.1020 - val_mae: 264.9707 - val_mse: 141087.2344\n",
            "Epoch 581/1000\n",
            "76511/76511 - 6s - loss: 0.1060 - mae: 270.8533 - mse: 145366.5938 - val_loss: 0.1025 - val_mae: 265.0245 - val_mse: 140557.1250\n",
            "Epoch 582/1000\n",
            "76511/76511 - 6s - loss: 0.1062 - mae: 271.5647 - mse: 145382.0938 - val_loss: 0.1038 - val_mae: 268.6181 - val_mse: 146950.3281\n",
            "Epoch 583/1000\n",
            "76511/76511 - 6s - loss: 0.1055 - mae: 270.7967 - mse: 145490.3438 - val_loss: 0.1025 - val_mae: 266.0159 - val_mse: 143779.2188\n",
            "Epoch 584/1000\n",
            "76511/76511 - 6s - loss: 0.1057 - mae: 270.7503 - mse: 144998.1094 - val_loss: 0.1027 - val_mae: 266.6151 - val_mse: 144878.3281\n",
            "Epoch 585/1000\n",
            "76511/76511 - 6s - loss: 0.1058 - mae: 271.1460 - mse: 145738.4375 - val_loss: 0.1023 - val_mae: 264.7266 - val_mse: 140150.2500\n",
            "Epoch 586/1000\n",
            "76511/76511 - 6s - loss: 0.1063 - mae: 271.9037 - mse: 146883.9062 - val_loss: 0.1038 - val_mae: 269.7005 - val_mse: 150066.0156\n",
            "Epoch 587/1000\n",
            "76511/76511 - 6s - loss: 0.1053 - mae: 270.5852 - mse: 144762.8906 - val_loss: 0.1038 - val_mae: 270.0241 - val_mse: 150220.8906\n",
            "Epoch 588/1000\n",
            "76511/76511 - 6s - loss: 0.1059 - mae: 270.9870 - mse: 145981.5000 - val_loss: 0.1044 - val_mae: 270.5210 - val_mse: 150525.1719\n",
            "Epoch 589/1000\n",
            "76511/76511 - 6s - loss: 0.1060 - mae: 271.0457 - mse: 145329.0938 - val_loss: 0.1026 - val_mae: 265.5269 - val_mse: 141923.1250\n",
            "Epoch 590/1000\n",
            "76511/76511 - 6s - loss: 0.1055 - mae: 270.2432 - mse: 145165.7500 - val_loss: 0.1045 - val_mae: 271.2340 - val_mse: 152757.7031\n",
            "Epoch 591/1000\n",
            "76511/76511 - 6s - loss: 0.1066 - mae: 271.3001 - mse: 145867.9375 - val_loss: 0.1030 - val_mae: 265.9094 - val_mse: 140782.8594\n",
            "Epoch 592/1000\n",
            "76511/76511 - 6s - loss: 0.1061 - mae: 271.7112 - mse: 145489.1406 - val_loss: 0.1027 - val_mae: 265.7908 - val_mse: 142661.2344\n",
            "Epoch 593/1000\n",
            "76511/76511 - 6s - loss: 0.1057 - mae: 271.0554 - mse: 145708.6719 - val_loss: 0.1039 - val_mae: 270.3083 - val_mse: 151417.0312\n",
            "Epoch 594/1000\n",
            "76511/76511 - 6s - loss: 0.1058 - mae: 271.0372 - mse: 146024.2031 - val_loss: 0.1043 - val_mae: 271.5897 - val_mse: 153886.8281\n",
            "Epoch 595/1000\n",
            "76511/76511 - 6s - loss: 0.1055 - mae: 270.4761 - mse: 144887.0469 - val_loss: 0.1040 - val_mae: 270.2551 - val_mse: 151320.9062\n",
            "Epoch 596/1000\n",
            "76511/76511 - 6s - loss: 0.1057 - mae: 270.9370 - mse: 145589.4219 - val_loss: 0.1037 - val_mae: 268.7768 - val_mse: 148538.6719\n",
            "Epoch 597/1000\n",
            "76511/76511 - 6s - loss: 0.1059 - mae: 271.4712 - mse: 145551.3438 - val_loss: 0.1045 - val_mae: 270.6428 - val_mse: 151659.2344\n",
            "Epoch 598/1000\n",
            "76511/76511 - 6s - loss: 0.1055 - mae: 270.6937 - mse: 145389.9531 - val_loss: 0.1023 - val_mae: 265.3062 - val_mse: 141228.8750\n",
            "Epoch 599/1000\n",
            "76511/76511 - 6s - loss: 0.1061 - mae: 271.4097 - mse: 145784.3750 - val_loss: 0.1041 - val_mae: 270.5076 - val_mse: 151590.7500\n",
            "Epoch 600/1000\n",
            "76511/76511 - 6s - loss: 0.1059 - mae: 271.3642 - mse: 145229.2031 - val_loss: 0.1032 - val_mae: 268.7799 - val_mse: 149071.6250\n",
            "Epoch 601/1000\n",
            "76511/76511 - 6s - loss: 0.1062 - mae: 271.0785 - mse: 145427.6250 - val_loss: 0.1030 - val_mae: 267.0593 - val_mse: 145973.0312\n",
            "Epoch 602/1000\n",
            "76511/76511 - 6s - loss: 0.1058 - mae: 270.6571 - mse: 144762.9688 - val_loss: 0.1030 - val_mae: 266.7107 - val_mse: 144050.4375\n",
            "Epoch 603/1000\n",
            "76511/76511 - 6s - loss: 0.1056 - mae: 270.8788 - mse: 145718.9844 - val_loss: 0.1024 - val_mae: 264.8398 - val_mse: 139943.1875\n",
            "Epoch 604/1000\n",
            "76511/76511 - 6s - loss: 0.1054 - mae: 270.8565 - mse: 146004.5312 - val_loss: 0.1060 - val_mae: 275.0697 - val_mse: 159863.4688\n",
            "Epoch 605/1000\n",
            "76511/76511 - 6s - loss: 0.1061 - mae: 271.2978 - mse: 145629.8281 - val_loss: 0.1045 - val_mae: 270.4601 - val_mse: 150848.6719\n",
            "Epoch 606/1000\n",
            "76511/76511 - 6s - loss: 0.1064 - mae: 271.4092 - mse: 145428.4219 - val_loss: 0.1027 - val_mae: 266.6387 - val_mse: 144426.4062\n",
            "Epoch 607/1000\n",
            "76511/76511 - 5s - loss: 0.1056 - mae: 271.0201 - mse: 145202.5000 - val_loss: 0.1039 - val_mae: 270.0947 - val_mse: 150931.8438\n",
            "Epoch 608/1000\n",
            "76511/76511 - 6s - loss: 0.1058 - mae: 271.5861 - mse: 146051.1406 - val_loss: 0.1029 - val_mae: 267.6576 - val_mse: 147041.2656\n",
            "Epoch 609/1000\n",
            "76511/76511 - 6s - loss: 0.1059 - mae: 271.3541 - mse: 146281.0938 - val_loss: 0.1025 - val_mae: 266.4964 - val_mse: 143617.0781\n",
            "Epoch 610/1000\n",
            "76511/76511 - 6s - loss: 0.1051 - mae: 270.6235 - mse: 145251.4375 - val_loss: 0.1031 - val_mae: 267.7334 - val_mse: 145414.6719\n",
            "Epoch 611/1000\n",
            "76511/76511 - 6s - loss: 0.1064 - mae: 271.3096 - mse: 146362.8906 - val_loss: 0.1039 - val_mae: 269.9091 - val_mse: 150334.0625\n",
            "Epoch 612/1000\n",
            "76511/76511 - 6s - loss: 0.1053 - mae: 270.4625 - mse: 145354.4844 - val_loss: 0.1025 - val_mae: 267.1149 - val_mse: 144282.5469\n",
            "Epoch 613/1000\n",
            "76511/76511 - 6s - loss: 0.1057 - mae: 271.1921 - mse: 145642.9844 - val_loss: 0.1028 - val_mae: 267.5856 - val_mse: 146739.9062\n",
            "Epoch 614/1000\n",
            "76511/76511 - 6s - loss: 0.1053 - mae: 270.8128 - mse: 145274.0312 - val_loss: 0.1027 - val_mae: 266.1295 - val_mse: 142998.7031\n",
            "Epoch 615/1000\n",
            "76511/76511 - 6s - loss: 0.1060 - mae: 270.7933 - mse: 145715.6406 - val_loss: 0.1038 - val_mae: 269.5227 - val_mse: 149941.0625\n",
            "Epoch 616/1000\n",
            "76511/76511 - 6s - loss: 0.1062 - mae: 270.6632 - mse: 145126.5781 - val_loss: 0.1026 - val_mae: 265.1382 - val_mse: 139732.1094\n",
            "Epoch 617/1000\n",
            "76511/76511 - 6s - loss: 0.1057 - mae: 271.2346 - mse: 145815.3281 - val_loss: 0.1021 - val_mae: 265.0666 - val_mse: 140658.4375\n",
            "Epoch 618/1000\n",
            "76511/76511 - 6s - loss: 0.1052 - mae: 270.3271 - mse: 145019.8125 - val_loss: 0.1026 - val_mae: 265.3430 - val_mse: 139803.9375\n",
            "Epoch 619/1000\n",
            "76511/76511 - 6s - loss: 0.1050 - mae: 270.2879 - mse: 144912.1875 - val_loss: 0.1022 - val_mae: 264.9407 - val_mse: 141342.0156\n",
            "Epoch 620/1000\n",
            "76511/76511 - 6s - loss: 0.1053 - mae: 270.6348 - mse: 145633.3594 - val_loss: 0.1021 - val_mae: 265.2629 - val_mse: 141247.0625\n",
            "Epoch 621/1000\n",
            "76511/76511 - 6s - loss: 0.1054 - mae: 270.3856 - mse: 144843.8281 - val_loss: 0.1027 - val_mae: 265.6245 - val_mse: 141859.6875\n",
            "Epoch 622/1000\n",
            "76511/76511 - 6s - loss: 0.1053 - mae: 270.2357 - mse: 144646.4219 - val_loss: 0.1039 - val_mae: 269.9722 - val_mse: 150567.8906\n",
            "Epoch 623/1000\n",
            "76511/76511 - 6s - loss: 0.1057 - mae: 270.4142 - mse: 144225.7188 - val_loss: 0.1035 - val_mae: 269.0576 - val_mse: 148941.7656\n",
            "Epoch 624/1000\n",
            "76511/76511 - 6s - loss: 0.1052 - mae: 270.4218 - mse: 144984.2500 - val_loss: 0.1046 - val_mae: 272.2278 - val_mse: 154496.2344\n",
            "Epoch 625/1000\n",
            "76511/76511 - 6s - loss: 0.1056 - mae: 270.8120 - mse: 145781.5938 - val_loss: 0.1025 - val_mae: 265.8707 - val_mse: 142537.2656\n",
            "Epoch 626/1000\n",
            "76511/76511 - 6s - loss: 0.1060 - mae: 270.9882 - mse: 145938.1875 - val_loss: 0.1029 - val_mae: 267.1900 - val_mse: 145127.4844\n",
            "Epoch 627/1000\n",
            "76511/76511 - 6s - loss: 0.1057 - mae: 271.3782 - mse: 146006.3281 - val_loss: 0.1034 - val_mae: 268.3762 - val_mse: 147740.1719\n",
            "Epoch 628/1000\n",
            "76511/76511 - 6s - loss: 0.1063 - mae: 271.1361 - mse: 145603.2812 - val_loss: 0.1056 - val_mae: 273.6978 - val_mse: 155889.1719\n",
            "Epoch 629/1000\n",
            "76511/76511 - 6s - loss: 0.1052 - mae: 270.0351 - mse: 144555.6094 - val_loss: 0.1051 - val_mae: 271.8829 - val_mse: 153508.0312\n",
            "Epoch 630/1000\n",
            "76511/76511 - 6s - loss: 0.1052 - mae: 270.5426 - mse: 145624.0469 - val_loss: 0.1024 - val_mae: 266.5496 - val_mse: 144878.2344\n",
            "Epoch 631/1000\n",
            "76511/76511 - 6s - loss: 0.1049 - mae: 270.5895 - mse: 144871.9219 - val_loss: 0.1062 - val_mae: 274.9825 - val_mse: 159787.0156\n",
            "Epoch 632/1000\n",
            "76511/76511 - 6s - loss: 0.1053 - mae: 270.3655 - mse: 145592.2344 - val_loss: 0.1025 - val_mae: 265.6648 - val_mse: 142484.0156\n",
            "Epoch 633/1000\n",
            "76511/76511 - 6s - loss: 0.1062 - mae: 271.4007 - mse: 146338.0469 - val_loss: 0.1027 - val_mae: 265.8248 - val_mse: 142518.2031\n",
            "Epoch 634/1000\n",
            "76511/76511 - 6s - loss: 0.1051 - mae: 269.6785 - mse: 144610.8750 - val_loss: 0.1032 - val_mae: 265.9168 - val_mse: 140915.8281\n",
            "Epoch 635/1000\n",
            "76511/76511 - 6s - loss: 0.1051 - mae: 270.5358 - mse: 144773.7500 - val_loss: 0.1034 - val_mae: 266.5579 - val_mse: 141520.7500\n",
            "Epoch 636/1000\n",
            "76511/76511 - 6s - loss: 0.1056 - mae: 270.4790 - mse: 145219.9062 - val_loss: 0.1024 - val_mae: 265.3851 - val_mse: 141444.9844\n",
            "Epoch 637/1000\n",
            "76511/76511 - 6s - loss: 0.1057 - mae: 270.5283 - mse: 145156.9062 - val_loss: 0.1040 - val_mae: 270.1420 - val_mse: 150673.6875\n",
            "Epoch 638/1000\n",
            "76511/76511 - 6s - loss: 0.1054 - mae: 270.4857 - mse: 145037.2969 - val_loss: 0.1043 - val_mae: 271.2377 - val_mse: 152912.9688\n",
            "Epoch 639/1000\n",
            "76511/76511 - 6s - loss: 0.1050 - mae: 269.8631 - mse: 144116.4219 - val_loss: 0.1032 - val_mae: 267.8828 - val_mse: 146593.7188\n",
            "Epoch 640/1000\n",
            "76511/76511 - 6s - loss: 0.1057 - mae: 271.1447 - mse: 145272.5469 - val_loss: 0.1031 - val_mae: 268.2980 - val_mse: 147378.8906\n",
            "Epoch 641/1000\n",
            "76511/76511 - 6s - loss: 0.1062 - mae: 271.1908 - mse: 146249.4531 - val_loss: 0.1024 - val_mae: 265.9432 - val_mse: 141956.1562\n",
            "Epoch 642/1000\n",
            "76511/76511 - 6s - loss: 0.1052 - mae: 270.4275 - mse: 144709.9688 - val_loss: 0.1044 - val_mae: 270.6321 - val_mse: 151651.2344\n",
            "Epoch 643/1000\n",
            "76511/76511 - 6s - loss: 0.1051 - mae: 270.5417 - mse: 145069.1719 - val_loss: 0.1035 - val_mae: 268.2503 - val_mse: 146642.1875\n",
            "Epoch 644/1000\n",
            "76511/76511 - 6s - loss: 0.1052 - mae: 270.4196 - mse: 145159.5469 - val_loss: 0.1041 - val_mae: 270.1458 - val_mse: 150832.4375\n",
            "Epoch 645/1000\n",
            "76511/76511 - 6s - loss: 0.1052 - mae: 270.1692 - mse: 144796.6250 - val_loss: 0.1028 - val_mae: 267.2180 - val_mse: 146394.8906\n",
            "Epoch 646/1000\n",
            "76511/76511 - 6s - loss: 0.1057 - mae: 271.0398 - mse: 145749.5312 - val_loss: 0.1034 - val_mae: 268.4569 - val_mse: 147110.2188\n",
            "Epoch 647/1000\n",
            "76511/76511 - 6s - loss: 0.1051 - mae: 270.1035 - mse: 144675.0469 - val_loss: 0.1029 - val_mae: 265.4767 - val_mse: 139634.0000\n",
            "Epoch 648/1000\n",
            "76511/76511 - 6s - loss: 0.1055 - mae: 270.8887 - mse: 145732.7969 - val_loss: 0.1024 - val_mae: 266.3803 - val_mse: 143450.4531\n",
            "Epoch 649/1000\n",
            "76511/76511 - 6s - loss: 0.1055 - mae: 270.5725 - mse: 145129.1094 - val_loss: 0.1026 - val_mae: 265.1177 - val_mse: 139930.6094\n",
            "Epoch 650/1000\n",
            "76511/76511 - 6s - loss: 0.1054 - mae: 270.3591 - mse: 145214.9688 - val_loss: 0.1055 - val_mae: 273.3387 - val_mse: 156619.7812\n",
            "Epoch 651/1000\n",
            "76511/76511 - 6s - loss: 0.1056 - mae: 271.1561 - mse: 145674.6406 - val_loss: 0.1049 - val_mae: 271.9978 - val_mse: 154006.0781\n",
            "Epoch 652/1000\n",
            "76511/76511 - 6s - loss: 0.1054 - mae: 270.5341 - mse: 145104.0312 - val_loss: 0.1028 - val_mae: 266.5826 - val_mse: 143789.4219\n",
            "Epoch 653/1000\n",
            "76511/76511 - 6s - loss: 0.1051 - mae: 270.6804 - mse: 145177.4062 - val_loss: 0.1027 - val_mae: 265.4731 - val_mse: 141554.0000\n",
            "Epoch 654/1000\n",
            "76511/76511 - 6s - loss: 0.1050 - mae: 269.8356 - mse: 144093.9375 - val_loss: 0.1029 - val_mae: 267.7794 - val_mse: 147176.0625\n",
            "Epoch 655/1000\n",
            "76511/76511 - 6s - loss: 0.1053 - mae: 270.3431 - mse: 145145.2656 - val_loss: 0.1027 - val_mae: 267.2440 - val_mse: 145367.6094\n",
            "Epoch 656/1000\n",
            "76511/76511 - 6s - loss: 0.1056 - mae: 271.0096 - mse: 145445.0781 - val_loss: 0.1030 - val_mae: 267.1841 - val_mse: 144885.5000\n",
            "Epoch 657/1000\n",
            "76511/76511 - 6s - loss: 0.1051 - mae: 270.1272 - mse: 144346.6406 - val_loss: 0.1030 - val_mae: 266.6841 - val_mse: 143272.4375\n",
            "Epoch 658/1000\n",
            "76511/76511 - 5s - loss: 0.1052 - mae: 271.0600 - mse: 145443.8125 - val_loss: 0.1030 - val_mae: 265.4957 - val_mse: 141211.3281\n",
            "Epoch 659/1000\n",
            "76511/76511 - 6s - loss: 0.1055 - mae: 270.9519 - mse: 145404.7969 - val_loss: 0.1028 - val_mae: 266.9944 - val_mse: 144824.8594\n",
            "Epoch 660/1000\n",
            "76511/76511 - 6s - loss: 0.1050 - mae: 270.0841 - mse: 144390.6719 - val_loss: 0.1032 - val_mae: 268.3499 - val_mse: 147701.7656\n",
            "Epoch 661/1000\n",
            "76511/76511 - 6s - loss: 0.1050 - mae: 269.9972 - mse: 145024.5469 - val_loss: 0.1041 - val_mae: 269.8863 - val_mse: 150462.6094\n",
            "Epoch 662/1000\n",
            "76511/76511 - 6s - loss: 0.1054 - mae: 270.6362 - mse: 145238.5156 - val_loss: 0.1030 - val_mae: 265.8074 - val_mse: 140541.7031\n",
            "Epoch 663/1000\n",
            "76511/76511 - 6s - loss: 0.1052 - mae: 270.3070 - mse: 144236.8594 - val_loss: 0.1031 - val_mae: 267.4559 - val_mse: 144906.4844\n",
            "Epoch 664/1000\n",
            "76511/76511 - 6s - loss: 0.1053 - mae: 270.8033 - mse: 145207.1875 - val_loss: 0.1021 - val_mae: 265.5280 - val_mse: 142096.7188\n",
            "Epoch 665/1000\n",
            "76511/76511 - 6s - loss: 0.1048 - mae: 269.4308 - mse: 144320.5781 - val_loss: 0.1039 - val_mae: 269.3733 - val_mse: 149058.8750\n",
            "Epoch 666/1000\n",
            "76511/76511 - 6s - loss: 0.1056 - mae: 271.3987 - mse: 146403.5469 - val_loss: 0.1025 - val_mae: 266.0789 - val_mse: 143362.8438\n",
            "Epoch 667/1000\n",
            "76511/76511 - 7s - loss: 0.1050 - mae: 270.4689 - mse: 144278.1875 - val_loss: 0.1031 - val_mae: 268.1573 - val_mse: 147395.8438\n",
            "Epoch 668/1000\n",
            "76511/76511 - 5s - loss: 0.1055 - mae: 270.9053 - mse: 145878.0781 - val_loss: 0.1032 - val_mae: 267.0829 - val_mse: 144913.3594\n",
            "Epoch 669/1000\n",
            "76511/76511 - 6s - loss: 0.1053 - mae: 270.4610 - mse: 145006.5938 - val_loss: 0.1029 - val_mae: 265.8673 - val_mse: 142477.8594\n",
            "Epoch 670/1000\n",
            "76511/76511 - 6s - loss: 0.1049 - mae: 270.0771 - mse: 144693.9688 - val_loss: 0.1077 - val_mae: 277.5426 - val_mse: 162511.0156\n",
            "Epoch 671/1000\n",
            "76511/76511 - 6s - loss: 0.1051 - mae: 270.2137 - mse: 144363.5156 - val_loss: 0.1033 - val_mae: 268.6108 - val_mse: 148751.1094\n",
            "Epoch 672/1000\n",
            "76511/76511 - 6s - loss: 0.1051 - mae: 270.4177 - mse: 145213.0938 - val_loss: 0.1041 - val_mae: 270.5699 - val_mse: 151917.0625\n",
            "Epoch 673/1000\n",
            "76511/76511 - 6s - loss: 0.1054 - mae: 271.1625 - mse: 145403.8906 - val_loss: 0.1030 - val_mae: 265.7557 - val_mse: 142155.4531\n",
            "Epoch 674/1000\n",
            "76511/76511 - 6s - loss: 0.1049 - mae: 269.9979 - mse: 144760.4375 - val_loss: 0.1027 - val_mae: 266.0103 - val_mse: 143210.3438\n",
            "Epoch 675/1000\n",
            "76511/76511 - 6s - loss: 0.1055 - mae: 271.0692 - mse: 146081.9688 - val_loss: 0.1031 - val_mae: 266.6188 - val_mse: 144620.2969\n",
            "Epoch 676/1000\n",
            "76511/76511 - 6s - loss: 0.1049 - mae: 270.2793 - mse: 145028.3281 - val_loss: 0.1028 - val_mae: 265.1593 - val_mse: 140046.4844\n",
            "Epoch 677/1000\n",
            "76511/76511 - 6s - loss: 0.1047 - mae: 269.6308 - mse: 144364.4219 - val_loss: 0.1059 - val_mae: 274.1998 - val_mse: 157909.5938\n",
            "Epoch 678/1000\n",
            "76511/76511 - 6s - loss: 0.1049 - mae: 269.8592 - mse: 144445.1406 - val_loss: 0.1033 - val_mae: 268.5630 - val_mse: 147838.7188\n",
            "Epoch 679/1000\n",
            "76511/76511 - 7s - loss: 0.1051 - mae: 270.2534 - mse: 145340.1250 - val_loss: 0.1032 - val_mae: 266.3318 - val_mse: 141422.2188\n",
            "Epoch 680/1000\n",
            "76511/76511 - 6s - loss: 0.1054 - mae: 270.3230 - mse: 145025.9219 - val_loss: 0.1030 - val_mae: 266.9370 - val_mse: 144455.7188\n",
            "Epoch 681/1000\n",
            "76511/76511 - 6s - loss: 0.1047 - mae: 270.0201 - mse: 144991.6406 - val_loss: 0.1044 - val_mae: 270.2924 - val_mse: 150703.2500\n",
            "Epoch 682/1000\n",
            "76511/76511 - 6s - loss: 0.1052 - mae: 270.9406 - mse: 145629.6250 - val_loss: 0.1024 - val_mae: 265.3979 - val_mse: 141501.9062\n",
            "Epoch 683/1000\n",
            "76511/76511 - 6s - loss: 0.1047 - mae: 269.5260 - mse: 144441.4375 - val_loss: 0.1028 - val_mae: 265.6334 - val_mse: 141161.5156\n",
            "Epoch 684/1000\n",
            "76511/76511 - 6s - loss: 0.1048 - mae: 269.5764 - mse: 143480.5000 - val_loss: 0.1032 - val_mae: 267.6274 - val_mse: 146572.5938\n",
            "Epoch 685/1000\n",
            "76511/76511 - 6s - loss: 0.1054 - mae: 270.4568 - mse: 145056.5938 - val_loss: 0.1048 - val_mae: 271.5644 - val_mse: 153040.9375\n",
            "Epoch 686/1000\n",
            "76511/76511 - 6s - loss: 0.1052 - mae: 270.1288 - mse: 145228.4375 - val_loss: 0.1024 - val_mae: 264.9309 - val_mse: 140518.4062\n",
            "Epoch 687/1000\n",
            "76511/76511 - 6s - loss: 0.1053 - mae: 270.2454 - mse: 145132.0156 - val_loss: 0.1046 - val_mae: 270.9084 - val_mse: 152650.3594\n",
            "Epoch 688/1000\n",
            "76511/76511 - 6s - loss: 0.1050 - mae: 269.9892 - mse: 144641.9844 - val_loss: 0.1031 - val_mae: 266.0305 - val_mse: 141725.2500\n",
            "Epoch 689/1000\n",
            "76511/76511 - 6s - loss: 0.1049 - mae: 270.3189 - mse: 144588.2969 - val_loss: 0.1024 - val_mae: 265.8816 - val_mse: 142387.3438\n",
            "Epoch 690/1000\n",
            "76511/76511 - 6s - loss: 0.1048 - mae: 270.0149 - mse: 144517.9531 - val_loss: 0.1041 - val_mae: 269.5110 - val_mse: 148790.1719\n",
            "Epoch 691/1000\n",
            "76511/76511 - 6s - loss: 0.1047 - mae: 269.7943 - mse: 144139.3125 - val_loss: 0.1048 - val_mae: 272.1458 - val_mse: 154515.1562\n",
            "Epoch 692/1000\n",
            "76511/76511 - 6s - loss: 0.1048 - mae: 269.9594 - mse: 144729.8281 - val_loss: 0.1026 - val_mae: 265.9327 - val_mse: 142918.3125\n",
            "Epoch 693/1000\n",
            "76511/76511 - 6s - loss: 0.1049 - mae: 269.8751 - mse: 144967.1094 - val_loss: 0.1056 - val_mae: 273.6863 - val_mse: 156723.4219\n",
            "Epoch 694/1000\n",
            "76511/76511 - 6s - loss: 0.1046 - mae: 269.8150 - mse: 144639.7344 - val_loss: 0.1034 - val_mae: 265.9585 - val_mse: 141369.4219\n",
            "Epoch 695/1000\n",
            "76511/76511 - 6s - loss: 0.1050 - mae: 270.2789 - mse: 145267.9062 - val_loss: 0.1033 - val_mae: 265.9369 - val_mse: 140453.7969\n",
            "Epoch 696/1000\n",
            "76511/76511 - 6s - loss: 0.1052 - mae: 269.6897 - mse: 144147.9062 - val_loss: 0.1023 - val_mae: 265.2807 - val_mse: 141677.9062\n",
            "Epoch 697/1000\n",
            "76511/76511 - 6s - loss: 0.1050 - mae: 269.5186 - mse: 144146.8594 - val_loss: 0.1030 - val_mae: 266.9691 - val_mse: 145388.3594\n",
            "Epoch 698/1000\n",
            "76511/76511 - 6s - loss: 0.1048 - mae: 269.4654 - mse: 143975.4688 - val_loss: 0.1030 - val_mae: 266.7160 - val_mse: 143567.8906\n",
            "Epoch 699/1000\n",
            "76511/76511 - 6s - loss: 0.1052 - mae: 270.3513 - mse: 144362.1719 - val_loss: 0.1036 - val_mae: 268.1853 - val_mse: 146607.1406\n",
            "Epoch 700/1000\n",
            "76511/76511 - 6s - loss: 0.1051 - mae: 270.2729 - mse: 145359.7812 - val_loss: 0.1025 - val_mae: 266.2116 - val_mse: 144091.3438\n",
            "Epoch 701/1000\n",
            "76511/76511 - 6s - loss: 0.1052 - mae: 270.5363 - mse: 146247.2500 - val_loss: 0.1027 - val_mae: 266.2475 - val_mse: 143687.2344\n",
            "Epoch 702/1000\n",
            "76511/76511 - 6s - loss: 0.1053 - mae: 270.5996 - mse: 145560.5781 - val_loss: 0.1029 - val_mae: 267.2522 - val_mse: 145679.3750\n",
            "Epoch 703/1000\n",
            "76511/76511 - 6s - loss: 0.1048 - mae: 270.1399 - mse: 144428.6562 - val_loss: 0.1050 - val_mae: 272.3496 - val_mse: 154378.9062\n",
            "Epoch 704/1000\n",
            "76511/76511 - 6s - loss: 0.1047 - mae: 269.5244 - mse: 144252.6406 - val_loss: 0.1078 - val_mae: 278.6029 - val_mse: 165598.6719\n",
            "Epoch 705/1000\n",
            "76511/76511 - 6s - loss: 0.1046 - mae: 269.9248 - mse: 144540.8594 - val_loss: 0.1023 - val_mae: 265.6227 - val_mse: 142329.4219\n",
            "Epoch 706/1000\n",
            "76511/76511 - 6s - loss: 0.1048 - mae: 269.7900 - mse: 144309.5938 - val_loss: 0.1025 - val_mae: 265.5551 - val_mse: 142110.2500\n",
            "Epoch 707/1000\n",
            "76511/76511 - 6s - loss: 0.1050 - mae: 270.4297 - mse: 145588.9844 - val_loss: 0.1038 - val_mae: 269.6199 - val_mse: 149901.7188\n",
            "Epoch 708/1000\n",
            "76511/76511 - 6s - loss: 0.1043 - mae: 269.2761 - mse: 143547.4375 - val_loss: 0.1039 - val_mae: 267.3213 - val_mse: 143680.6250\n",
            "Epoch 709/1000\n",
            "76511/76511 - 6s - loss: 0.1051 - mae: 270.0736 - mse: 144722.1406 - val_loss: 0.1033 - val_mae: 268.0855 - val_mse: 147110.9531\n",
            "Epoch 710/1000\n",
            "76511/76511 - 6s - loss: 0.1050 - mae: 270.5168 - mse: 145011.9688 - val_loss: 0.1026 - val_mae: 265.8839 - val_mse: 142304.9062\n",
            "Epoch 711/1000\n",
            "76511/76511 - 6s - loss: 0.1049 - mae: 269.8879 - mse: 145481.0312 - val_loss: 0.1033 - val_mae: 268.7747 - val_mse: 148531.4219\n",
            "Epoch 712/1000\n",
            "76511/76511 - 5s - loss: 0.1059 - mae: 270.0837 - mse: 145348.0469 - val_loss: 0.1056 - val_mae: 273.6790 - val_mse: 156340.0000\n",
            "Epoch 713/1000\n",
            "76511/76511 - 6s - loss: 0.1052 - mae: 270.3111 - mse: 145067.9688 - val_loss: 0.1033 - val_mae: 267.2012 - val_mse: 144283.0938\n",
            "Epoch 714/1000\n",
            "76511/76511 - 6s - loss: 0.1047 - mae: 270.2705 - mse: 144190.7031 - val_loss: 0.1025 - val_mae: 265.4370 - val_mse: 141569.3594\n",
            "Epoch 715/1000\n",
            "76511/76511 - 6s - loss: 0.1049 - mae: 269.9075 - mse: 145526.2344 - val_loss: 0.1034 - val_mae: 268.7791 - val_mse: 148159.8750\n",
            "Epoch 716/1000\n",
            "76511/76511 - 6s - loss: 0.1046 - mae: 269.7005 - mse: 144114.7812 - val_loss: 0.1028 - val_mae: 265.6666 - val_mse: 141492.5000\n",
            "Epoch 717/1000\n",
            "76511/76511 - 6s - loss: 0.1053 - mae: 269.7475 - mse: 144681.4844 - val_loss: 0.1025 - val_mae: 265.0737 - val_mse: 139824.5469\n",
            "Epoch 718/1000\n",
            "76511/76511 - 6s - loss: 0.1052 - mae: 270.3812 - mse: 145433.0156 - val_loss: 0.1028 - val_mae: 265.7332 - val_mse: 143074.5469\n",
            "Epoch 719/1000\n",
            "76511/76511 - 6s - loss: 0.1048 - mae: 270.2368 - mse: 144870.9062 - val_loss: 0.1042 - val_mae: 269.8657 - val_mse: 150545.1406\n",
            "Epoch 720/1000\n",
            "76511/76511 - 6s - loss: 0.1053 - mae: 270.0664 - mse: 144693.2500 - val_loss: 0.1047 - val_mae: 271.6056 - val_mse: 152562.0156\n",
            "Epoch 721/1000\n",
            "76511/76511 - 6s - loss: 0.1049 - mae: 269.7914 - mse: 144188.5938 - val_loss: 0.1031 - val_mae: 266.4117 - val_mse: 143103.2188\n",
            "Epoch 722/1000\n",
            "76511/76511 - 6s - loss: 0.1055 - mae: 270.6458 - mse: 145353.4219 - val_loss: 0.1041 - val_mae: 269.7234 - val_mse: 149946.3750\n",
            "Epoch 723/1000\n",
            "76511/76511 - 6s - loss: 0.1050 - mae: 270.1686 - mse: 144711.0781 - val_loss: 0.1023 - val_mae: 265.0295 - val_mse: 140812.2656\n",
            "Epoch 724/1000\n",
            "76511/76511 - 6s - loss: 0.1051 - mae: 270.1755 - mse: 144887.7031 - val_loss: 0.1027 - val_mae: 266.5164 - val_mse: 143533.2656\n",
            "Epoch 725/1000\n",
            "76511/76511 - 6s - loss: 0.1048 - mae: 269.9307 - mse: 144863.3750 - val_loss: 0.1027 - val_mae: 267.1067 - val_mse: 145784.1406\n",
            "Epoch 726/1000\n",
            "76511/76511 - 6s - loss: 0.1048 - mae: 270.1656 - mse: 145132.4531 - val_loss: 0.1034 - val_mae: 268.6654 - val_mse: 148579.9688\n",
            "Epoch 727/1000\n",
            "76511/76511 - 6s - loss: 0.1048 - mae: 269.9702 - mse: 144143.2812 - val_loss: 0.1027 - val_mae: 265.0384 - val_mse: 140356.5312\n",
            "Epoch 728/1000\n",
            "76511/76511 - 6s - loss: 0.1050 - mae: 270.3469 - mse: 145170.0156 - val_loss: 0.1033 - val_mae: 268.0422 - val_mse: 147388.2344\n",
            "Epoch 729/1000\n",
            "76511/76511 - 6s - loss: 0.1051 - mae: 270.3206 - mse: 145566.9531 - val_loss: 0.1036 - val_mae: 266.5603 - val_mse: 141156.2344\n",
            "Epoch 730/1000\n",
            "76511/76511 - 6s - loss: 0.1049 - mae: 269.8662 - mse: 144384.0469 - val_loss: 0.1026 - val_mae: 265.3403 - val_mse: 140573.2812\n",
            "Epoch 731/1000\n",
            "76511/76511 - 6s - loss: 0.1055 - mae: 270.0030 - mse: 144480.1094 - val_loss: 0.1051 - val_mae: 271.9884 - val_mse: 154566.9531\n",
            "Epoch 732/1000\n",
            "76511/76511 - 6s - loss: 0.1043 - mae: 269.1150 - mse: 144116.4531 - val_loss: 0.1025 - val_mae: 265.6263 - val_mse: 142702.8906\n",
            "Epoch 733/1000\n",
            "76511/76511 - 6s - loss: 0.1050 - mae: 269.9453 - mse: 145103.2500 - val_loss: 0.1031 - val_mae: 267.2439 - val_mse: 145554.7500\n",
            "Epoch 734/1000\n",
            "76511/76511 - 6s - loss: 0.1045 - mae: 269.7157 - mse: 144787.4844 - val_loss: 0.1028 - val_mae: 265.9235 - val_mse: 141388.5938\n",
            "Epoch 735/1000\n",
            "76511/76511 - 6s - loss: 0.1049 - mae: 269.9609 - mse: 145529.5000 - val_loss: 0.1036 - val_mae: 269.6925 - val_mse: 150223.0312\n",
            "Epoch 736/1000\n",
            "76511/76511 - 6s - loss: 0.1052 - mae: 270.2487 - mse: 145541.7500 - val_loss: 0.1027 - val_mae: 265.5797 - val_mse: 141219.5156\n",
            "Epoch 737/1000\n",
            "76511/76511 - 6s - loss: 0.1047 - mae: 269.7145 - mse: 144393.2344 - val_loss: 0.1031 - val_mae: 266.9358 - val_mse: 144847.9688\n",
            "Epoch 738/1000\n",
            "76511/76511 - 6s - loss: 0.1043 - mae: 269.4153 - mse: 143867.2656 - val_loss: 0.1026 - val_mae: 265.9912 - val_mse: 141958.4688\n",
            "Epoch 739/1000\n",
            "76511/76511 - 6s - loss: 0.1045 - mae: 269.3758 - mse: 144605.7812 - val_loss: 0.1028 - val_mae: 266.9743 - val_mse: 145386.0000\n",
            "Epoch 740/1000\n",
            "76511/76511 - 6s - loss: 0.1044 - mae: 269.2232 - mse: 144205.2188 - val_loss: 0.1032 - val_mae: 267.3611 - val_mse: 146080.6406\n",
            "Epoch 741/1000\n",
            "76511/76511 - 6s - loss: 0.1052 - mae: 270.0613 - mse: 144673.9531 - val_loss: 0.1025 - val_mae: 264.9074 - val_mse: 140820.2969\n",
            "Epoch 742/1000\n",
            "76511/76511 - 6s - loss: 0.1051 - mae: 270.2003 - mse: 144780.6406 - val_loss: 0.1026 - val_mae: 266.0532 - val_mse: 144203.6250\n",
            "Epoch 743/1000\n",
            "76511/76511 - 6s - loss: 0.1045 - mae: 269.4421 - mse: 144272.1875 - val_loss: 0.1050 - val_mae: 272.7010 - val_mse: 155970.8594\n",
            "Epoch 744/1000\n",
            "76511/76511 - 6s - loss: 0.1044 - mae: 269.7716 - mse: 144973.4844 - val_loss: 0.1032 - val_mae: 267.0880 - val_mse: 145417.2812\n",
            "Epoch 745/1000\n",
            "76511/76511 - 6s - loss: 0.1047 - mae: 269.9934 - mse: 144748.0781 - val_loss: 0.1036 - val_mae: 268.4685 - val_mse: 148153.8906\n",
            "Epoch 746/1000\n",
            "76511/76511 - 6s - loss: 0.1048 - mae: 269.8624 - mse: 144862.5000 - val_loss: 0.1036 - val_mae: 268.3613 - val_mse: 147259.5781\n",
            "Epoch 747/1000\n",
            "76511/76511 - 6s - loss: 0.1042 - mae: 269.2794 - mse: 143980.0938 - val_loss: 0.1027 - val_mae: 265.5875 - val_mse: 141019.0156\n",
            "Epoch 748/1000\n",
            "76511/76511 - 6s - loss: 0.1051 - mae: 269.8147 - mse: 144150.0625 - val_loss: 0.1030 - val_mae: 267.3680 - val_mse: 146242.1562\n",
            "Epoch 749/1000\n",
            "76511/76511 - 6s - loss: 0.1046 - mae: 269.7937 - mse: 145049.5938 - val_loss: 0.1030 - val_mae: 266.9078 - val_mse: 144717.4844\n",
            "Epoch 750/1000\n",
            "76511/76511 - 6s - loss: 0.1042 - mae: 268.6352 - mse: 143990.3594 - val_loss: 0.1028 - val_mae: 265.8994 - val_mse: 141945.3750\n",
            "Epoch 751/1000\n",
            "76511/76511 - 6s - loss: 0.1045 - mae: 269.1593 - mse: 144295.3906 - val_loss: 0.1034 - val_mae: 268.3104 - val_mse: 146793.5938\n",
            "Epoch 752/1000\n",
            "76511/76511 - 6s - loss: 0.1048 - mae: 269.9100 - mse: 144125.4062 - val_loss: 0.1024 - val_mae: 266.0733 - val_mse: 143524.5938\n",
            "Epoch 753/1000\n",
            "76511/76511 - 6s - loss: 0.1041 - mae: 269.0629 - mse: 144077.1406 - val_loss: 0.1047 - val_mae: 271.2077 - val_mse: 153162.2344\n",
            "Epoch 754/1000\n",
            "76511/76511 - 6s - loss: 0.1042 - mae: 269.0162 - mse: 143731.7344 - val_loss: 0.1036 - val_mae: 269.2596 - val_mse: 149804.7500\n",
            "Epoch 755/1000\n",
            "76511/76511 - 6s - loss: 0.1041 - mae: 268.8513 - mse: 143428.9375 - val_loss: 0.1055 - val_mae: 273.5074 - val_mse: 156364.2188\n",
            "Epoch 756/1000\n",
            "76511/76511 - 6s - loss: 0.1044 - mae: 269.9280 - mse: 144746.8125 - val_loss: 0.1027 - val_mae: 266.4962 - val_mse: 144546.0469\n",
            "Epoch 757/1000\n",
            "76511/76511 - 6s - loss: 0.1041 - mae: 269.3751 - mse: 144137.1250 - val_loss: 0.1034 - val_mae: 269.0076 - val_mse: 149861.3750\n",
            "Epoch 758/1000\n",
            "76511/76511 - 6s - loss: 0.1046 - mae: 269.5729 - mse: 144287.3906 - val_loss: 0.1025 - val_mae: 266.5188 - val_mse: 144074.8906\n",
            "Epoch 759/1000\n",
            "76511/76511 - 6s - loss: 0.1046 - mae: 269.7757 - mse: 144820.7188 - val_loss: 0.1028 - val_mae: 266.6847 - val_mse: 144490.8438\n",
            "Epoch 760/1000\n",
            "76511/76511 - 6s - loss: 0.1049 - mae: 270.2718 - mse: 145811.9219 - val_loss: 0.1026 - val_mae: 266.3312 - val_mse: 144053.1406\n",
            "Epoch 761/1000\n",
            "76511/76511 - 6s - loss: 0.1043 - mae: 269.3388 - mse: 143927.4219 - val_loss: 0.1035 - val_mae: 269.2367 - val_mse: 149910.0312\n",
            "Epoch 762/1000\n",
            "76511/76511 - 6s - loss: 0.1042 - mae: 268.8427 - mse: 144133.9375 - val_loss: 0.1023 - val_mae: 265.0059 - val_mse: 141005.1562\n",
            "Epoch 763/1000\n",
            "76511/76511 - 6s - loss: 0.1045 - mae: 269.4217 - mse: 144565.7188 - val_loss: 0.1026 - val_mae: 265.3967 - val_mse: 140761.4219\n",
            "Epoch 764/1000\n",
            "76511/76511 - 6s - loss: 0.1048 - mae: 269.5631 - mse: 143826.2812 - val_loss: 0.1029 - val_mae: 267.5731 - val_mse: 145991.1094\n",
            "Epoch 765/1000\n",
            "76511/76511 - 6s - loss: 0.1043 - mae: 268.9659 - mse: 144578.4531 - val_loss: 0.1037 - val_mae: 268.7751 - val_mse: 148775.1406\n",
            "Epoch 766/1000\n",
            "76511/76511 - 6s - loss: 0.1047 - mae: 269.6248 - mse: 145450.0781 - val_loss: 0.1062 - val_mae: 275.2308 - val_mse: 159379.4219\n",
            "Epoch 767/1000\n",
            "76511/76511 - 6s - loss: 0.1044 - mae: 269.6138 - mse: 143831.4062 - val_loss: 0.1028 - val_mae: 265.8797 - val_mse: 141899.7031\n",
            "Epoch 768/1000\n",
            "76511/76511 - 6s - loss: 0.1043 - mae: 269.3142 - mse: 144391.1406 - val_loss: 0.1060 - val_mae: 275.1839 - val_mse: 159477.7812\n",
            "Epoch 769/1000\n",
            "76511/76511 - 6s - loss: 0.1048 - mae: 270.1690 - mse: 145039.3125 - val_loss: 0.1048 - val_mae: 271.7941 - val_mse: 154458.7656\n",
            "Epoch 770/1000\n",
            "76511/76511 - 6s - loss: 0.1045 - mae: 269.5244 - mse: 144298.7188 - val_loss: 0.1027 - val_mae: 266.6204 - val_mse: 144409.7344\n",
            "Epoch 771/1000\n",
            "76511/76511 - 6s - loss: 0.1040 - mae: 268.8004 - mse: 143341.2031 - val_loss: 0.1037 - val_mae: 268.6617 - val_mse: 147766.6406\n",
            "Epoch 772/1000\n",
            "76511/76511 - 6s - loss: 0.1041 - mae: 268.8784 - mse: 143757.7969 - val_loss: 0.1024 - val_mae: 266.2039 - val_mse: 144003.5938\n",
            "Epoch 773/1000\n",
            "76511/76511 - 6s - loss: 0.1046 - mae: 269.0937 - mse: 144161.2344 - val_loss: 0.1026 - val_mae: 266.3869 - val_mse: 144026.7344\n",
            "Epoch 774/1000\n",
            "76511/76511 - 6s - loss: 0.1049 - mae: 270.2539 - mse: 145391.5312 - val_loss: 0.1031 - val_mae: 268.0853 - val_mse: 147900.2188\n",
            "Epoch 775/1000\n",
            "76511/76511 - 6s - loss: 0.1046 - mae: 269.8445 - mse: 144666.3750 - val_loss: 0.1026 - val_mae: 266.8450 - val_mse: 146074.0000\n",
            "Epoch 776/1000\n",
            "76511/76511 - 6s - loss: 0.1048 - mae: 270.0776 - mse: 144163.0938 - val_loss: 0.1034 - val_mae: 268.1813 - val_mse: 148011.6406\n",
            "Epoch 777/1000\n",
            "76511/76511 - 6s - loss: 0.1046 - mae: 270.0282 - mse: 144698.0000 - val_loss: 0.1022 - val_mae: 265.4754 - val_mse: 143130.1250\n",
            "Epoch 778/1000\n",
            "76511/76511 - 6s - loss: 0.1043 - mae: 269.7858 - mse: 144791.6719 - val_loss: 0.1041 - val_mae: 267.8810 - val_mse: 143732.4844\n",
            "Epoch 779/1000\n",
            "76511/76511 - 6s - loss: 0.1044 - mae: 269.5912 - mse: 144740.4219 - val_loss: 0.1030 - val_mae: 267.9733 - val_mse: 147614.2969\n",
            "Epoch 780/1000\n",
            "76511/76511 - 6s - loss: 0.1047 - mae: 268.9037 - mse: 144097.6094 - val_loss: 0.1045 - val_mae: 270.6891 - val_mse: 152525.6719\n",
            "Epoch 781/1000\n",
            "76511/76511 - 6s - loss: 0.1047 - mae: 268.9311 - mse: 143741.5469 - val_loss: 0.1035 - val_mae: 268.1873 - val_mse: 147389.8438\n",
            "Epoch 782/1000\n",
            "76511/76511 - 6s - loss: 0.1038 - mae: 268.4937 - mse: 143826.5156 - val_loss: 0.1029 - val_mae: 267.4207 - val_mse: 146339.2188\n",
            "Epoch 783/1000\n",
            "76511/76511 - 6s - loss: 0.1040 - mae: 269.5187 - mse: 143845.6406 - val_loss: 0.1026 - val_mae: 265.3920 - val_mse: 140795.7656\n",
            "Epoch 784/1000\n",
            "76511/76511 - 6s - loss: 0.1047 - mae: 269.5017 - mse: 144612.0938 - val_loss: 0.1042 - val_mae: 270.0181 - val_mse: 151345.0312\n",
            "Epoch 785/1000\n",
            "76511/76511 - 6s - loss: 0.1042 - mae: 269.2838 - mse: 144037.1406 - val_loss: 0.1034 - val_mae: 268.0625 - val_mse: 146820.8438\n",
            "Epoch 786/1000\n",
            "76511/76511 - 6s - loss: 0.1046 - mae: 269.5154 - mse: 144492.7500 - val_loss: 0.1025 - val_mae: 266.3410 - val_mse: 143564.4531\n",
            "Epoch 787/1000\n",
            "76511/76511 - 6s - loss: 0.1043 - mae: 268.8978 - mse: 143929.4219 - val_loss: 0.1032 - val_mae: 267.2274 - val_mse: 145573.8594\n",
            "Epoch 788/1000\n",
            "76511/76511 - 6s - loss: 0.1049 - mae: 269.8086 - mse: 145300.3750 - val_loss: 0.1027 - val_mae: 265.9401 - val_mse: 143274.1875\n",
            "Epoch 789/1000\n",
            "76511/76511 - 7s - loss: 0.1042 - mae: 269.3399 - mse: 144325.5938 - val_loss: 0.1029 - val_mae: 265.8336 - val_mse: 142059.0312\n",
            "Epoch 790/1000\n",
            "76511/76511 - 7s - loss: 0.1040 - mae: 269.3397 - mse: 144542.7500 - val_loss: 0.1038 - val_mae: 269.6837 - val_mse: 150346.1562\n",
            "Epoch 791/1000\n",
            "76511/76511 - 6s - loss: 0.1046 - mae: 269.3865 - mse: 143987.7656 - val_loss: 0.1029 - val_mae: 267.1068 - val_mse: 145495.6094\n",
            "Epoch 792/1000\n",
            "76511/76511 - 6s - loss: 0.1042 - mae: 269.2231 - mse: 143711.8906 - val_loss: 0.1028 - val_mae: 266.5895 - val_mse: 144740.8125\n",
            "Epoch 793/1000\n",
            "76511/76511 - 6s - loss: 0.1049 - mae: 269.9060 - mse: 145086.8125 - val_loss: 0.1026 - val_mae: 266.5365 - val_mse: 143917.7656\n",
            "Epoch 794/1000\n",
            "76511/76511 - 6s - loss: 0.1046 - mae: 269.5162 - mse: 144756.5156 - val_loss: 0.1037 - val_mae: 268.5302 - val_mse: 146985.2344\n",
            "Epoch 795/1000\n",
            "76511/76511 - 6s - loss: 0.1041 - mae: 268.9377 - mse: 143594.7969 - val_loss: 0.1026 - val_mae: 265.8320 - val_mse: 142916.8438\n",
            "Epoch 796/1000\n",
            "76511/76511 - 6s - loss: 0.1047 - mae: 269.0370 - mse: 144185.9844 - val_loss: 0.1028 - val_mae: 267.6225 - val_mse: 147113.5469\n",
            "Epoch 797/1000\n",
            "76511/76511 - 6s - loss: 0.1038 - mae: 268.5297 - mse: 143536.3906 - val_loss: 0.1066 - val_mae: 275.9039 - val_mse: 160701.3125\n",
            "Epoch 798/1000\n",
            "76511/76511 - 6s - loss: 0.1043 - mae: 269.4120 - mse: 144453.5625 - val_loss: 0.1028 - val_mae: 265.6675 - val_mse: 141919.6719\n",
            "Epoch 799/1000\n",
            "76511/76511 - 6s - loss: 0.1051 - mae: 269.2415 - mse: 144229.1562 - val_loss: 0.1025 - val_mae: 266.7065 - val_mse: 144146.4375\n",
            "Epoch 800/1000\n",
            "76511/76511 - 6s - loss: 0.1041 - mae: 269.1143 - mse: 144284.9375 - val_loss: 0.1027 - val_mae: 266.3885 - val_mse: 143889.7969\n",
            "Epoch 801/1000\n",
            "76511/76511 - 6s - loss: 0.1048 - mae: 269.0913 - mse: 144103.9062 - val_loss: 0.1023 - val_mae: 264.8755 - val_mse: 140544.8594\n",
            "Epoch 802/1000\n",
            "76511/76511 - 6s - loss: 0.1043 - mae: 268.6904 - mse: 144109.3594 - val_loss: 0.1034 - val_mae: 268.3981 - val_mse: 147827.5781\n",
            "Epoch 803/1000\n",
            "76511/76511 - 6s - loss: 0.1039 - mae: 268.8242 - mse: 143594.2500 - val_loss: 0.1023 - val_mae: 265.3672 - val_mse: 141508.4688\n",
            "Epoch 804/1000\n",
            "76511/76511 - 6s - loss: 0.1039 - mae: 269.0247 - mse: 143839.5312 - val_loss: 0.1039 - val_mae: 270.1695 - val_mse: 151235.4062\n",
            "Epoch 805/1000\n",
            "76511/76511 - 6s - loss: 0.1043 - mae: 269.0760 - mse: 143836.3594 - val_loss: 0.1025 - val_mae: 265.6545 - val_mse: 142789.4688\n",
            "Epoch 806/1000\n",
            "76511/76511 - 6s - loss: 0.1038 - mae: 268.5887 - mse: 143388.7344 - val_loss: 0.1028 - val_mae: 265.8192 - val_mse: 141546.3125\n",
            "Epoch 807/1000\n",
            "76511/76511 - 6s - loss: 0.1045 - mae: 268.6436 - mse: 143319.3438 - val_loss: 0.1027 - val_mae: 266.1089 - val_mse: 142967.4531\n",
            "Epoch 808/1000\n",
            "76511/76511 - 6s - loss: 0.1037 - mae: 268.1444 - mse: 143317.4844 - val_loss: 0.1030 - val_mae: 266.9835 - val_mse: 144558.2188\n",
            "Epoch 809/1000\n",
            "76511/76511 - 6s - loss: 0.1038 - mae: 268.9556 - mse: 143570.2188 - val_loss: 0.1028 - val_mae: 265.9799 - val_mse: 142937.7188\n",
            "Epoch 810/1000\n",
            "76511/76511 - 6s - loss: 0.1052 - mae: 269.7926 - mse: 144807.7344 - val_loss: 0.1029 - val_mae: 266.7911 - val_mse: 143945.5469\n",
            "Epoch 811/1000\n",
            "76511/76511 - 6s - loss: 0.1040 - mae: 268.5910 - mse: 144046.2031 - val_loss: 0.1031 - val_mae: 267.4371 - val_mse: 146027.6094\n",
            "Epoch 812/1000\n",
            "76511/76511 - 6s - loss: 0.1041 - mae: 269.2766 - mse: 144542.8125 - val_loss: 0.1028 - val_mae: 265.7819 - val_mse: 142636.0625\n",
            "Epoch 813/1000\n",
            "76511/76511 - 6s - loss: 0.1044 - mae: 269.5614 - mse: 144941.3906 - val_loss: 0.1051 - val_mae: 272.5323 - val_mse: 154846.6094\n",
            "Epoch 814/1000\n",
            "76511/76511 - 6s - loss: 0.1042 - mae: 269.3427 - mse: 144289.2188 - val_loss: 0.1032 - val_mae: 267.5538 - val_mse: 147071.0000\n",
            "Epoch 815/1000\n",
            "76511/76511 - 6s - loss: 0.1046 - mae: 268.5279 - mse: 142918.7656 - val_loss: 0.1028 - val_mae: 266.7765 - val_mse: 144595.4688\n",
            "Epoch 816/1000\n",
            "76511/76511 - 6s - loss: 0.1039 - mae: 268.9220 - mse: 143742.4375 - val_loss: 0.1025 - val_mae: 266.0715 - val_mse: 142886.7656\n",
            "Epoch 817/1000\n",
            "76511/76511 - 5s - loss: 0.1037 - mae: 268.8727 - mse: 143698.0469 - val_loss: 0.1028 - val_mae: 267.6306 - val_mse: 146626.4375\n",
            "Epoch 818/1000\n",
            "76511/76511 - 6s - loss: 0.1043 - mae: 268.9569 - mse: 144376.8906 - val_loss: 0.1038 - val_mae: 268.9977 - val_mse: 148936.7500\n",
            "Epoch 819/1000\n",
            "76511/76511 - 6s - loss: 0.1040 - mae: 269.0213 - mse: 144141.8281 - val_loss: 0.1026 - val_mae: 266.1783 - val_mse: 143331.4219\n",
            "Epoch 820/1000\n",
            "76511/76511 - 6s - loss: 0.1045 - mae: 269.4662 - mse: 144313.8906 - val_loss: 0.1024 - val_mae: 265.0194 - val_mse: 139931.6094\n",
            "Epoch 821/1000\n",
            "76511/76511 - 6s - loss: 0.1043 - mae: 269.2339 - mse: 144329.7500 - val_loss: 0.1027 - val_mae: 266.0189 - val_mse: 142968.7656\n",
            "Epoch 822/1000\n",
            "76511/76511 - 6s - loss: 0.1043 - mae: 269.1213 - mse: 144299.7500 - val_loss: 0.1021 - val_mae: 265.4862 - val_mse: 143081.5312\n",
            "Epoch 823/1000\n",
            "76511/76511 - 6s - loss: 0.1040 - mae: 268.9020 - mse: 144189.3594 - val_loss: 0.1026 - val_mae: 264.9771 - val_mse: 140291.9062\n",
            "Epoch 824/1000\n",
            "76511/76511 - 6s - loss: 0.1041 - mae: 268.0636 - mse: 143222.0625 - val_loss: 0.1024 - val_mae: 265.5821 - val_mse: 141919.1406\n",
            "Epoch 825/1000\n",
            "76511/76511 - 6s - loss: 0.1044 - mae: 268.6603 - mse: 143629.7812 - val_loss: 0.1030 - val_mae: 265.6971 - val_mse: 141230.1562\n",
            "Epoch 826/1000\n",
            "76511/76511 - 6s - loss: 0.1041 - mae: 269.1487 - mse: 144865.2969 - val_loss: 0.1035 - val_mae: 267.1556 - val_mse: 143555.5312\n",
            "Epoch 827/1000\n",
            "76511/76511 - 6s - loss: 0.1042 - mae: 269.5734 - mse: 144432.5781 - val_loss: 0.1032 - val_mae: 265.9915 - val_mse: 142467.9844\n",
            "Epoch 828/1000\n",
            "76511/76511 - 6s - loss: 0.1040 - mae: 268.9220 - mse: 144091.5469 - val_loss: 0.1033 - val_mae: 267.3275 - val_mse: 145402.7344\n",
            "Epoch 829/1000\n",
            "76511/76511 - 6s - loss: 0.1041 - mae: 268.6617 - mse: 143220.1562 - val_loss: 0.1032 - val_mae: 266.3531 - val_mse: 142390.9062\n",
            "Epoch 830/1000\n",
            "76511/76511 - 6s - loss: 0.1041 - mae: 269.1547 - mse: 144130.4688 - val_loss: 0.1029 - val_mae: 267.4832 - val_mse: 145842.7656\n",
            "Epoch 831/1000\n",
            "76511/76511 - 6s - loss: 0.1039 - mae: 268.9608 - mse: 143471.3438 - val_loss: 0.1032 - val_mae: 267.1023 - val_mse: 144943.4531\n",
            "Epoch 832/1000\n",
            "76511/76511 - 6s - loss: 0.1039 - mae: 268.7572 - mse: 144184.1875 - val_loss: 0.1025 - val_mae: 264.7594 - val_mse: 140180.4844\n",
            "Epoch 833/1000\n",
            "76511/76511 - 6s - loss: 0.1038 - mae: 268.7985 - mse: 143851.1875 - val_loss: 0.1036 - val_mae: 269.6081 - val_mse: 150618.2812\n",
            "Epoch 834/1000\n",
            "76511/76511 - 6s - loss: 0.1045 - mae: 269.0956 - mse: 144721.3750 - val_loss: 0.1023 - val_mae: 265.8285 - val_mse: 142968.1562\n",
            "Epoch 835/1000\n",
            "76511/76511 - 6s - loss: 0.1036 - mae: 268.6445 - mse: 143544.5781 - val_loss: 0.1055 - val_mae: 272.9938 - val_mse: 156441.0000\n",
            "Epoch 836/1000\n",
            "76511/76511 - 6s - loss: 0.1040 - mae: 268.7560 - mse: 143449.1406 - val_loss: 0.1031 - val_mae: 266.8651 - val_mse: 144786.4375\n",
            "Epoch 837/1000\n",
            "76511/76511 - 6s - loss: 0.1036 - mae: 268.2822 - mse: 143307.0469 - val_loss: 0.1033 - val_mae: 265.7626 - val_mse: 140574.0781\n",
            "Epoch 838/1000\n",
            "76511/76511 - 6s - loss: 0.1039 - mae: 268.8497 - mse: 143954.0625 - val_loss: 0.1025 - val_mae: 265.1834 - val_mse: 140874.1406\n",
            "Epoch 839/1000\n",
            "76511/76511 - 6s - loss: 0.1040 - mae: 268.7802 - mse: 144256.0312 - val_loss: 0.1031 - val_mae: 266.0262 - val_mse: 141895.4219\n",
            "Epoch 840/1000\n",
            "76511/76511 - 6s - loss: 0.1040 - mae: 268.7885 - mse: 143705.9688 - val_loss: 0.1036 - val_mae: 266.4315 - val_mse: 142383.3594\n",
            "Epoch 841/1000\n",
            "76511/76511 - 6s - loss: 0.1040 - mae: 269.2407 - mse: 144340.8438 - val_loss: 0.1028 - val_mae: 265.8512 - val_mse: 142504.8438\n",
            "Epoch 842/1000\n",
            "76511/76511 - 6s - loss: 0.1038 - mae: 268.9140 - mse: 143716.4688 - val_loss: 0.1032 - val_mae: 267.4977 - val_mse: 145532.5000\n",
            "Epoch 843/1000\n",
            "76511/76511 - 6s - loss: 0.1040 - mae: 268.9086 - mse: 144036.1250 - val_loss: 0.1029 - val_mae: 265.7851 - val_mse: 140678.0625\n",
            "Epoch 844/1000\n",
            "76511/76511 - 6s - loss: 0.1040 - mae: 268.5689 - mse: 143874.0625 - val_loss: 0.1031 - val_mae: 267.1103 - val_mse: 145505.0000\n",
            "Epoch 845/1000\n",
            "76511/76511 - 6s - loss: 0.1042 - mae: 268.7425 - mse: 144192.2656 - val_loss: 0.1023 - val_mae: 265.7666 - val_mse: 142314.9688\n",
            "Epoch 846/1000\n",
            "76511/76511 - 6s - loss: 0.1037 - mae: 268.6357 - mse: 143451.6719 - val_loss: 0.1021 - val_mae: 265.5230 - val_mse: 141725.2344\n",
            "Epoch 847/1000\n",
            "76511/76511 - 6s - loss: 0.1039 - mae: 269.3171 - mse: 143802.3438 - val_loss: 0.1031 - val_mae: 268.4361 - val_mse: 147443.6250\n",
            "Epoch 848/1000\n",
            "76511/76511 - 6s - loss: 0.1035 - mae: 268.1166 - mse: 142829.3125 - val_loss: 0.1030 - val_mae: 266.7689 - val_mse: 144654.7188\n",
            "Epoch 849/1000\n",
            "76511/76511 - 6s - loss: 0.1042 - mae: 269.0342 - mse: 144012.9844 - val_loss: 0.1032 - val_mae: 266.6386 - val_mse: 142738.5625\n",
            "Epoch 850/1000\n",
            "76511/76511 - 6s - loss: 0.1042 - mae: 269.2853 - mse: 144066.8125 - val_loss: 0.1026 - val_mae: 265.9871 - val_mse: 142944.3594\n",
            "Epoch 851/1000\n",
            "76511/76511 - 6s - loss: 0.1040 - mae: 268.5794 - mse: 143071.3906 - val_loss: 0.1031 - val_mae: 267.3010 - val_mse: 146160.9688\n",
            "Epoch 852/1000\n",
            "76511/76511 - 6s - loss: 0.1041 - mae: 268.4293 - mse: 143355.2812 - val_loss: 0.1042 - val_mae: 269.2260 - val_mse: 148531.5000\n",
            "Epoch 853/1000\n",
            "76511/76511 - 6s - loss: 0.1039 - mae: 268.3493 - mse: 143512.6875 - val_loss: 0.1052 - val_mae: 272.8971 - val_mse: 155954.1719\n",
            "Epoch 854/1000\n",
            "76511/76511 - 6s - loss: 0.1047 - mae: 269.3812 - mse: 144754.5938 - val_loss: 0.1061 - val_mae: 274.6907 - val_mse: 158327.6250\n",
            "Epoch 855/1000\n",
            "76511/76511 - 6s - loss: 0.1038 - mae: 268.7481 - mse: 143337.0781 - val_loss: 0.1022 - val_mae: 265.0927 - val_mse: 140624.6406\n",
            "Epoch 856/1000\n",
            "76511/76511 - 6s - loss: 0.1036 - mae: 268.4846 - mse: 143078.4688 - val_loss: 0.1032 - val_mae: 268.0920 - val_mse: 147459.7812\n",
            "Epoch 857/1000\n",
            "76511/76511 - 5s - loss: 0.1035 - mae: 268.4503 - mse: 143730.0000 - val_loss: 0.1021 - val_mae: 265.5396 - val_mse: 142047.0469\n",
            "Epoch 858/1000\n",
            "76511/76511 - 6s - loss: 0.1034 - mae: 268.3670 - mse: 143030.8438 - val_loss: 0.1043 - val_mae: 270.7038 - val_mse: 151720.3594\n",
            "Epoch 859/1000\n",
            "76511/76511 - 6s - loss: 0.1036 - mae: 268.6235 - mse: 143598.6094 - val_loss: 0.1039 - val_mae: 269.3496 - val_mse: 148372.9688\n",
            "Epoch 860/1000\n",
            "76511/76511 - 6s - loss: 0.1037 - mae: 268.7948 - mse: 143662.5156 - val_loss: 0.1031 - val_mae: 266.9634 - val_mse: 144814.4844\n",
            "Epoch 861/1000\n",
            "76511/76511 - 6s - loss: 0.1038 - mae: 268.6624 - mse: 143688.6406 - val_loss: 0.1030 - val_mae: 266.8111 - val_mse: 144224.7344\n",
            "Epoch 862/1000\n",
            "76511/76511 - 6s - loss: 0.1034 - mae: 268.3310 - mse: 143002.9844 - val_loss: 0.1033 - val_mae: 268.1007 - val_mse: 146726.8594\n",
            "Epoch 863/1000\n",
            "76511/76511 - 6s - loss: 0.1036 - mae: 268.4835 - mse: 143644.6875 - val_loss: 0.1033 - val_mae: 267.4447 - val_mse: 146012.8594\n",
            "Epoch 864/1000\n",
            "76511/76511 - 6s - loss: 0.1034 - mae: 268.4240 - mse: 143498.6094 - val_loss: 0.1065 - val_mae: 275.9568 - val_mse: 160917.4844\n",
            "Epoch 865/1000\n",
            "76511/76511 - 6s - loss: 0.1037 - mae: 268.7119 - mse: 144029.1250 - val_loss: 0.1051 - val_mae: 272.2645 - val_mse: 154551.1406\n",
            "Epoch 866/1000\n",
            "76511/76511 - 6s - loss: 0.1036 - mae: 268.1457 - mse: 143440.0000 - val_loss: 0.1027 - val_mae: 266.0604 - val_mse: 142620.0938\n",
            "Epoch 867/1000\n",
            "76511/76511 - 6s - loss: 0.1036 - mae: 268.3074 - mse: 143560.3750 - val_loss: 0.1025 - val_mae: 265.9691 - val_mse: 142377.8594\n",
            "Epoch 868/1000\n",
            "76511/76511 - 6s - loss: 0.1039 - mae: 268.7010 - mse: 143557.7969 - val_loss: 0.1036 - val_mae: 268.2920 - val_mse: 147450.0000\n",
            "Epoch 869/1000\n",
            "76511/76511 - 6s - loss: 0.1034 - mae: 268.1719 - mse: 143036.9688 - val_loss: 0.1037 - val_mae: 268.2790 - val_mse: 147464.5312\n",
            "Epoch 870/1000\n",
            "76511/76511 - 6s - loss: 0.1038 - mae: 268.4022 - mse: 143299.7812 - val_loss: 0.1027 - val_mae: 265.8760 - val_mse: 142810.7344\n",
            "Epoch 871/1000\n",
            "76511/76511 - 6s - loss: 0.1039 - mae: 268.7807 - mse: 144350.2500 - val_loss: 0.1028 - val_mae: 266.6535 - val_mse: 144140.9219\n",
            "Epoch 872/1000\n",
            "76511/76511 - 6s - loss: 0.1036 - mae: 268.1764 - mse: 143153.3281 - val_loss: 0.1037 - val_mae: 269.9425 - val_mse: 151230.5938\n",
            "Epoch 873/1000\n",
            "76511/76511 - 6s - loss: 0.1040 - mae: 268.8409 - mse: 143849.2344 - val_loss: 0.1029 - val_mae: 266.1438 - val_mse: 143258.6875\n",
            "Epoch 874/1000\n",
            "76511/76511 - 6s - loss: 0.1040 - mae: 268.1843 - mse: 143109.8125 - val_loss: 0.1038 - val_mae: 268.9207 - val_mse: 148815.0000\n",
            "Epoch 875/1000\n",
            "76511/76511 - 6s - loss: 0.1037 - mae: 268.6183 - mse: 143104.8594 - val_loss: 0.1041 - val_mae: 269.5731 - val_mse: 148968.8750\n",
            "Epoch 876/1000\n",
            "76511/76511 - 6s - loss: 0.1045 - mae: 269.4622 - mse: 144729.2969 - val_loss: 0.1028 - val_mae: 266.8806 - val_mse: 144486.5781\n",
            "Epoch 877/1000\n",
            "76511/76511 - 6s - loss: 0.1038 - mae: 268.8365 - mse: 144179.9375 - val_loss: 0.1030 - val_mae: 268.3244 - val_mse: 148197.3594\n",
            "Epoch 878/1000\n",
            "76511/76511 - 6s - loss: 0.1038 - mae: 268.9947 - mse: 144359.5938 - val_loss: 0.1031 - val_mae: 266.5929 - val_mse: 142872.3281\n",
            "Epoch 879/1000\n",
            "76511/76511 - 6s - loss: 0.1036 - mae: 268.1654 - mse: 143259.1250 - val_loss: 0.1031 - val_mae: 267.4267 - val_mse: 146813.5938\n",
            "Epoch 880/1000\n",
            "76511/76511 - 6s - loss: 0.1040 - mae: 268.1698 - mse: 143363.7031 - val_loss: 0.1031 - val_mae: 266.7195 - val_mse: 143776.5625\n",
            "Epoch 881/1000\n",
            "76511/76511 - 6s - loss: 0.1041 - mae: 268.4729 - mse: 143275.7656 - val_loss: 0.1030 - val_mae: 266.0022 - val_mse: 141337.2344\n",
            "Epoch 882/1000\n",
            "76511/76511 - 6s - loss: 0.1038 - mae: 269.1709 - mse: 144324.4375 - val_loss: 0.1042 - val_mae: 270.4408 - val_mse: 150914.8125\n",
            "Epoch 883/1000\n",
            "76511/76511 - 6s - loss: 0.1036 - mae: 268.6107 - mse: 143816.1250 - val_loss: 0.1054 - val_mae: 272.4972 - val_mse: 154544.1250\n",
            "Epoch 884/1000\n",
            "76511/76511 - 6s - loss: 0.1037 - mae: 268.6700 - mse: 143395.6250 - val_loss: 0.1028 - val_mae: 265.7730 - val_mse: 141035.0938\n",
            "Epoch 885/1000\n",
            "76511/76511 - 6s - loss: 0.1038 - mae: 268.5102 - mse: 143839.3438 - val_loss: 0.1030 - val_mae: 267.1243 - val_mse: 145504.8594\n",
            "Epoch 886/1000\n",
            "76511/76511 - 6s - loss: 0.1033 - mae: 268.5195 - mse: 143417.6406 - val_loss: 0.1038 - val_mae: 269.6650 - val_mse: 150180.9844\n",
            "Epoch 887/1000\n",
            "76511/76511 - 6s - loss: 0.1033 - mae: 268.4199 - mse: 143501.2188 - val_loss: 0.1061 - val_mae: 274.1699 - val_mse: 157823.4844\n",
            "Epoch 888/1000\n",
            "76511/76511 - 6s - loss: 0.1034 - mae: 268.1210 - mse: 142572.1250 - val_loss: 0.1027 - val_mae: 266.1765 - val_mse: 143421.5469\n",
            "Epoch 889/1000\n",
            "76511/76511 - 6s - loss: 0.1045 - mae: 268.3525 - mse: 144170.6875 - val_loss: 0.1035 - val_mae: 266.1619 - val_mse: 140831.7031\n",
            "Epoch 890/1000\n",
            "76511/76511 - 6s - loss: 0.1037 - mae: 268.5605 - mse: 143493.9688 - val_loss: 0.1028 - val_mae: 267.3159 - val_mse: 145545.0938\n",
            "Epoch 891/1000\n",
            "76511/76511 - 6s - loss: 0.1033 - mae: 267.8606 - mse: 143123.1250 - val_loss: 0.1026 - val_mae: 265.4456 - val_mse: 141653.0625\n",
            "Epoch 892/1000\n",
            "76511/76511 - 6s - loss: 0.1031 - mae: 267.3904 - mse: 142164.2344 - val_loss: 0.1026 - val_mae: 266.6142 - val_mse: 144120.5938\n",
            "Epoch 893/1000\n",
            "76511/76511 - 6s - loss: 0.1033 - mae: 268.1747 - mse: 143163.1719 - val_loss: 0.1047 - val_mae: 271.5345 - val_mse: 153455.7344\n",
            "Epoch 894/1000\n",
            "76511/76511 - 6s - loss: 0.1038 - mae: 268.3083 - mse: 143498.4688 - val_loss: 0.1037 - val_mae: 269.2073 - val_mse: 149254.9844\n",
            "Epoch 895/1000\n",
            "76511/76511 - 6s - loss: 0.1033 - mae: 267.6158 - mse: 142634.0625 - val_loss: 0.1050 - val_mae: 271.1782 - val_mse: 152272.0938\n",
            "Epoch 896/1000\n",
            "76511/76511 - 6s - loss: 0.1032 - mae: 267.8536 - mse: 143147.1875 - val_loss: 0.1033 - val_mae: 266.0015 - val_mse: 140581.7500\n",
            "Epoch 897/1000\n",
            "76511/76511 - 6s - loss: 0.1032 - mae: 268.3428 - mse: 143426.4062 - val_loss: 0.1031 - val_mae: 267.4594 - val_mse: 145610.7031\n",
            "Epoch 898/1000\n",
            "76511/76511 - 6s - loss: 0.1037 - mae: 268.6621 - mse: 143956.6094 - val_loss: 0.1033 - val_mae: 267.4430 - val_mse: 145212.7656\n",
            "Epoch 899/1000\n",
            "76511/76511 - 6s - loss: 0.1032 - mae: 268.1597 - mse: 142778.1406 - val_loss: 0.1028 - val_mae: 265.2244 - val_mse: 140560.5625\n",
            "Epoch 900/1000\n",
            "76511/76511 - 6s - loss: 0.1038 - mae: 268.4531 - mse: 144054.4062 - val_loss: 0.1033 - val_mae: 266.2279 - val_mse: 141280.4375\n",
            "Epoch 901/1000\n",
            "76511/76511 - 6s - loss: 0.1036 - mae: 267.5394 - mse: 142475.6406 - val_loss: 0.1039 - val_mae: 266.5234 - val_mse: 141201.5156\n",
            "Epoch 902/1000\n",
            "76511/76511 - 6s - loss: 0.1035 - mae: 268.2084 - mse: 143705.3125 - val_loss: 0.1027 - val_mae: 266.8255 - val_mse: 144683.9375\n",
            "Epoch 903/1000\n",
            "76511/76511 - 6s - loss: 0.1037 - mae: 268.9293 - mse: 143130.9375 - val_loss: 0.1033 - val_mae: 268.4799 - val_mse: 147292.3906\n",
            "Epoch 904/1000\n",
            "76511/76511 - 6s - loss: 0.1035 - mae: 268.2346 - mse: 143080.9844 - val_loss: 0.1029 - val_mae: 266.7408 - val_mse: 144705.1406\n",
            "Epoch 905/1000\n",
            "76511/76511 - 6s - loss: 0.1034 - mae: 268.0665 - mse: 143008.0156 - val_loss: 0.1027 - val_mae: 266.3376 - val_mse: 143842.4688\n",
            "Epoch 906/1000\n",
            "76511/76511 - 6s - loss: 0.1034 - mae: 268.4100 - mse: 143047.8750 - val_loss: 0.1042 - val_mae: 269.2083 - val_mse: 148865.9375\n",
            "Epoch 907/1000\n",
            "76511/76511 - 6s - loss: 0.1033 - mae: 268.4344 - mse: 143266.2969 - val_loss: 0.1037 - val_mae: 266.8049 - val_mse: 142595.9375\n",
            "Epoch 908/1000\n",
            "76511/76511 - 6s - loss: 0.1033 - mae: 268.0410 - mse: 143434.0469 - val_loss: 0.1036 - val_mae: 266.7177 - val_mse: 142034.4531\n",
            "Epoch 909/1000\n",
            "76511/76511 - 6s - loss: 0.1037 - mae: 268.4927 - mse: 143802.9219 - val_loss: 0.1037 - val_mae: 266.6964 - val_mse: 140223.1094\n",
            "Epoch 910/1000\n",
            "76511/76511 - 6s - loss: 0.1039 - mae: 268.1078 - mse: 143130.0938 - val_loss: 0.1030 - val_mae: 266.4595 - val_mse: 142394.7500\n",
            "Epoch 911/1000\n",
            "76511/76511 - 6s - loss: 0.1030 - mae: 267.8535 - mse: 143013.5625 - val_loss: 0.1030 - val_mae: 266.6541 - val_mse: 144226.9219\n",
            "Epoch 912/1000\n",
            "76511/76511 - 6s - loss: 0.1035 - mae: 268.4152 - mse: 142944.5781 - val_loss: 0.1042 - val_mae: 268.7841 - val_mse: 147123.7188\n",
            "Epoch 913/1000\n",
            "76511/76511 - 6s - loss: 0.1033 - mae: 267.8555 - mse: 142956.7031 - val_loss: 0.1045 - val_mae: 271.1546 - val_mse: 152537.6250\n",
            "Epoch 914/1000\n",
            "76511/76511 - 6s - loss: 0.1033 - mae: 267.7817 - mse: 142535.5000 - val_loss: 0.1025 - val_mae: 266.2852 - val_mse: 143573.5938\n",
            "Epoch 915/1000\n",
            "76511/76511 - 6s - loss: 0.1039 - mae: 268.5095 - mse: 143627.9688 - val_loss: 0.1025 - val_mae: 265.1687 - val_mse: 140662.6719\n",
            "Epoch 916/1000\n",
            "76511/76511 - 6s - loss: 0.1038 - mae: 269.2081 - mse: 144405.5156 - val_loss: 0.1031 - val_mae: 266.5673 - val_mse: 141987.4844\n",
            "Epoch 917/1000\n",
            "76511/76511 - 6s - loss: 0.1030 - mae: 267.7929 - mse: 143324.7812 - val_loss: 0.1053 - val_mae: 272.7260 - val_mse: 154892.2188\n",
            "Epoch 918/1000\n",
            "76511/76511 - 6s - loss: 0.1034 - mae: 268.3025 - mse: 143603.1250 - val_loss: 0.1037 - val_mae: 268.9088 - val_mse: 148660.5781\n",
            "Epoch 919/1000\n",
            "76511/76511 - 6s - loss: 0.1036 - mae: 267.8896 - mse: 143438.5156 - val_loss: 0.1026 - val_mae: 265.7744 - val_mse: 141994.5781\n",
            "Epoch 920/1000\n",
            "76511/76511 - 6s - loss: 0.1034 - mae: 267.9023 - mse: 143589.0000 - val_loss: 0.1083 - val_mae: 275.5858 - val_mse: 150964.1562\n",
            "Epoch 921/1000\n",
            "76511/76511 - 6s - loss: 0.1032 - mae: 267.8199 - mse: 142915.2188 - val_loss: 0.1029 - val_mae: 266.5246 - val_mse: 143556.5000\n",
            "Epoch 922/1000\n",
            "76511/76511 - 6s - loss: 0.1031 - mae: 268.1008 - mse: 142788.5781 - val_loss: 0.1030 - val_mae: 266.7863 - val_mse: 143693.3438\n",
            "Epoch 923/1000\n",
            "76511/76511 - 6s - loss: 0.1034 - mae: 267.8525 - mse: 143473.9062 - val_loss: 0.1030 - val_mae: 266.1974 - val_mse: 140527.2500\n",
            "Epoch 924/1000\n",
            "76511/76511 - 6s - loss: 0.1033 - mae: 267.7067 - mse: 143099.2656 - val_loss: 0.1027 - val_mae: 265.9937 - val_mse: 142725.5938\n",
            "Epoch 925/1000\n",
            "76511/76511 - 6s - loss: 0.1039 - mae: 268.1025 - mse: 143636.0469 - val_loss: 0.1036 - val_mae: 266.2026 - val_mse: 140754.1406\n",
            "Epoch 926/1000\n",
            "76511/76511 - 6s - loss: 0.1037 - mae: 268.2332 - mse: 143988.9375 - val_loss: 0.1029 - val_mae: 266.4318 - val_mse: 142513.7656\n",
            "Epoch 927/1000\n",
            "76511/76511 - 6s - loss: 0.1035 - mae: 267.3893 - mse: 142929.3281 - val_loss: 0.1047 - val_mae: 268.3072 - val_mse: 142045.6406\n",
            "Epoch 928/1000\n",
            "76511/76511 - 6s - loss: 0.1034 - mae: 268.1550 - mse: 143676.9062 - val_loss: 0.1030 - val_mae: 266.7395 - val_mse: 143512.0781\n",
            "Epoch 929/1000\n",
            "76511/76511 - 6s - loss: 0.1032 - mae: 268.1915 - mse: 143586.5938 - val_loss: 0.1047 - val_mae: 271.6564 - val_mse: 153952.7812\n",
            "Epoch 930/1000\n",
            "76511/76511 - 6s - loss: 0.1032 - mae: 267.7345 - mse: 143130.7344 - val_loss: 0.1041 - val_mae: 269.1274 - val_mse: 148114.5156\n",
            "Epoch 931/1000\n",
            "76511/76511 - 6s - loss: 0.1033 - mae: 267.4685 - mse: 142481.1094 - val_loss: 0.1029 - val_mae: 266.1531 - val_mse: 142572.5938\n",
            "Epoch 932/1000\n",
            "76511/76511 - 6s - loss: 0.1033 - mae: 267.8063 - mse: 142740.7969 - val_loss: 0.1032 - val_mae: 266.9090 - val_mse: 143442.3438\n",
            "Epoch 933/1000\n",
            "76511/76511 - 6s - loss: 0.1038 - mae: 268.0126 - mse: 142548.0000 - val_loss: 0.1032 - val_mae: 267.5099 - val_mse: 145830.6094\n",
            "Epoch 934/1000\n",
            "76511/76511 - 6s - loss: 0.1030 - mae: 267.4718 - mse: 142777.4531 - val_loss: 0.1026 - val_mae: 265.3620 - val_mse: 141114.8281\n",
            "Epoch 935/1000\n",
            "76511/76511 - 6s - loss: 0.1038 - mae: 268.2467 - mse: 143608.6719 - val_loss: 0.1028 - val_mae: 267.2495 - val_mse: 145908.8125\n",
            "Epoch 936/1000\n",
            "76511/76511 - 6s - loss: 0.1031 - mae: 267.7896 - mse: 143419.0156 - val_loss: 0.1030 - val_mae: 265.8997 - val_mse: 141558.5469\n",
            "Epoch 937/1000\n",
            "76511/76511 - 6s - loss: 0.1030 - mae: 267.4127 - mse: 142214.3750 - val_loss: 0.1024 - val_mae: 265.3944 - val_mse: 141879.3438\n",
            "Epoch 938/1000\n",
            "76511/76511 - 6s - loss: 0.1031 - mae: 267.8161 - mse: 143158.2344 - val_loss: 0.1037 - val_mae: 269.5659 - val_mse: 149066.0156\n",
            "Epoch 939/1000\n",
            "76511/76511 - 6s - loss: 0.1030 - mae: 267.6063 - mse: 142555.7344 - val_loss: 0.1045 - val_mae: 268.7162 - val_mse: 143680.6719\n",
            "Epoch 940/1000\n",
            "76511/76511 - 6s - loss: 0.1031 - mae: 268.3910 - mse: 142960.7656 - val_loss: 0.1044 - val_mae: 271.2448 - val_mse: 152693.2031\n",
            "Epoch 941/1000\n",
            "76511/76511 - 6s - loss: 0.1031 - mae: 267.6039 - mse: 142604.0156 - val_loss: 0.1026 - val_mae: 266.0168 - val_mse: 143111.6719\n",
            "Epoch 942/1000\n",
            "76511/76511 - 6s - loss: 0.1039 - mae: 267.6865 - mse: 143418.0156 - val_loss: 0.1025 - val_mae: 265.1068 - val_mse: 140154.8281\n",
            "Epoch 943/1000\n",
            "76511/76511 - 6s - loss: 0.1034 - mae: 268.1827 - mse: 143779.5781 - val_loss: 0.1032 - val_mae: 266.1531 - val_mse: 141195.5156\n",
            "Epoch 944/1000\n",
            "76511/76511 - 6s - loss: 0.1035 - mae: 267.2618 - mse: 142575.8594 - val_loss: 0.1043 - val_mae: 270.7614 - val_mse: 151603.0625\n",
            "Epoch 945/1000\n",
            "76511/76511 - 5s - loss: 0.1030 - mae: 267.1720 - mse: 142050.8438 - val_loss: 0.1027 - val_mae: 265.7125 - val_mse: 141442.0781\n",
            "Epoch 946/1000\n",
            "76511/76511 - 6s - loss: 0.1031 - mae: 267.8828 - mse: 142928.1875 - val_loss: 0.1029 - val_mae: 267.1284 - val_mse: 145329.4688\n",
            "Epoch 947/1000\n",
            "76511/76511 - 6s - loss: 0.1035 - mae: 267.7697 - mse: 143065.2031 - val_loss: 0.1034 - val_mae: 266.0109 - val_mse: 141144.1719\n",
            "Epoch 948/1000\n",
            "76511/76511 - 6s - loss: 0.1028 - mae: 266.9936 - mse: 141939.9844 - val_loss: 0.1030 - val_mae: 267.7899 - val_mse: 146409.4219\n",
            "Epoch 949/1000\n",
            "76511/76511 - 6s - loss: 0.1038 - mae: 268.0673 - mse: 143461.9688 - val_loss: 0.1039 - val_mae: 267.0222 - val_mse: 140702.3438\n",
            "Epoch 950/1000\n",
            "76511/76511 - 6s - loss: 0.1034 - mae: 267.6337 - mse: 142609.4688 - val_loss: 0.1031 - val_mae: 266.6055 - val_mse: 143376.8438\n",
            "Epoch 951/1000\n",
            "76511/76511 - 6s - loss: 0.1031 - mae: 266.8353 - mse: 141726.0469 - val_loss: 0.1034 - val_mae: 267.6355 - val_mse: 145769.3594\n",
            "Epoch 952/1000\n",
            "76511/76511 - 6s - loss: 0.1030 - mae: 267.6532 - mse: 142984.7656 - val_loss: 0.1032 - val_mae: 267.7234 - val_mse: 145522.7031\n",
            "Epoch 953/1000\n",
            "76511/76511 - 6s - loss: 0.1035 - mae: 268.1553 - mse: 142818.2812 - val_loss: 0.1029 - val_mae: 266.1166 - val_mse: 142097.0156\n",
            "Epoch 954/1000\n",
            "76511/76511 - 6s - loss: 0.1035 - mae: 267.7304 - mse: 143001.6719 - val_loss: 0.1043 - val_mae: 270.4277 - val_mse: 150450.3281\n",
            "Epoch 955/1000\n",
            "76511/76511 - 6s - loss: 0.1025 - mae: 267.2360 - mse: 142161.3125 - val_loss: 0.1030 - val_mae: 266.3888 - val_mse: 141812.3125\n",
            "Epoch 956/1000\n",
            "76511/76511 - 6s - loss: 0.1030 - mae: 267.6935 - mse: 142347.2500 - val_loss: 0.1037 - val_mae: 267.0400 - val_mse: 142693.9062\n",
            "Epoch 957/1000\n",
            "76511/76511 - 6s - loss: 0.1030 - mae: 266.9041 - mse: 142174.2812 - val_loss: 0.1035 - val_mae: 268.6523 - val_mse: 147198.0000\n",
            "Epoch 958/1000\n",
            "76511/76511 - 6s - loss: 0.1032 - mae: 267.6226 - mse: 143183.9688 - val_loss: 0.1036 - val_mae: 269.2605 - val_mse: 148027.2812\n",
            "Epoch 959/1000\n",
            "76511/76511 - 6s - loss: 0.1031 - mae: 267.9250 - mse: 143420.1250 - val_loss: 0.1045 - val_mae: 271.2826 - val_mse: 153121.7656\n",
            "Epoch 960/1000\n",
            "76511/76511 - 6s - loss: 0.1031 - mae: 267.6214 - mse: 142676.6094 - val_loss: 0.1028 - val_mae: 266.8651 - val_mse: 144958.7969\n",
            "Epoch 961/1000\n",
            "76511/76511 - 6s - loss: 0.1025 - mae: 266.8687 - mse: 142145.5312 - val_loss: 0.1046 - val_mae: 270.3157 - val_mse: 151159.6719\n",
            "Epoch 962/1000\n",
            "76511/76511 - 5s - loss: 0.1029 - mae: 267.3012 - mse: 143112.4531 - val_loss: 0.1027 - val_mae: 266.0185 - val_mse: 141921.3906\n",
            "Epoch 963/1000\n",
            "76511/76511 - 5s - loss: 0.1030 - mae: 268.0960 - mse: 142912.6094 - val_loss: 0.1039 - val_mae: 269.3734 - val_mse: 150026.6562\n",
            "Epoch 964/1000\n",
            "76511/76511 - 6s - loss: 0.1040 - mae: 267.6626 - mse: 142921.1250 - val_loss: 0.1028 - val_mae: 266.4184 - val_mse: 143478.6250\n",
            "Epoch 965/1000\n",
            "76511/76511 - 6s - loss: 0.1030 - mae: 267.9049 - mse: 143011.9062 - val_loss: 0.1034 - val_mae: 267.4885 - val_mse: 144337.8438\n",
            "Epoch 966/1000\n",
            "76511/76511 - 6s - loss: 0.1032 - mae: 266.8955 - mse: 141876.7031 - val_loss: 0.1035 - val_mae: 268.1276 - val_mse: 147279.3438\n",
            "Epoch 967/1000\n",
            "76511/76511 - 6s - loss: 0.1031 - mae: 267.5265 - mse: 143451.7656 - val_loss: 0.1039 - val_mae: 268.8481 - val_mse: 147346.9375\n",
            "Epoch 968/1000\n",
            "76511/76511 - 6s - loss: 0.1034 - mae: 268.0767 - mse: 142988.2188 - val_loss: 0.1029 - val_mae: 266.2194 - val_mse: 143426.1250\n",
            "Epoch 969/1000\n",
            "76511/76511 - 6s - loss: 0.1030 - mae: 268.0290 - mse: 142933.9062 - val_loss: 0.1040 - val_mae: 269.9359 - val_mse: 150692.3125\n",
            "Epoch 970/1000\n",
            "76511/76511 - 6s - loss: 0.1031 - mae: 267.4629 - mse: 142357.1250 - val_loss: 0.1032 - val_mae: 267.2669 - val_mse: 145056.2656\n",
            "Epoch 971/1000\n",
            "76511/76511 - 6s - loss: 0.1038 - mae: 267.8182 - mse: 143984.2969 - val_loss: 0.1048 - val_mae: 271.9979 - val_mse: 153503.5938\n",
            "Epoch 972/1000\n",
            "76511/76511 - 6s - loss: 0.1027 - mae: 266.6264 - mse: 141813.4375 - val_loss: 0.1027 - val_mae: 265.7780 - val_mse: 141939.0312\n",
            "Epoch 973/1000\n",
            "76511/76511 - 6s - loss: 0.1033 - mae: 266.9892 - mse: 141767.4844 - val_loss: 0.1033 - val_mae: 266.7594 - val_mse: 143373.2969\n",
            "Epoch 974/1000\n",
            "76511/76511 - 6s - loss: 0.1032 - mae: 267.6729 - mse: 142989.5469 - val_loss: 0.1029 - val_mae: 266.5505 - val_mse: 143014.6094\n",
            "Epoch 975/1000\n",
            "76511/76511 - 6s - loss: 0.1032 - mae: 267.7298 - mse: 142995.1250 - val_loss: 0.1046 - val_mae: 270.2829 - val_mse: 149931.7188\n",
            "Epoch 976/1000\n",
            "76511/76511 - 6s - loss: 0.1037 - mae: 268.0681 - mse: 143438.4375 - val_loss: 0.1057 - val_mae: 274.6501 - val_mse: 158219.5156\n",
            "Epoch 977/1000\n",
            "76511/76511 - 6s - loss: 0.1029 - mae: 267.5177 - mse: 143011.0625 - val_loss: 0.1045 - val_mae: 270.8884 - val_mse: 151751.0938\n",
            "Epoch 978/1000\n",
            "76511/76511 - 6s - loss: 0.1042 - mae: 267.3327 - mse: 143471.5000 - val_loss: 0.1034 - val_mae: 267.8279 - val_mse: 146157.6406\n",
            "Epoch 979/1000\n",
            "76511/76511 - 6s - loss: 0.1031 - mae: 267.2469 - mse: 142831.7344 - val_loss: 0.1026 - val_mae: 265.3463 - val_mse: 140573.9375\n",
            "Epoch 980/1000\n",
            "76511/76511 - 6s - loss: 0.1028 - mae: 267.0983 - mse: 142848.6250 - val_loss: 0.1042 - val_mae: 269.7302 - val_mse: 149742.7812\n",
            "Epoch 981/1000\n",
            "76511/76511 - 6s - loss: 0.1029 - mae: 267.1557 - mse: 142371.3125 - val_loss: 0.1031 - val_mae: 265.6823 - val_mse: 140722.0000\n",
            "Epoch 982/1000\n",
            "76511/76511 - 6s - loss: 0.1029 - mae: 267.1570 - mse: 142763.0469 - val_loss: 0.1034 - val_mae: 267.8138 - val_mse: 146355.7031\n",
            "Epoch 983/1000\n",
            "76511/76511 - 6s - loss: 0.1030 - mae: 267.8149 - mse: 142607.7812 - val_loss: 0.1030 - val_mae: 267.3774 - val_mse: 145717.1406\n",
            "Epoch 984/1000\n",
            "76511/76511 - 6s - loss: 0.1025 - mae: 266.7273 - mse: 141756.4844 - val_loss: 0.1024 - val_mae: 265.8666 - val_mse: 142918.1875\n",
            "Epoch 985/1000\n",
            "76511/76511 - 6s - loss: 0.1030 - mae: 267.6111 - mse: 143065.8438 - val_loss: 0.1035 - val_mae: 268.7229 - val_mse: 148125.8750\n",
            "Epoch 986/1000\n",
            "76511/76511 - 6s - loss: 0.1027 - mae: 267.3970 - mse: 142604.8594 - val_loss: 0.1031 - val_mae: 267.0014 - val_mse: 145599.4219\n",
            "Epoch 987/1000\n",
            "76511/76511 - 6s - loss: 0.1033 - mae: 267.4919 - mse: 142800.5938 - val_loss: 0.1034 - val_mae: 268.3657 - val_mse: 147847.4219\n",
            "Epoch 988/1000\n",
            "76511/76511 - 6s - loss: 0.1030 - mae: 266.8405 - mse: 142181.5469 - val_loss: 0.1043 - val_mae: 270.5866 - val_mse: 151247.6094\n",
            "Epoch 989/1000\n",
            "76511/76511 - 6s - loss: 0.1027 - mae: 267.1127 - mse: 142487.5000 - val_loss: 0.1040 - val_mae: 268.8115 - val_mse: 148239.0156\n",
            "Epoch 990/1000\n",
            "76511/76511 - 6s - loss: 0.1031 - mae: 267.5904 - mse: 142353.5000 - val_loss: 0.1029 - val_mae: 265.7177 - val_mse: 141398.5625\n",
            "Epoch 991/1000\n",
            "76511/76511 - 6s - loss: 0.1026 - mae: 267.7668 - mse: 142268.1250 - val_loss: 0.1026 - val_mae: 266.3321 - val_mse: 144319.5625\n",
            "Epoch 992/1000\n",
            "76511/76511 - 6s - loss: 0.1026 - mae: 267.5375 - mse: 143603.4062 - val_loss: 0.1024 - val_mae: 265.4982 - val_mse: 141859.6094\n",
            "Epoch 993/1000\n",
            "76511/76511 - 6s - loss: 0.1028 - mae: 267.5773 - mse: 143071.4062 - val_loss: 0.1044 - val_mae: 270.0615 - val_mse: 149947.2188\n",
            "Epoch 994/1000\n",
            "76511/76511 - 6s - loss: 0.1029 - mae: 267.2228 - mse: 142551.6094 - val_loss: 0.1033 - val_mae: 268.7598 - val_mse: 148234.1094\n",
            "Epoch 995/1000\n",
            "76511/76511 - 6s - loss: 0.1030 - mae: 267.6631 - mse: 142758.1094 - val_loss: 0.1076 - val_mae: 277.7735 - val_mse: 163366.0156\n",
            "Epoch 996/1000\n",
            "76511/76511 - 6s - loss: 0.1031 - mae: 267.7194 - mse: 143208.5625 - val_loss: 0.1026 - val_mae: 266.2190 - val_mse: 144057.2969\n",
            "Epoch 997/1000\n",
            "76511/76511 - 6s - loss: 0.1026 - mae: 267.0184 - mse: 142388.9062 - val_loss: 0.1027 - val_mae: 265.5320 - val_mse: 141925.9844\n",
            "Epoch 998/1000\n",
            "76511/76511 - 6s - loss: 0.1030 - mae: 267.7397 - mse: 143448.9688 - val_loss: 0.1026 - val_mae: 265.5136 - val_mse: 141194.5781\n",
            "Epoch 999/1000\n",
            "76511/76511 - 6s - loss: 0.1028 - mae: 267.3401 - mse: 142624.3594 - val_loss: 0.1025 - val_mae: 265.7200 - val_mse: 142439.7969\n",
            "Epoch 1000/1000\n",
            "76511/76511 - 7s - loss: 0.1029 - mae: 267.6307 - mse: 143491.6562 - val_loss: 0.1032 - val_mae: 267.5864 - val_mse: 146819.7969\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x18c40349cc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7h4Ype_d7sTh",
        "colab_type": "code",
        "outputId": "df5ed4ba-ffd1-4a7b-aa2c-9485865452e0",
        "colab": {}
      },
      "source": [
        "#check models loss, mean actual error rate, mean squared error rate\n",
        "#uncomment to run\n",
        "loss, mae, mse = model.evaluate(normed_test_data, test_labels, verbose=2)\n",
        "print(\"Testing set Mean Abs Error: {:5.2f} \".format(mae))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15091/15091 - 0s - loss: 0.1023 - mae: 264.3573 - mse: 141213.4219\n",
            "Testing set Mean Abs Error: 264.36 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZZmrCeN7sTj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#saves TF model as name noted below\n",
        "model.save('predAnnualGas.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVeZ5YjE7sTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Save the model, serialized model to JSON format\n",
        "model_json = model.to_json()\n",
        "with open(\"predGasModel.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}