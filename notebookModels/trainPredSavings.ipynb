{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "trainPredSavings.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danoAasland/OhioUtilModel/blob/master/notebookModels/trainPredSavings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqbHLetS8hAI",
        "colab_type": "code",
        "colab": {},
        "outputId": "b08c491d-1509-49c8-948f-b502b511334a"
      },
      "source": [
        "#python 2/3 compatibility\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "#packages\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.externals import joblib\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fCmsOmB8hAN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#add code to input data\n",
        "#for now, uploads data file from local drive\n",
        "dataset =  pd.read_csv('mergeCleCinSave.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6m8urzd8hAQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#split data into train/test sets 80%/20%\n",
        "train_dataset = dataset.sample(frac=0.8,random_state=0)\n",
        "test_dataset = dataset.drop(train_dataset.index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJdW01iD8hAT",
        "colab_type": "code",
        "colab": {},
        "outputId": "d704f660-27ba-453c-e55b-c60e98ec62bf"
      },
      "source": [
        "#creates training data stats \n",
        "train_stats = train_dataset.describe()\n",
        "train_stats.pop(\"Estimated Savings\")\n",
        "train_stats = train_stats.transpose()\n",
        "\n",
        "#save train stats for norm. function\n",
        "scaler_filename = \"trainPredSaveScaler.save\"\n",
        "joblib.dump(train_stats, scaler_filename)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['trainPredSaveScaler.save']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4sYkIUh8hAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creates train and test datasets target variable: Estimated Savings dollar value\n",
        "#and removes target variable from feature variable dataset\n",
        "train_labels = train_dataset.pop('Estimated Savings')\n",
        "test_labels = test_dataset.pop('Estimated Savings')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2Q6c8xn8hAY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Function to normalize train and test datasets to dist. range from train data\n",
        "def norm(x):\n",
        "    return (x - train_stats['mean']) / train_stats['std']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fg-hyBfI8hAb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#normalized train and test datasets\n",
        "normed_train_data = norm(train_dataset)\n",
        "normed_test_data = norm(test_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dn4OCFsp8hAd",
        "colab_type": "code",
        "colab": {},
        "outputId": "1d318024-1110-4c0d-d5c5-bbc065c6c507"
      },
      "source": [
        "normed_test_data.head(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SF</th>\n",
              "      <th>Floors</th>\n",
              "      <th>Year Built</th>\n",
              "      <th>Value</th>\n",
              "      <th>E annual</th>\n",
              "      <th>G annual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>-0.567464</td>\n",
              "      <td>0.746941</td>\n",
              "      <td>-1.218103</td>\n",
              "      <td>-0.695772</td>\n",
              "      <td>-0.635564</td>\n",
              "      <td>2.02569</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         SF    Floors  Year Built     Value  E annual  G annual\n",
              "9 -0.567464  0.746941   -1.218103 -0.695772 -0.635564   2.02569"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbzTcAxy8hAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Deep Learning model, 4 layers deep, 2 fully connected layers\n",
        "#can adjust optimizer by commenting/uncommeting 'optimizer' variable\n",
        "#loss func. set to mod. penalize model for large errors\n",
        "\n",
        "def build_model():\n",
        "  model = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=[len(train_dataset.keys())]),\n",
        "    layers.Dropout(0.5), #50% data random dropout to reduce overfitting training data\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dropout(0.5), #50% data random dropout to reduce overfitting training data\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(1)\n",
        "  ])\n",
        "\n",
        "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "  #optimizer = tf.keras.optimizers.Adam(lr=0.001)\n",
        "\n",
        "  model.compile(loss='mean_squared_logarithmic_error',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mae', 'mse'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6CYTUEb8hAi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calls ML model and assigns it to the variable 'model'\n",
        "model = build_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zD73AJzg8hAk",
        "colab_type": "code",
        "colab": {},
        "outputId": "44e13df5-ebca-4311-ddee-d1926704774d"
      },
      "source": [
        "# The patience parameter is the amount of epochs to check for improvement\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=200)\n",
        "\n",
        "model.fit(normed_train_data, train_labels, epochs=1000, \n",
        "          validation_split = 0.2, verbose=0, \n",
        "          callbacks=[early_stop])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x13140cdefd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34Bdm6Gr8hAn",
        "colab_type": "code",
        "colab": {},
        "outputId": "4fdff8eb-13a0-403c-fbd4-03a617c886d5"
      },
      "source": [
        "#check models loss, mean actual error rate, mean squared error rate\n",
        "#uncomment to run\n",
        "loss, mae, mse = model.evaluate(normed_test_data, test_labels, verbose=2)\n",
        "print(\"Testing set Mean Abs Error: {:5.2f} \".format(mae))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33/33 - 0s - loss: 0.2049 - mae: 192.3001 - mse: 58961.9141\n",
            "Testing set Mean Abs Error: 192.30 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJjagqGp8hAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#saves TF model weights as name noted below\n",
        "model.save('predSaveDollar.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-upmSZt28hAt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#save the model, serialized model to JSON format\n",
        "model_json = model.to_json()\n",
        "with open(\"predSaveModel.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}